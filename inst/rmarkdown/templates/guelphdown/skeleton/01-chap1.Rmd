---
output:
  pdf_document: default
---

```{=html}
<!--
This is for including Chapter 1.  Notice that it's also good practice to name your chunk.  This will help you debug potential issues as you knit.  The chunk above is called intro and the one below is called chapter1.  Feel free to change the name of the Rmd file as you wish, but don't forget to change it here from chap1.Rmd.
-->
```
```{=html}
<!--
The {#rmd-basics} text after the chapter declaration will allow us to link throughout the document back to the beginning of Chapter 1.  These labels will automatically be generated (if not specified) by changing the spaces to hyphens and capital letters to lowercase.  Look for the reference to this label at the beginning of Chapter 2.
-->
```

```{r package_loading_int_c1, include=F}
#devtools::install_github(repo = 'sciarraseb/nonlinSimsAnalysis', force = T)
#devtools::install_github(repo = 'sciarraseb/nonlinSims', force = T)

library(easypackages)
packages <- c('tidyverse', 'RColorBrewer', 'parallel', 'data.table', 'kableExtra', 'ggtext', 'egg', 'ggbrace', 'cowplot', 'nonlinSimsAnalysis', 'nonlinSims', 'knitr', 'nonlinSims')
libraries(packages)

knitr::opts_chunk$set(message = F)
```

```{r knitting_setup_int_c1, echo=F, message = F, warning = F}
#import raw data files (needed for computing variances)
exp_1_raw <- nonlinSimsAnalysis:::convert_raw_var_to_sd(raw_data = read_csv('data/exp_1_data.csv')) %>%
  mutate_at(.vars = c("number_measurements", "measurement_spacing", "midpoint"), factor)

exp_1_ext_raw <- nonlinSimsAnalysis:::convert_raw_var_to_sd(raw_data = read_csv('data/exp_1_data_extended.csv')) %>%
  mutate_at(.vars = c("number_measurements", "measurement_spacing", "midpoint"), factor)


exp_2_raw <-nonlinSimsAnalysis:::convert_raw_var_to_sd(raw_data = read_csv('data/exp_2_data.csv')) %>%
  mutate_at(.vars = c("number_measurements", "measurement_spacing", "sample_size"), factor)

exp_3_raw <-nonlinSimsAnalysis:::convert_raw_var_to_sd(raw_data = read_csv('data/exp_3_data.csv')) %>%
  mutate_at(.vars = c("number_measurements", "time_structuredness", "sample_size"), factor)

#unfiltered data 
param_summary_exp_1 <- readRDS(file = 'data/uf_param_summary_exp_1.RData')
param_summary_exp_1_ext <- readRDS(file = 'data/uf_param_summary_exp_1_ext.RData')
param_summary_exp_2 <- readRDS(file = 'data/uf_param_summary_exp_2.RData')
param_summary_exp_3 <- readRDS(file = 'data/uf_param_summary_exp_3.RData')

#create analytical versions of summary data + converts vars to sds
exp_1_analytical <- generate_likert_days_data_sets(summary_data = param_summary_exp_1, exp_num = '1')
exp_1_ext_analytical <- generate_likert_days_data_sets(summary_data = param_summary_exp_1_ext, exp_num = '1')
exp_2_analytical <- generate_likert_days_data_sets(summary_data = param_summary_exp_2, exp_num = '2')
exp_3_analytical <- generate_likert_days_data_sets(summary_data = param_summary_exp_3, exp_num = '3')

combined_analytical_exp_1 <- rbind(exp_1_analytical$likert, exp_1_analytical$days)
combined_analytical_exp_1_ext <- rbind(exp_1_ext_analytical$likert, exp_1_ext_analytical$days)

combined_analytical_exp_2 <- rbind(exp_2_analytical$likert, exp_2_analytical$days)
combined_analytical_exp_3 <- rbind(exp_3_analytical$likert, exp_3_analytical$days)

#create condition summary data sets 
cond_summary_exp_1 <- compute_condition_summary(param_summary_data = combined_analytical_exp_1, facet_var = 'measurement_spacing', 
                          ind_vars = c('number_measurements', 'measurement_spacing', 'midpoint'))
cond_summary_exp_2 <- compute_condition_summary(param_summary_data = combined_analytical_exp_2, facet_var = 'measurement_spacing', 
                  ind_vars = c('number_measurements', 'measurement_spacing', 'sample_size'))

cond_summary_exp_3 <- compute_condition_summary(param_summary_data = combined_analytical_exp_3, facet_var = 'time_structuredness', 
                          ind_vars = c('number_measurements', 'sample_size', 'time_structuredness'))
```

```{r pre_knitting_setup_unfiltered_int_c1, echo=F, eval=F, include=F}
#code should be computed before knitting to decrease knitting time 
#load data from experiments
exp_1 <- read_csv(file = 'data/exp_1_data.csv') %>% filter(code == 0)
exp_1_ext <- read_csv(file = 'data/exp_1_data_extended.csv') %>% filter(code == 0)

exp_2 <- read_csv(file = 'data/exp_2_data.csv')
exp_3 <- read_csv(file = 'data/exp_3_data.csv')

#compute parameter summary statistics  
exp_1_long <- exp_1 %>%
    filter(code == 0) %>%
    #place parameter estimates in one column
    pivot_longer(cols = contains(c('theta', 'alpha', 'beta', 'gamma', 'epsilon')),
                 names_to = 'parameter', values_to = 'estimate') %>%
    filter(parameter == 'beta_fixed') %>%
    mutate(pop_value = midpoint)

exp_1_ordered <- order_param_spacing_levels(data = exp_1_long)

#xp_1_ordered %>%
#     #compute statistics for each parameter for each experimental variable
#     group_by(parameter, .dots = locate_ivs(exp_1_ordered)) %>%
#     summarize(
#      lower_ci = compute_middle_95_estimate(param_data = estimate)[1],
#      upper_ci = compute_middle_95_estimate(param_data = estimate)[2])

#ompute_parameter_summary(data = exp_1, exp_num = '1')

param_summary_exp_1 <- compute_parameter_summary(data = exp_1, exp_num = 1)
param_summary_exp_1_ext <- compute_parameter_summary(data = exp_1_ext_raw, exp_num = 1)
param_summary_exp_2 <- compute_parameter_summary(data = exp_2, exp_num = 2)
param_summary_exp_3 <- compute_parameter_summary(data = exp_3, exp_num = 3)

#necessary factor conversions 
param_summary_exp_1$number_measurements <- factor(param_summary_exp_1$number_measurements, levels = c(5, 7, 9,11))
param_summary_exp_1$midpoint <- factor(param_summary_exp_1$midpoint, levels = c(80, 180,280))

#necessary factor conversions 
param_summary_exp_1_ext$number_measurements <- factor(param_summary_exp_1$number_measurements, levels = c(5, 7, 9,11))
param_summary_exp_1_ext$midpoint <- factor(param_summary_exp_1_ext$midpoint, levels = c(80, 130,  180, 230, 280))


param_summary_exp_2$number_measurements <- factor(param_summary_exp_2$number_measurements, levels = c(5, 7, 9,11))
param_summary_exp_2$sample_size <- factor(param_summary_exp_2$sample_size, levels = c(30, 50, 100, 200, 500, 1000))

param_summary_exp_3$number_measurements <- factor(param_summary_exp_3$number_measurements, levels = c(5, 7, 9,11))
param_summary_exp_3$sample_size <- factor(param_summary_exp_3$sample_size, levels = c(30, 50, 100, 200, 500, 1000))

#write data sets 
#save parameter summary files as RData files so that metadata are correctly stored (e.g., factor levels, variable types)
saveRDS(object = param_summary_exp_1, file = 'data/uf_param_summary_exp_1.RData')
saveRDS(object = param_summary_exp_1_ext, file = 'data/uf_param_summary_exp_1_ext.RData')

saveRDS(object = param_summary_exp_2, file = 'data/uf_param_summary_exp_2.RData')
saveRDS(object = param_summary_exp_3, file = 'data/uf_param_summary_exp_3.RData')
```


```{r echo=F}
summary_table <- exp_1_ext_analytical$days %>%
  group_by(parameter, measurement_spacing) %>%
  summarize(mean_errorbar_length = mean(errorbar_length)) %>% 
  pivot_wider(names_from = 2, values_from = 3)
```

# Experiment 1 {#exp-1}

In Experiment 1, I investigated the number of measurements needed to obtain high model performance for the estimation of each logistic function parameter (i.e., unbiased and precise estimation) under different spacing schedules and natures of change. Before presenting the results of Experiment 1, I present my design and analysis goals. For my design goals, I conducted a 4 (measurement spacing:equal, time-interval increasing, time-interval decreasing, middle-and-extreme) x 4 (number of measurements: 5, 7, 9, 11) x 3 (nature of change: population value for the fixed-effect days-to-halfway elevation parameter [$\upbeta_{fixed}$] of 80, 180, or 280) study. For my analysis goals, I was interested in answering two questions. First, I was interested in whether placing measurements near periods of change increases model performance. To answer my first question, I determined whether model performance under each spacing schedule increased when measurements were taken closer to periods of change.

Second, I was interested in how to space measurements when the nature of change is unknown. When the nature of change is unknown, this translates to a situation where a researcher has little to no knowledge of how change unfolds over time, and so any nature of change is a viable candidate for the true change. Therefore, to determine how to space measurements when the nature of change is unknown, I averaged the model performance of each spacing schedule across all possible nature-of-change curves and considered the spacing schedule with the highest model performance to be the best one.


## Methods

### Overview of Data Generation {#data-generation}

#### Function Used to Generate Each Data Set

Data for each simulation experiment were generated using R [@rstudio]. To run the simulations, I created the `nonlinSims` package, which is available at the following GitHub repository: [https://github.com/sciarraseb/nonlinSims](https://github.com/sciarraseb/nonlinSims). The code used to run the simulations and create the data set can be found in Appendix \ref{simulation-code} and the data file (`exp_1_data.csv`) can be found at the following GitHub repository: [https://github.com/sciarraseb/dissertation](https://github.com/sciarraseb/dissertation). To generate the data, the *multilevel logistic function* shown below in Equation \@ref(eq:logFunction-generation) was used:

```{=tex}
\begin{align}
  y_{ij} = \uptheta_j + \frac{\upalpha_j - \uptheta_j}{{1 + e^\frac{\upbeta_j - time_i}{\upgamma_j}}} + \upepsilon_{ij}, 
(\#eq:logFunction-generation)
\end{align}
```

\noindent where $\uptheta$ represents the baseline parameter, $\upalpha$ represents the maximal elevation parameter, $\upbeta$ represents the days-to-halfway elevation parameter, and $\upgamma$ represents triquarter-halfway delta parameter. Note that, values for $\uptheta$, $\upalpha$, $\upbeta$, and $\upgamma$ were generated for each *j* person across all *i* time points, with an error value being randomly generated at each *i* time point($\upepsilon_{ij}$; see Figure \ref{fig:combined_plot} for a review of each parameter). In other words, unique response patterns were generated for each person in each generated data set. Importantly, 1000 data sets were generated per cell.

```{r logistic-interpretation-plot1, eval=F, include=F}
#setup variables for logistic curve 
time <- seq(from = 1, to = 360, by = 1)
theta <- 3
alpha <- 3.32
beta <- 180
gamma <- 40

logistic_data <- data.frame('day' = time, 
                            'curve_score' = theta + (alpha - theta)/(1 + exp((beta - time)/gamma))) 

#make first and last values exactly equal to theta and alpha 
logistic_data$curve_score[c(1, 360)] <- c(theta, alpha)

baseline <- logistic_data$curve_score[logistic_data$day == 1]
halfway_value <- logistic_data$curve_score[logistic_data$day == beta]
triquarter_value <- logistic_data$curve_score[logistic_data$day == beta + gamma]
maximal_elevation <- logistic_data$curve_score[logistic_data$day == 360]

#df for points 
point_df <- data.frame('day' = c(1, beta, beta+gamma, 360), 
                       'curve_score' = c(baseline, halfway_value, triquarter_value, maximal_elevation), 
                       'beta_brace' = factor(c('beta', 'beta', 'NA', 'NA')),
                       'beta_label' = rep('d[beta]', times = 4), 
                       
                       'gamma_brace' = factor(c('NA', 'gamma', 'gamma', 'NA')), 
                       'gamma_label' = rep('d[gamma]', times = 4),
                       
                       'total_brace' = factor(c('total', 'NA', 'NA', 'total')), 
                       'total_label' = rep('d[total]', times = 4))

font_size <- 8
title_font <- 30
axis_text_size <- 20
axis_title_size <- 24

theta_plot <- ggplot(data = logistic_data, aes(x = day, y = curve_score)) + 
  geom_line(size = 2) + 
  theme_classic(base_family = 'Helvetica') +
  scale_y_continuous(name = 'Curve value', limits = c(3, 3.35), breaks = c(3, 3.16, 3.23, 3.32)) + 
  scale_x_continuous(name = 'Day', breaks = c(0, beta, beta + gamma, 360)) +
  annotate(geom = 'text', x = 80, y = 3.28, label = 'y == theta + frac(alpha - theta, 1 + e^(frac(beta-time, gamma)))', parse = T, size = font_size) + 
  geom_point(data = point_df, mapping = aes(x = day, y = curve_score), size = 5) +
  coord_cartesian(clip = 'off') + 
  
  ggtitle(label = expression(bold(A:~Baseline~(theta)))) + 
  #theta 
  geom_segment(x = 10, xend = 360, y = baseline, yend = baseline, linetype = 5, size = 1) + #horizontal dashed line  
  geom_segment(x = 400, xend = 365, y = baseline, yend = baseline, size = 1, arrow = arrow(length = unit(0.3, 'cm'))) + #horizontal arrow
  annotate(geom = 'text', x = 440, y = 3.05, label = 'Baseline \n(y-axis)', size = font_size, fontface = 'bold') +
  annotate(geom = 'text', x = 440, y = 3.00, label = 'theta == 3.00', parse = T, size = font_size) + 

   #themes
  theme_classic(base_family = 'Helvetica', base_size = 13) +
  theme(plot.margin = unit(c(0, 1, 0.1, 0.1), units="cm"), 
        plot.title = element_text(face='bold', size = title_font,  hjust = 0), 
        axis.title = element_text(size = axis_title_size), 
        axis.text = element_text(size = axis_text_size, colour = 'black'), 
        plot.tag = element_text(face = 'bold'))


alpha_plot <- ggplot(data = logistic_data, aes(x = day, y = curve_score)) + 
  geom_line(size = 2) + 
  theme_classic(base_family = 'Helvetica') +
  scale_y_continuous(name = 'Curve value', limits = c(3, 3.35), breaks = c(3, 3.16, 3.23, 3.32)) + 
  scale_x_continuous(name = 'Day', breaks = c(0, beta, beta + gamma, 360)) +
  annotate(geom = 'text', x = 80, y = 3.28, label = 'y == theta + frac(alpha - theta, 1 + e^(frac(beta-time, gamma)))', parse = T, size = font_size) + 
  geom_point(data = point_df, mapping = aes(x = day, y = curve_score), size = 5) +
  coord_cartesian(clip = 'off') + 
  
  ggtitle(label = expression(bold(B:~Maximal~elevation~(alpha)))) + 
  #theta 
  geom_segment(x = -3, xend = 360, y = maximal_elevation, yend = maximal_elevation, linetype = 5, size = 1) + #horizontal dashed line  
  geom_segment(x = 400, xend = 365, y = maximal_elevation, yend = maximal_elevation, size = 1, arrow = arrow(length = unit(0.3, 'cm'))) + #horizontal arrow
  annotate(geom = 'text',  x = 440, y = 3.27, label = 'Maximal \nelevation \n(y-axis)', size = font_size, fontface = 'bold') +
  annotate(geom = 'text', x = 440, y = 3.20, label = 'alpha == 3.32', parse = T, size = font_size) + 

   #themes
  theme_classic(base_family = 'Helvetica', base_size = 13) +
  theme(plot.margin = unit(c(0, 1, 0.1, 0.1), units="cm"), 
        plot.title = element_text(face='bold', size = title_font,  hjust = 0), 
        axis.title = element_text(size = axis_title_size), 
        axis.text = element_text(size = axis_text_size, colour = 'black'), 
        plot.tag = element_text(face = 'bold'))


beta_plot <- ggplot(data = logistic_data, aes(x = day, y = curve_score)) + 
  geom_line(size = 2) + 
  theme_classic(base_family = 'Helvetica') +
  scale_y_continuous(name = 'Curve value', limits = c(3, 3.35), breaks = c(3, 3.16, 3.23, 3.32)) + 
  scale_x_continuous(name = 'Day', breaks = c(0, beta, beta + gamma, 360)) +
  annotate(geom = 'text', x = 80, y = 3.28, label = 'y == theta + frac(alpha - theta, 1 + e^(frac(beta-time, gamma)))', parse = T, size = font_size) + 
  geom_point(data = point_df, mapping = aes(x = day, y = curve_score), size = 5) +
  coord_cartesian(clip = 'off') + 
  
  ggtitle(label =  expression(bold(C:~Days~to~halfway~elevation~(beta)))) + 
  #theta 
    geom_segment(x = 130, xend = 175, y = 3.16, yend = 3.16, size = 1, arrow = arrow(length = unit(0.3, 'cm'))) + #horizontal arrow
  geom_segment(x = 180, xend = 180, y = 3.16, yend = 2.98, linetype = 2, size = 1) + #vertical dashed line 
  annotate(geom = 'text', x = 55, y = 3.14, label = 'Days to halfway \nelevation', size = font_size, fontface = 'bold') +
  annotate(geom = 'text', x = 55, y = 3.08, label = 'beta == 180~days', parse = T, size = font_size) + 
  
   #themes
  theme_classic(base_family = 'Helvetica', base_size = 13) +
  theme(plot.margin = unit(c(0, 1, 0.1, 0.1), units="cm"), 
        plot.title = element_text(face='bold', size = title_font,  hjust = 0), 
        axis.title = element_text(size = axis_title_size), 
        axis.text = element_text(size = axis_text_size, colour = 'black'), 
        plot.tag = element_text(face = 'bold'))

gamma_plot <- ggplot(data = logistic_data, aes(x = day, y = curve_score)) + 
  geom_line(size = 2) + 
  theme_classic(base_family = 'Helvetica') +
  scale_y_continuous(name = 'Curve value', limits = c(3, 3.35), breaks = c(3, 3.16, 3.23, 3.32)) + 
  scale_x_continuous(name = 'Day', breaks = c(0, beta, beta + gamma, 360)) +
  annotate(geom = 'text', x = 80, y = 3.28, label = 'y == theta + frac(alpha - theta, 1 + e^(frac(beta-time, gamma)))', parse = T, size = font_size) + 
  geom_point(data = point_df, mapping = aes(x = day, y = curve_score), size = 5) +
  coord_cartesian(clip = 'off') + 
  
  ggtitle(label = expression(bold(D:~`Triquarter-halfway`~'delta'~(gamma)))) +
  
  #gamma 
  geom_segment(x = 175, xend = 215, y = 3.233, yend = 3.233, size = 1, arrow = arrow(length = unit(0.3, 'cm'))) + #horizontal arrow
  geom_segment(x = 220, xend = 220, y = 3.233, yend = 2.98, linetype = 2, size = 1) + #vertical dashed line 
  annotate(geom = 'text', x = 100, y = 3.21, label = 'Triquarter-halfway delta', size = font_size, fontface = 'bold') +
  annotate(geom = 'text', x = 105, y = 3.15, label = 'gamma == 40~days', parse = T, size = font_size) + 
  
  #themes
  theme_classic(base_family = 'Helvetica', base_size = 13) +
  theme(plot.margin = unit(c(0, 1, 0.1, 0.1), units="cm"), 
        plot.title = element_text(face='bold', size = title_font,  hjust = 0), 
        axis.title = element_text(size = axis_title_size), 
        axis.text = element_text(size = axis_text_size, colour = 'black'), 
        plot.tag = element_text(face = 'bold'))

combined_plot <- ggarrange(theta_plot, alpha_plot, beta_plot, gamma_plot)
ggsave(plot = combined_plot, filename = 'Figures/combined_plot.pdf', width = 18, height = 12)


complete_plot <- ggplot(data = logistic_data, aes(x = day, y = curve_score)) + 
  geom_line(size = 1) + 
  theme_classic(base_family = 'Helvetica') +
  scale_y_continuous(name = 'Curve value', limits = c(3, 3.35), breaks = c(3, 3.16, 3.23, 3.32)) + 
  scale_x_continuous(name = 'Day', breaks = c(0, beta, beta + gamma, 360))+
  annotate(geom = 'text', x = 50, y = 3.28, label = 'y == theta + frac(alpha - theta, 1 + e^(frac(beta-time, gamma)))', parse = T, size = 5) + 
  geom_point(data = point_df, mapping = aes(x = day, y = curve_score), size = 3) +

  #beta
  annotate(geom = 'text', x = 85, y = 3.15, label = 'Days to halfway \nelevation', size = font_size, fontface = 'bold') +
  annotate(geom = 'text', x = 90, y = 3.12, label = 'beta == 180~days', parse = T, size = font_size) +
  geom_segment(x = 130, xend = 175, y = 3.16, yend = 3.16, size = 0.2, arrow = arrow(length = unit(0.3, 'cm'))) + #horizontal arrow
  geom_segment(x = 180, xend = 180, y = 3.16, yend = 2.98, linetype = 2, size = 0.3) + #vertical dashed line 
  
  #gamma
  annotate(geom = 'text', x = 97, y = 3.233, label = 'Triquarter-halfway delta', size = font_size, fontface = 'bold') +
  annotate(geom = 'text', x = 105, y = 3.21, label = 'gamma == 40~days', parse = T, size = font_size) + 
  geom_segment(x = 175, xend = 215, y = 3.233, yend = 3.233, size = 0.2, arrow = arrow(length = unit(0.3, 'cm'))) + #horizontal arrow
  geom_segment(x = 220, xend = 220, y = 3.233, yend = 2.98, linetype = 2, size = 0.3)+  #vertical dashed line  
  
  coord_cartesian(clip = 'off') + 
  #theta 
  geom_segment(x = 10, xend = 360, y = baseline, yend = baseline, linetype = 3, size = 0.3) + #horizontal dashed line  
  geom_segment(x = 400, xend = 365, y = baseline, yend = baseline, size = 0.2, arrow = arrow(length = unit(0.3, 'cm'))) + #horizontal arrow
  annotate(geom = 'text', x = 425, y = 3.03, label = 'Baseline \n(y-axis)', size = font_size, fontface = 'bold') +
  annotate(geom = 'text', x = 425, y = 3.00, label = 'theta == 3.00', parse = T, size = font_size) + 

  #alpha 
  geom_segment(x = -3, xend = 360, y = maximal_elevation, yend = maximal_elevation, linetype = 3, size = 0.3) + #vertical dashed line  
  geom_segment(x = 400, xend = 365, y = maximal_elevation, yend = maximal_elevation, size = 0.2, arrow = arrow(length = unit(0.3, 'cm'))) +      #horizontal arrow
  annotate(geom = 'text', x = 430, y = 3.30, label = 'Maximal \nelevation \n(y-axis)', size = font_size, fontface = 'bold') +
  annotate(geom = 'text', x = 430, y = 3.26, label = 'alpha == 3.32', parse = T, size = font_size) + 
  
   #themes
  theme_classic(base_family = 'Helvetica', base_size = 13) +
  theme(plot.margin = unit(c(0, 1, 0.1, 0.1), units="cm"), 
        plot.title = element_text(face='bold',size = title_font), 
        axis.title = element_text(size = 16), 
        axis.text = element_text(size = 13, colour = 'black'))
  
    ##brace information
  #stat_brace(data = point_df %>% filter(beta_brace == 'beta'), 
  #           mapping = aes(group = beta_brace, label = beta_label), labelsize = 4.5, parse = T,  width = 15, rotate = 90) + 
  #
  #stat_brace(data = point_df %>% filter(gamma_brace == 'gamma'), 
  #           mapping = aes(group = gamma_brace, label = gamma_label), labelsize = 4.5, parse = T,  width = 15, rotate = 90) +
  #
  #stat_brace(data = point_df %>% filter(total_brace == 'total'), 
  #           mapping = aes(group = total_brace, label = total_label), labelsize = 4.5, parse = T,  width = 15, rotate = 90) + 
  #
  #description box 
  #annotate(geom = 'rect', xmin = 235, xmax = 355, ymin = 3.02, ymax = 3.15, alpha = 0.1, color = 'black') + 
  #annotate(geom = 'text', x = 295, y = 3.13, label = 'd[total] == alpha~-~theta == 0.32', parse = T, size = 4.5) + 
  #annotate(geom = 'text', x = 295, y = 3.09, label = 'd[beta] == 0.5~(d[total]) == 0.16', parse = T, size = 4.5) + 
  #annotate(geom = 'text', x = 295, y = 3.06, label = 'd[gamma] == 0.23~(d[total]) == 0.07', parse = T, size = 4.5) + 
  #annotate(geom = 'text', x = 295, y = 3.03, label = 'd[beta]~+~d[gamma] == 0.73~(d[total]) == 0.23', parse = T, size = 4.5) + 

ggsave(plot = complete_plot, filename = 'Figures/complete_logistic_exp_plot.pdf', width = 9, height = 6)
```

The logistic growth function (Equation \ref{eq:logFunction-generation}) was used because it is a common pattern of organizational change [or institutionalization\; @lawrence2001]. Institutionalization curves follow an s-shaped pattern (i.e., logistic growth), and so their rates of change can be represented by the days-to-halfway elevation and triquarter-halfway delta parameters ($\upbeta$, $\upgamma$, respectively), and the success of the change can be defined by the magnitude of the difference between baseline and maximal elevation parameters ($\upalpha$ - $\uptheta$, respectively).

#### Population Values Used for Function Parameters

Table \@ref(tab:parameterValues) lists the parameter values that were used for the population parameters. Given that the decisions for setting the values for the baseline, maximal elevation, and residual variance parameters were informed by past research, the discussion that follows highlights how these decisions were made. The difference between the baseline and maximal elevation parameters ($\uptheta$ and $\upalpha$, respectively) corresponded to the effect size most commonly observed in organizational research [i.e., the 50^th^ percentile effect size value\; @bosco2015]. Because the meta-analysis of @bosco2015 computed effect sizes as correlations, the 50^th^ percentile effect size value of $r = .16$ was computed to a standardized effect size using the following conversion function shown in Equation \ref{eq:conversion-effect} [@borenstein2009, Chapter 7]:

```{=tex}
\begin{align}
d = \frac{2r}{\sqrt{1 - r^2}}, 
(\#eq:conversion-effect)
\end{align}
```
\noindent where $r$ is the correlation effect size. Using Equation \ref{eq:conversion-effect}, a correlation value of $r = .16$ becomes a standardized effect size value of $d = 0.32$. For the value of the residual variance parameter ($\upepsilon$), @coulombe2016 set it to the value used for the intercept variance parameter. In the current context, the intercept of the logistic function (Equation \ref{eq:logFunction-generation}) is the baseline parameter ($\uptheta$).\footnote{The definition of an intercept parameter is the value of a curve when no time has elapsed, and this is precisely the definition of the baseline parameter ($\uptheta$). Therefore, the variance of the intercept parameter carries the same meaning as the variance of the baseline parameter ($\uptheta_{random}$).} Given that the value for the variability of the baseline parameter was 0.05 (albeit in standard deviation units), the value used for the residual variance parameter was 0.05 ($\upepsilon = 0.05$). Importantly, because @coulombe2016 set covariances between parameters to zero, all the simulation experiments used zero-value covariances. Because justification for the other parameters could not be found in any of the simulation studies identified in my systematic review, values set for the other parameters were largely arbitrary.

Two last brief points need to be mentioned about how data were generated to facilitate the interpretation of the results. First, data were generated to take on units similar to that of a Likert scale (range of 1--5) by assuming a standard deviation of 1.00. Thus, previously established effect size of $d = 0.32$ standard deviations implies an effect size of 0.32 units. Second, change was assumed to occur over a period of 360 days because many organizational processes are often governed by annual events (e.g., performance reviews, annual returns, regulations, etc.).

### Modelling of Each Generated Data Set {#data-modelling}

Previously, I described how data were generated. Here, I describe how the generated data were modelled.

Each data set generated by the multilevel logistic function (Equation \ref{eq:logFunction-generation}) was analysed using a modified latent growth curve model known as a structure latent growth curve model [@preacher2015].

```{r parameterValues, echo=F}
#specify parameters for parameter table 
theta <- 3
alpha <- 3 + .32*1
beta <- 180
gamma <- 20

sd_alpha <- 0.05
sd_theta <- 0.05
sd_beta <- 10
sd_gamma <- 4

sd_error <- 0.05


#table of parameter values
parameterValues_df <- data.frame('Parameter Means' = c(
                                         'Baseline, $\\uptheta$',
                                         'Maximal elevation, $\\upalpha$', 
                                         'Days-to-halfway elevation, $\\upbeta$', 
                                         'Triquarter-halfway delta, $\\upgamma$', 
                                         
                         'Variability and Covariability Parameters (in Standard Deviations)', 
                              'Baseline standard deviation, $\\uppsi_{\\uptheta}$',
                              'Maximal elevation standard deviation, $\\uppsi_{\\upalpha}$', 
                              'Days-to-halfway elevation standard deviation, $\\uppsi_{\\upbeta}$',
                              'Triquarter-halfway delta standard deviation, $\\uppsi_{\\upgamma}$',
                         
                              'Baseline-maximal elevation covariability, $\\uppsi_{\\uptheta\\upalpha}$',
                              'Baseline-days-to-halfway elevation covariability, $\\uppsi_{\\uptheta\\upbeta}$',
                              'Baseline-triquarter-halfway delta covariability, $\\uppsi_{\\uptheta\\upgamma}$',
                         
                              'Maximal elevation-days-to-halfway elevation covariability, $\\uppsi_{\\upalpha\\upbeta}$',
                              'Maximal elevation-triquarter-halfway delta covariability, $\\uppsi_{\\upalpha\\upgamma}$',
                         
                              'Days-to-halfway elevation-triquarter-halfway delta covariability, $\\uppsi_{\\upbeta\\upgamma}$',
                          
                              'Residual standard deviation, $\\uppsi_{\\upepsilon}$'), 
                         'Value' = c( theta, alpha, beta, gamma, 
                                     '', sd_theta, sd_alpha, sd_beta, sd_gamma, 
                                     0, 0, 0, 0, 0,0,  sd_error), check.names = F)

#round numbers to that they print with two significant numbers
parameterValues_df$Value <- round(as.numeric(as.character(parameterValues_df$Value)), 3)
parameterValues_df$Value <- formatC(round(parameterValues_df$Value, 3), format='f', digits=2)

#replace '  NA' with empty string 
parameterValues_df$Value[parameterValues_df$Value ==" NA"] <- ''

kbl(parameterValues_df, booktabs = TRUE, format = 'latex', longtable = T, 
    linesep = c(rep('', times = 3), '\\addlinespace\\addlinespace\\cmidrule{1-2}', '\\cmidrule{1-2}',
                rep('', times = 10)), 
    align = c('l', 'c'), 
    caption = "Values Used for Multilevel Logistic Function Parameters", 
    escape = F) %>%
   add_indent(positions = c(1:4, 6:16), level_of_indent = 2) %>%
   kable_styling(latex_options= c('hold_position', 'repeat_header'), position = 'left') %>%
  footnote(general =  "\\\\textit{Note. }The difference between $\\\\upalpha$ and $\\\\uptheta$ corresponds to the 50$\\\\mathrm{^{th}}$ percentile Cohen's $d$ value of 0.32 in organizational psychology (Bosco et al., 2015).",  threeparttable = T,  escape = F, general_title = '') %>%
   column_spec(column = 1, width = '12 cm')
```

\noindent Importantly, the model fit to each generated data set estimated nine parameters: A fixed-effect parameter for each of the four logistic function parameters, a random-effect parameter for each of the four logistic function parameters, and an error parameter. As with a multilevel model, a fixed-effect parameter has a constant value across all individuals, whereas a random-effect parameter represents the variability of values across all modelled people.\footnote{Estimating a random-effect for a parameter allows person- or data-point-specific values to be computed for the parameter.} To fit the logistic function to a given data set (Equation \ref{eq:logFunction-generation}), a linear approximation of the logistic function was needed so that it could fit within the linear nature of structural equation modelling framework.\footnote{The logistic function (Equation \ref{eq:logFunction-generation}) is a nonlinear function and so cannot be directly inserted into the structural equation modelling framework because this framework only allows linear computations of matrix-matrix, matrix-vector, and vector-vector operations. Unfortunately, the algebraic operations permitted in a linear framework cannot directly reproduce the operations in the logistic function (Equation \ref{eq:logFunction-generation}) and so a linear approximation of the logistic function must be constructed so that the logistic function can be inserted into the structural equation modelling framework.} To construct a linear approximation of the logistic function, a first-order Taylor series was constructed for the logistic function. For a detailed explanation of how the logistic function was fit into the structural equation modelling framework, see Appendix \ref{structured-lgc} for an explanation of the model and Appendix \ref{structured-lgc-code} for the code used to create the model.

### Variables Used in Simulation Experiment

#### Independent Variables

To build on current research, Experiment 1 used independent variable manipulations from a select number of previous studies. In looking at the summary of the simulation literature in Table \ref{tab:systematicReview}, the study by @coulombe2016 was the only one to investigate three longitudinal issues of interest to my dissertation, and so represented the most comprehensive investigation. Because I was also interested in investigating measurement spacing, manipulations were inspired from the only other simulation study identified by my systematic review to manipulate measurement spacing [the study by @timmons2015]. The sections that follow will discuss each of the variables manipulated in Experiment 1.

##### Spacing of Measurements {#spacing-measurements}

The only simulation study identified by my systematic review that manipulated measurement spacing was @timmons2015. Measurement spacing in @timmons2015 was manipulated in the following four ways:

1)  *Equal spacing*: measurements are divided by intervals of equivalent lengths.

2)  *Time-interval increasing spacing*: intervals that divide measurements increase in length over time.

3)  *Time-interval decreasing spacing*: intervals that divide measurements decrease in length over time.

4)  *Middle-and-extreme spacing*: measurements are clustered near the beginning, middle, and end of the data collection period.

\noindent To maintain consistency with the established literature, I manipulated measurement spacing in the same way as @timmons2015 presented above. Importantly, because @timmons2015 did not create their measurement spacing schedules with any systematicity, I developed a novel and replicable procedure for generating measurement schedules for each of the four measurement spacing conditions, which is described in Appendix \ref{measurement-schedules}. I also automated the generation of measurement schedules by creating a set of functions in R [@rstudio].

Table \@ref(tab:measurementDays) lists the measurement days that were used for all measurement spacing-measurement number cells. The first column lists the type of measurement spacing (i.e., equal, time-interval increasing, time-interval decreasing, or middle-and-extreme); the second column lists the number of measurements (5, 7, 9, or 11); the third column lists the measurement days that correspond to each measurement number-measurement spacing condition; and the fourth column lists the interval lengths between the measurements. Note that the interval lengths are equal for equal spacing, increase over time for time-interval increasing spacing, and decrease over time for time-interval decreasing spacing. For cells with middle-and-extreme spacing, the measurement days and interval lengths in the middle of the measurement window have been emboldened.

##### Number of Measurements {#number-measurements}

The smallest measurement number value in @coulombe2016 of three measurements could not be used in Experiment 1 (or any other simulation experiment that manipulated measurement number in my dissertation) because doing so would have created non-identified models The model used in my simulations estimated 9 parameters (*p* = 9; 4 fixed-effects + 4 random-effects + 1 error)\footnote{Degrees of freedom is calculated by multiplying the number of observed variables (\textit{p}) by \textit{p} + 1 and dividing it by 2 \parencite[$\frac{p [p+1]}{2}$;][]{loehlin2017}.} and so the minimum number of measurements (or observed variables) required for model identification (and to allow model comparison) was 4. Although a measurement number of three could not be used in my manipulation of measurement number, the next highest measurement number values in @coulombe2016 of 5, 7, and 9 were used. Importantly, a larger value of 11 was 

```{r measurementDays, echo=F}
time_period <- 360
num_measurements <- seq(from = 5, to = 11, by = 2)
smallest_int_length <- 30

#meausurement days 
equal_5 <- compute_measurement_schedule(time_period = time_period, num_measurements = 5, smallest_int_length,measurement_spacing = 'equal')$measurement_days
equal_7 <- compute_measurement_schedule(time_period = time_period, num_measurements = 7, smallest_int_length,measurement_spacing = 'equal')$measurement_days
equal_9 <- compute_measurement_schedule(time_period = time_period, num_measurements = 9, smallest_int_length,measurement_spacing = 'equal')$measurement_days
equal_11 <- compute_measurement_schedule(time_period = time_period, num_measurements = 11, smallest_int_length,measurement_spacing = 'equal')$measurement_days

time_inc_5 <- compute_measurement_schedule(time_period = time_period, num_measurements = 5, smallest_int_length,measurement_spacing = 'time_inc')$measurement_days
time_inc_7 <- compute_measurement_schedule(time_period = time_period, num_measurements = 7, smallest_int_length,measurement_spacing = 'time_inc')$measurement_days
time_inc_9 <- round(compute_measurement_schedule(time_period = time_period, num_measurements = 9, smallest_int_length,measurement_spacing = 'time_inc')$measurement_days, 2)
time_inc_11 <- round(compute_measurement_schedule(time_period = time_period, num_measurements = 11, smallest_int_length,measurement_spacing = 'time_inc')$measurement_days, 2)

time_dec_5 <- compute_measurement_schedule(time_period = time_period, num_measurements = 5, smallest_int_length,measurement_spacing = 'time_dec')$measurement_days
time_dec_7 <- compute_measurement_schedule(time_period = time_period, num_measurements = 7, smallest_int_length,measurement_spacing = 'time_dec')$measurement_days
time_dec_9 <- round(compute_measurement_schedule(time_period = time_period, num_measurements = 9, smallest_int_length,measurement_spacing = 'time_dec')$measurement_days, 2)
time_dec_11 <- round(compute_measurement_schedule(time_period = time_period, num_measurements = 11, smallest_int_length,measurement_spacing = 'time_dec')$measurement_days, 2)

mid_ext_5 <- compute_measurement_schedule(time_period = time_period, num_measurements = 5, smallest_int_length,measurement_spacing = 'mid_ext')$measurement_days
mid_ext_7 <- compute_measurement_schedule(time_period = time_period, num_measurements = 7, smallest_int_length,measurement_spacing = 'mid_ext')$measurement_days
mid_ext_9 <- compute_measurement_schedule(time_period = time_period, num_measurements = 9, smallest_int_length,measurement_spacing = 'mid_ext')$measurement_days
mid_ext_11 <- compute_measurement_schedule(time_period = time_period, num_measurements = 11, smallest_int_length,measurement_spacing = 'mid_ext')$measurement_days


#measurement intervals
equal_5_int <- compute_measurement_schedule(time_period = time_period, num_measurements = 5, smallest_int_length,measurement_spacing = 'equal')$interval_lengths
equal_7_int <- compute_measurement_schedule(time_period = time_period, num_measurements = 7, smallest_int_length,measurement_spacing = 'equal')$interval_lengths
equal_9_int <- compute_measurement_schedule(time_period = time_period, num_measurements = 9, smallest_int_length,measurement_spacing = 'equal')$interval_lengths
equal_11_int <- compute_measurement_schedule(time_period = time_period, num_measurements = 11, smallest_int_length,measurement_spacing = 'equal')$interval_lengths

time_inc_5_int <- compute_measurement_schedule(time_period = time_period, num_measurements = 5, smallest_int_length,measurement_spacing = 'time_inc')$interval_lengths
time_inc_7_int <- compute_measurement_schedule(time_period = time_period, num_measurements = 7, smallest_int_length,measurement_spacing = 'time_inc')$interval_lengths
time_inc_9_int <- round(compute_measurement_schedule(time_period = time_period, num_measurements = 9, smallest_int_length,measurement_spacing = 'time_inc')$interval_lengths, 2)
time_inc_11_int <- round(compute_measurement_schedule(time_period = time_period, num_measurements = 11, smallest_int_length,measurement_spacing = 'time_inc')$interval_lengths, 2)

time_dec_5_int <- compute_measurement_schedule(time_period = time_period, num_measurements = 5, smallest_int_length,measurement_spacing = 'time_dec')$interval_lengths
time_dec_7_int <- compute_measurement_schedule(time_period = time_period, num_measurements = 7, smallest_int_length,measurement_spacing = 'time_dec')$interval_lengths
time_dec_9_int <- round(compute_measurement_schedule(time_period = time_period, num_measurements = 9, smallest_int_length,measurement_spacing = 'time_dec')$interval_lengths, 2)
time_dec_11_int <- round(compute_measurement_schedule(time_period = time_period, num_measurements = 11, smallest_int_length,measurement_spacing = 'time_dec')$interval_lengths, 2)

mid_ext_5_int <- compute_measurement_schedule(time_period = time_period, num_measurements = 5, smallest_int_length,measurement_spacing = 'mid_ext')$interval_lengths
mid_ext_7_int <- compute_measurement_schedule(time_period = time_period, num_measurements = 7, smallest_int_length,measurement_spacing = 'mid_ext')$interval_lengths
mid_ext_9_int <- compute_measurement_schedule(time_period = time_period, num_measurements = 9, smallest_int_length,measurement_spacing = 'mid_ext')$interval_lengths
mid_ext_11_int <- compute_measurement_schedule(time_period = time_period, num_measurements = 11, smallest_int_length,measurement_spacing = 'mid_ext')$interval_lengths


measurement_days_df <- data.frame('Spacing Schedule' = c('Equal', '', '', '', 
                                                         'Time-interval increasing', '', '', '', 
                                                         'Time-interval decreasing', '', '', '', 
                                                         'Middle-and-extreme', '', '', ''), 
                                  'Number of Measurements' = rep(num_measurements, times = 4), 
                                  'Measurement Days' = c(paste(equal_5, collapse = ', '), 
                                                         paste(equal_7, collapse = ', '), 
                                                         paste(equal_9, collapse = ', '), 
                                                         paste(equal_11, collapse = ', '), 
                                                         
                                                         paste(time_inc_5, collapse = ', '),
                                                         paste(time_inc_7, collapse = ', '),
                                                         paste(time_inc_9, collapse = ', '),
                                                         paste(time_inc_11, collapse = ', '),
                                                         
                                                         paste(time_dec_5, collapse = ', '),
                                                         paste(time_dec_7, collapse = ', '),
                                                         paste(time_dec_9, collapse = ', '),
                                                         paste(time_dec_11, collapse = ', '),
                                                         
                                                        '1, \\textbf{150, 180, 210}, 360',
                                                        '1, 30, \\textbf{150, 180, 210}, 330, 360',
                                                        '1, 30, 60, \\textbf{150, 180, 210}, 300, 330, 360',
                                                        '1, 30, 60, \\textbf{120, 150, 180, 210, 240,} 300, 330, 360'), 
                                  
                                  'Interval Lengths' = c(paste(equal_5_int, collapse = ', '), 
                                                         paste(equal_7_int, collapse = ', '), 
                                                         paste(equal_9_int, collapse = ', '), 
                                                         paste(equal_11_int, collapse = ', '), 
                                                         
                                                         paste(time_inc_5_int, collapse = ', '),
                                                         paste(time_inc_7_int, collapse = ', '),
                                                         paste(time_inc_9_int, collapse = ', '),
                                                         paste(time_inc_11_int, collapse = ', '),
                                                         
                                                         paste(time_dec_5_int, collapse = ', '),
                                                         paste(time_dec_7_int, collapse = ', '),
                                                         paste(time_dec_9_int, collapse = ', '),
                                                         paste(time_dec_11_int, collapse = ', '),
                                                         
                                                        '150, \\textbf{30, 30}, 150',
                                                         '30, 120, \\textbf{30, 30}, 120, 30',
                                                         '30, 30, 90, \\textbf{30, 30}, 90, 30, 30',
                                                         '30, 30, 60, \\textbf{30, 30, 30, 30}, 60, 30, 30'),
                                  check.names = F)

kbl(x = measurement_days_df, booktabs = TRUE, format = 'latex', longtable = T, 
      align = c('l', 'l'), 
    linesep = c(rep('', times = 3),
            '\\cmidrule{1-4}\\addlinespace'), 
      caption = 'Measurement Days Used for All Measurement Number-Measurement Spacing Conditions ', 
    escape=F) %>%
    column_spec(column = 1, width = '4.5cm') %>%
  column_spec(column = 2, width = '3cm') %>%
   column_spec(column = 3, width = '6.5cm') %>%
     column_spec(column = 4, width = '6cm') %>%

   kable_styling(latex_options= c('hold_position', 'repeat_header'), font_size = 10, position = 'left') %>%  
    footnote(general =  "\\\\textit{Note. }For middle-and-extreme spacing levels, the measurement days and and interval lengths corresponding to the middle of measurement windows have been emboldened.",  threeparttable = T,  escape = F, general_title = '')%>%
  landscape(margin = '2.54cm')

```

added to test for a possible effect of a high measurement number. Therefore, my simulation experiments used the following values in manipulating the number of measurements: 5, 7, 9, and 11.

##### Population Values Set for The Fixed-Effect Days-to-Halfway Elevation Parameter $\upbeta_{fixed}$ (Nature of Change)

The nature of change was manipulated by setting the days-to-halfway elevation parameter ($\upbeta_{fixed}$) to a value of either 80, 180, or 280 days (see Figure \ref{fig:combined_plot}A). Note that no other study in my systematic review manipulated nature of change using logistic curves and so its manipulation in Experiment 1 is, to the best of my knowledge, unique. Importantly, nature of change was manipulated to simulate situations where uncertainty exists in how change unfolds over time.

#### Constants

Given that each simulation experiment manipulated no more than three independent variables so that results could be readily interpreted [@halford2005], other variables had to be set to constant values. In Experiment 1, two important variables were set to constant values: sample size and time structuredness. For sample size, I set the value across all cells to the average sample size used in organizational research [*n* = 225\; @bosco2015]. For time structuredness, data across all cells were generated to be time structured (i.e., all participants provide data according to one response pattern; that is, at each time point, participants provide their data at the exact same moment).

#### Dependent Variables {#dependent-variables}

##### Convergence Success Rate {#convergence}

The proportion of iterations in a cell where models converged defined the *convergence success rate*.\footnote{Specifically, convergence was obtained if the convergence code returned by OpenMx was 0.} Equation \@ref(eq:convergence) below shows the calculation used to compute the convergence success rate:

```{=tex}
\begin{align}
  \text{Convergence success rate} =  \frac{\text{Number of models that successfully converged in a cell}}{n},
  (\#eq:convergence) 
\end{align}
```
\noindent where *n* represents the total number of models run in a cell.

##### Model Performance

Model performance was the combination of two metrics: bias and precision. More specifically, two questions were of importance in the estimation of a given logistic function parameter: 1) How well was the parameter estimated on average (bias) and 2) what was a range of values that could be expected for an estimate from the output of a single model (precision). In the two sections that follow, I will discuss each metric of model performance and the cutoffs used to determine whether estimation was unbiased and precise.

###### Bias {#bias-comp}

Bias was calculated to evaluate the accuracy with which each logistic function parameter was estimated in each experimental cell. As shown below in Equation \@ref(eq:bias), *bias* was obtained by summing the differences between the population value set for a parameter and the value estimated for the parameter by each $i$ converged model and then dividing the sum by the number of $N$ converged models.

```{=tex}
\begin{align}
  \text{Bias} = \frac{\sum_i^N\text{(Population value for parameter} - \text{Average estimated value}_i)}{N}
  (\#eq:bias) 
\end{align}
```
\noindent Bias was calculated for the fixed- and random-effect parameters of the baseline ($\uptheta_{fixed}$, $\uptheta_{random}$), maximal elevation ($\upalpha_{fixed}$, $\upalpha_{random}$), days-to-halfway elevation ($\upbeta_{fixed}$, $\upbeta_{random}$), and the triquarter-halfway delta parameters ($\upgamma_{fixed}$, $\upgamma_{random}$) and the error parameter ($\upepsilon$).

###### Precision {#pres-precision}

In addition to computing bias, precision was calculated to evaluate the variability with which each parameter was estimated. Importantly, metrics used to evaluate precision in previous studies often assume estimates are normally distributed (e.g., mean-squared error and empirical standard error). Because some parameters in my simulations had skewed distributions, using a metric that assumed a normal distribution would likely yield inaccurate results. Correspondingly, I used a distribution-independent definition of precision. In my simulations, *precision* was defined as the range of values covered by the middle 95% of values estimated for a logistic function parameter.

### Analysis of Data Modelling Output and Accompanying Visualizations {#analysis-visualization}

To analyse and visualize modelling performance, I calculated values for convergence success rate, bias, and precision in each experimental cell (see [dependent variables](#dependent-variables)). The sections that follow provide details on how I analysed each dependent variable and constructed plots to visualize bias and precision.

#### Analysis of Convergence Success Rate {#convergence-analysis}

For the analysis of convergence success rate, the mean convergence success rate was computed for each cell in each experiment (see section on [convergence success rate](#convergence)). Because convergence rates exhibited little variability across cells due to the nearly unanimous high rates (almost all cells across all experiments had convergence success rates above 90%), examining the effects of any independent variable on these values would have provided little information. Therefore, I only reported the average convergence success rate for each cell (see Appendix \ref{convergence-tables}).

#### Analysis and Visualization of Bias {#bias-analysis}

In accordance with several simulation studies, an estimate with a bias value within a $\pm10\%$ margin of error of the parameter's population value was deemed unbiased [@muthen1997]. To visualize bias, I constructed bias/precision plots. Figure \ref{fig:param-estimation-ex} shows a bias/precision plot for the fixed-effect triquarter-halfway parameter ($\upgamma_{fixed}$) for each measurement number and nature of change. The dots (squares, circles, triangles, diamonds) indicate the average estimated value (see [bias](#bias-comp)). The horizontal blue line indicates the population value ($\upgamma_{fixed}$ = 4.00) and the gray band indicates the acceptable margin of error of $\pm10\%$ of the parameter's population value. Dots that lie within the gray margin of error are filled and dots that lie outside of the margin remain unfilled. In the current example, the average value estimated for the fixed-effect triquarter-halfway delta parameter ($\upgamma_{fixed}$) is only biased (i.e., lies outside the margin of error) with five measurements with a nature-of-change value of 80 ($\upbeta_{fixed}$ = 80). Therefore, estimates are unbiased in almost all cells.

#### Analysis and Visualization of Precision {#precision-analysis}

As discussed previously, precision was defined as the range of values covered by the middle 95% of estimated values for a given parameter (see [precision](#precision-mid-ext-exp1)). The cutoff value used to estimate precision directly followed from the cutoff value used for bias. Given that bias values within $\pm10\%$ of a parameter's population value were deemed acceptable, an acceptable value for precision should not allow any bias value above the $\pm10\%$ cutoff. That is, the range covered by the middle 95% of estimated values should not contain a bias value outside the $\pm10\%$ cutoff. If the range of values covered by the middle 95% of estimate values is conceptualized as an error bar centered on the population value, then an acceptable value for precision implies that neither the lower nor upper whiskers have a length greater than 10% of the parameter's population value. In summary, I deemed precision acceptable if no estimate within the range of values covered by the middle 95% of estimated values had a bias value greater than 10% of the population value, which also means that neither the lower nor upper whiskers of the error bar have a length greater than 10% of the population value.

Like bias, I also depicted precision in bias/precision plots using error bars. Each error bar in the bias/precision plot of Figure \ref{fig:param-estimation-ex} indicates the range of values covered by the middle 95% of estimated values in the given cell for the fixed-effect triquarter-halfway delta parameter ($\upgamma_{fixed}$). Importantly, if estimation is not precise, then at least one of the lower and/or upper whisker lengths exceeds 10% of the parameter's population value. When estimation is not precise, the error bar is light blue. When estimation is precise (i.e., neither of the lower or upper whisker lengths exceed 10% of the parameter's population value), the corresponding error bar is black. In the current example, all error bars are light blue and so precision is low in all cells.


```{=tex}
\begin{apaFigure}
[portrait]
[0cm]
{Bias/Precision Plot for the Fixed-Effect Days-to-Halfway Elevation Parameter ($\upgamma_{fixed}$)}
{param-estimation-ex}
{0.9}
{Figures/param_estimation_ex}
{Dots (squares, circles, triangles, diamonds) indicate the average estimated value and error bars show the range of values covered by the middle 95\% of the estimated values (see \nameref{pres-precision}). The horizontal blue line indicates the population value ($\upgamma_{fixed}$ = 4.00) and the gray band indicates the acceptable margin of error (i.e., $\pm$10\% of the population value) for bias. Dots that lie outside of the margin of error are unfilled and are considered biased estimates. Dots that lie inside the margin of error are filled and considered unbiased estimates. Error bars whose upper and/or lower whisker lengths exceed 10\% of the parameter's population value are light blue and indicate parameter estimation that is not precise. Error bars whose upper and/or lower whisker lengths do not excced 10\% of the parameter's population value are black and indicate parameter estimation that is precise.}
\end{apaFigure}
```

```{r variability-histograms, eval=F, include=F}
exp_2 <- read_csv(file = 'data/exp_2_data.csv')

#function does not work anymore 
generate_param_density_plot(raw_exp_data = exp_2, param_summary_data = param_summary_exp_2, spacing = 'Equal', num_measurements = 5, sample_size = 30)
```

##### Effect Size Computation for Precision

One last statistic I calculated was an effect size value to estimate the variance in parameter estimates accounted for by each effect. Among the several effect size metrics---at a broad level, effect size metrics can represent standardized differences or variance-accounted-for measures that are corrected or uncorrected for sampling error---the corrected variance-accounted-for effect size metric of partial $\upomega^2$ was chosen because of three desirable properties. First, partial $\upomega^2$ provides a less biased estimate of effect size than other variance-accounted-for measures [@okada2013]. Second, partial $\upomega^2$ is more robust to assumption violations of normality and homogeneity of variance [@yigit2018]. Given that parameter estimates were often non-normally distributed within cells, effect size values computed with partial $\upomega^2$ should be relatively less biased than other variance-accounted-for effect size metrics (e.g., $\eta^2$). Third, partial $\upomega^2$ provides an effect size estimate that is not diluted by the inclusion of unaccountable variance in the denominator. To compute partial $\upomega^2$ value for each experimental effect, Equation \ref{eq:partial-omega} shown below was used:

```{=tex}
\begin{align}
\text{partial } \upomega^2 = \frac{\sigma^2_{effect}}{\sigma^2_{effect} + MSE} 
(\#eq:partial-omega)
\end{align}
```
\noindent where $\sigma^2_{effect}$ represents the variance accounted for by an effect and $MSE$ is the mean squared error. Importantly, $\sigma^2_{effect}$ values were corrected for sampling error as shown below in Equation \ref{eq:var-effect} for a two-way factorial design with fixed variables [@howell2009, Chapter 13]:

```{=tex}
\begin{align}
 \sigma^2_{effect} = \frac{(df_{effect} - 1)(MS_{effect} - MS_{error})}{nab},
(\#eq:var-effect)
\end{align}
```
\noindent where $df_{effect}$ is the degrees of freedom for the effect, $a$ is the number of levels of the first independent variable, $b$ is the number of levels in the second independent variable, and $n$ is the cell size. The variance accounted for by the interaction was computed using the following formula in Equation \ref{eq:var-interac}:

```{=tex}
\begin{align}
 \sigma^2_{A x B} = \frac{(a - 1)(b-1)(MS_{AxB} - MS_{error})}{nab}. 
(\#eq:var-interac)
\end{align}
```

\noindent For computing partial $\upomega^2$ for a three-way factorial design with fixed variables, I used the following equations for the main effects (Equation \ref{eq:main-effect-three}), two-way interactions (Equation \ref{eq:two-way-three}), and three-way interactions (Equation \ref{eq:three-way-three}): 

```{=tex}
\begin{align}
 \sigma^2_{effect} = \frac{(df_{effect} - 1)(MS_{effect} - MS_{error})}{nabc},
(\#eq:main-effect-three) \\ 
 \sigma^2_{A x B} = \frac{(a - 1)(b-1)(MS_{AxB} - MS_{error})}{nabc}, \text{ and } 
(\#eq:two-way-three) \\
 \sigma^2_{A x B x C} = \frac{(a - 1)(b-1)(c-1)(MS_{AxB} - MS_{error})}{nabc}, 
(\#eq:three-way-three)
\end{align}
```

\noindent where $c$ represents the number of levels for the third independent variable. The three-way design partial $\upomega^2$ values are provided in Appendix \ref{omega-three-way}. 

To compute partial $\upomega^2$ values for effects, a Brown--Forsythe test was computed and the appropriate sum-of-squares terms were used to compute partial $\upomega^2$ values. A Brown-Forsythe test was used to protect against the biasing effects of skewed distributions [@brown1974], which were observed in the parameter estimate distributions in the current simulation experiments. To compute the Brown-Forsythe test, median absolute deviations in each cell were computed by calculating the absolute difference between each $i$ estimate and the median estimated value in the given experimental cell as shown in Equation \ref{eq:brown-forsythe} below:

```{=tex}
\begin{align}
\text{Median absolute deviation}_i = \lvert \text{Parameter estimate}_i - \text{Median parameter estimate}_{cell} \rvert.
(\#eq:brown-forsythe)
\end{align}
```
\noindent An ANOVA was then computed on the median absolute deviation values (using the independent variables of the experiment and the associated interactions as predictors), with the terms in Equation \ref{eq:partial-omega} extracted from the ANOVA output to compute the partial $\upomega^2$ values.

## Results and Discussion

In the sections that follow, I organize the results by presenting them for each spacing schedule (equal, time-interval increasing, time-interval decreasing, middle-and-extreme). The results are presented for each spacing schedule because answering my research questions first requires knowledge of these results. To answer my first question of whether model performance increases from placing measurements during periods of change, I need to determine whether model performance under each spacing schedule increases when measurements are placed near periods of change. To answer my second question of how to space measurements when the nature of change is unknown, model performance across all manipulated nature-of-change values must first be calculated for each spacing schedule. The spacing schedule that obtains the highest model performance across all nature-of-change values can then be determined as the best schedule to use.

For each spacing schedule, I will first present a concise summary table of the results and then provide a detailed report for each column of the summary table. Because the detailed reports are of considerable length, I provide concise summaries before the detailed reports to establish a framework to help interpret the detailed reports. The detailed report of each spacing schedule presents the results of each day-unit's bias/precision plot, model performance under each nature-of-change value, and then provides a qualitative summary. After providing the results for each spacing schedule, I then use the results to answer my research questions.

### Framework for Interpreting Results

To conduct Experiment 1, the three variables of number of measurements (4 levels), measurement spacing (4 levels), and nature of change (3 levels) were manipulated, which yielded a total of 48 cells. Importantly, within each cell, bias and precision values were also computed for each of the nine parameters estimated by the structured latent growth curve model (for a review, see [modelling of each generated data set](#modelling-data-sets)). Thus, because the analysis of Experiment 1 computed values for many dependent variables, interpreting the results can become overwhelming. Therefore, I will provide a framework to help the reader efficiently navigate the results section.

Because I will present the results of Experiment 1 by each level of measurement spacing, the framework I will describe in Figure \ref{fig:results-plot-primer} shows a template for the bias/precision plots that I will present for each spacing schedule. The results of each spacing schedule contain a bias/precision plot for each of the nine estimated parameters. Each bias/precision plot shows the bias and precision for the estimation of one parameter across all measurement number and nature-of change levels. Within each bias/precision plot, dots indicate the average estimated value (which indicates bias bias) and error bars represent the middle 95% range of estimated values (which indicates precision). Bias/precision plots with black outlines show the results for day-unit parameters and plots with gray outlines show the results for Likert-unit parameters. Importantly, only the results for the day-unit parameters will be presented (i.e., fixed- and random-effect days-to-halfway elevation and triquarter-halfway delta parameters [$\upbeta_{fixed}$, $\upbeta_{random}$, $\upgamma_{fixed}$, $\upgamma_{random}$, respectively]). The results for the Likert-unit parameters (i.e., fixed- and random-effect baseline and maximal elevation parameters [$\uptheta_{fixed}$, $\uptheta_{random}$, $\upalpha_{fixed}$, $\upalpha_{random}$, respectively]) were largely trivial and so are presented in Appendix \ref{complete-versions}. Therefore, the results of each spacing schedule will only present the bias/precision plots for four parameters (i.e., the day-unit parameters).

### Pre-Processing of Data and Model Convergence

After collecting the output from the simulations, non-converged models (and their corresponding parameter estimates) were removed from subsequent analyses. Table \ref{tab:conv-exp-1} in Appendix \ref{convergence-tables} provides the convergence success rates for each cell in Experiment 1. Model convergence was almost always above 90% and convergence rates, with rates only going below 90% in two cells (or instances) with five measurements. 

### Equal Spacing {#concise-tab}

For equal spacing, Table \ref{tab:summary-table-equal-spacing-exp1} provides a concise summary of the results for the day-unit parameters (see Figure \ref{fig:exp1_plot_equal} for the corresponding bias/precision plots). The sections that follow will present the results for each column of Table \ref{tab:summary-table-equal-spacing-exp1} and provide elaboration when necessary.


```{=tex}
\begin{apaFigure}
[portrait]
[samepage]
[-0.2cm]
{Set of Bias/Precision Plots Constructed for Each Spacing Schedule in Experiment 1}
{results-plot-primer}
{.95}
{Figures/logistic_results_plot_exp1}
{A bias/precision plot is constructed for each parameter of the logistic function (see Equation \ref{eq:logFunction-generation}). Bias/precision plots with black borders show the results for day-unit parameters and plots with gray border show the results for Likert-unit parameters. For each parameter, bias and precision are shown across each combination of measurement number and nature of change.}\end{apaFigure}
```



Before presenting the results for equal spacing, I provide a brief description of the concise summary table created for each spacing schedule and shown for equal spacing below in Table \ref{tab:summary-table-equal-spacing-exp1}. Text within the 'Highest Model Performance' column indicates the nature-of-change value that resulted in the highest model performance for each day-unit parameter. Text within the 'Unbiased' and 'Precise' columns indicates the number of measurements that were needed to, respectively, obtain unbiased and precise parameter estimation across all manipulated nature-of-change values. Emboldened text in the 'Unbiased' and 'Qualitative Description' columns indicates the measurement number that, respectively, resulted in unbiased estimation and the greatest improvements in bias and precision across all day-unit parameters and manipulated nature-of-change values. The 'Error Bar Length' column indicates the average error bar length across all manipulated nature-of-change values that resulted from using the measurement number listed in the 'Qualitative Description' column.

#### Nature of Change That Leads to the Highest Model Performance {#nature-change-equal-exp1}

For equal spacing, Table \ref{tab:errorbar-equal-nc} lists the precision values (i.e., error bar lengths) for each day-unit parameter across each nature-of-change value. The 'Total' column indicates the total error bar length, which is a sum of the lower ('Lower') and upper ('Upper') whisker lengths. Given that the lower and upper whisker lengths were largely equivalent for each parameter, they were largely redundant and so were not reported for equal spacing. Although model performance was determined by bias and precision, results for bias were not reported because the differences in bias across the nature-of-change values were negligible. Note that error bar lengths were obtained by computing the average length across all manipulated number of measurements. The column shaded in gray


```{r summary-table-equal-spacing-exp1, echo=F}
errorbar_lengths <- compute_errorbar_lengths(exp_analytical_days = exp_1_analytical$days, iv_level = 'Equal spacing', num_measurements = 7)

summary_table <- data.frame('Parameter' = c('\\thead[lt]{$\\upbeta_{fixed}$ \\\\ (Figure \\ref{fig:exp1_plot_equal}A)}',
                                            '\\thead[lt]{$\\gamma_{fixed}$ \\\\ (Figure \\ref{fig:exp1_plot_equal}B)}', 
                                            '\\thead[lt]{$\\upbeta_{random}$ \\\\ (Figure \\ref{fig:exp1_plot_equal}C)}', 
                                            '\\thead[lt]{$\\upgamma_{random}$ \\\\ (Figure \\ref{fig:exp1_plot_equal}D)}'), 
                            
                            'Highest Model Performance' = rep(x = '$\\upbeta_{fixed}$ = 180', times = 4), 

                            
                            'Unbiased' = c('All cells', 
                                           'All cells', 
                                           'All cells', 
                                           '\\textbf{NM $\\boldsymbol{\\ge}$ 9}'), 
                            
                            'Precise' = c('All cells', 
                                            'No cells', 
                                            'No cells',
                                            'No cells'), 
                            

                            'Qualitative Description' = c('Largest improvements in precision with \\textbf{NM = 7}', 
                                                      'Largest improvements in precision with \\textbf{NM = 7}', 
                                                      'Largest improvements in precision with \\textbf{NM = 7}', 
                                                      'Largest improvements in bias and precision with \\textbf{NM = 7}'),
                            'Error Bar Length' = errorbar_lengths$errorbar_length, 
                            
                            check.names = F)

kbl(x = summary_table, format = 'latex',
       longtable = T, booktabs = T, centering = T, escape = F,
       align = c('l', 'c', 'c', 'c', 'l', 'c'), 
    linesep = rep('\\cmidrule{1-6}', times  = nrow(summary_table) - 1), 
    caption = 'Concise Summary of Results for Equal Spacing in Experiment 1') %>%
    #header
  column_spec(column = 1, width = '2cm') %>%
  column_spec(column = 2, width = '5cm') %>%
  column_spec(column = 3, width = '2.5cm') %>%
  column_spec(column = 4, width = '3cm') %>%
  column_spec(column = 5, width = '6.5cm') %>%
  column_spec(column = 6, width = '3cm') %>%
  add_header_above(header = c(' ' = 4, 'Summary' = 2)) %>%
  footnote(escape = F, threeparttable = T, general_title = '',
           general = "\\\\textit{Note. }`Highest Model Performance' indicates the curve that resulted in the highest model performance (largely determined by precision; see \\\\hyperref[nature-change-equal-exp1]{nature of change}). Emboldened text in the `Unbiased' and `Qualitative Description' columns indicates the number of measurements that, respectively, resulted in unbiased estimation and the greatest improvements in bias and precision across all day-unit parameters (note that acceptable precision was not obtained in the estimation of all day-unit parameters with equal spacing). `Error Bar Length' indicates the average error bar length value across all nature-of-change values that resulted from using the measurement number in the `Qualitative Description' column. Parameter names and population values are as follows: $\\\\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter = \\{80, 180, 280\\}; $\\\\upgamma_{fixed}$ = fixed-effect triquarter-halfway delta parameter = 20; $\\\\upbeta_{random}$ = random-effect days-to-halfway elevation parameter = 10; $\\\\upgamma_{random}$ = random-effect triquarter-halfway delta parameter = 4. NM = number of measurements.") %>% 
  kable_styling(position = 'left') %>%
  landscape(margin = '2.54cm')

```

```{r errorbar-equal-nc, echo=F}
param_midpoint_equal <- exp_1_analytical$days %>%
  filter(str_detect(string = measurement_spacing, pattern = 'Equal')) %>%
  group_by(parameter, midpoint) %>%
  summarize(lower = mean(pop_value - lower_ci, digits = 2), 
            upper = mean(upper_ci - pop_value, digits= 2),
            total_length = mean(errorbar_length, digits = 2)) %>% 
            #bias = round(mean(estimate) - mean(pop_value), digits = 2)) %>%
  pivot_wider(names_from = midpoint, names_glue = "{midpoint}_{.value}",
    values_from = lower:total_length,
    names_vary = 'slowest')


param_midpoint_equal$parameter <- factor(
  x = c('\\thead[lt]{$\\upbeta_{fixed}$ \\\\ (Figure \\ref{fig:exp1_plot_equal}A)}', 
        '\\thead[lt]{$\\upgamma_{fixed}$ \\\\ (Figure \\ref{fig:exp1_plot_equal}B)}', 
        '\\thead[lt]{$\\upbeta_{random}$ \\\\ (Figure \\ref{fig:exp1_plot_equal}C)}', 
        '\\thead[lt]{$\\upgamma_{random}$ \\\\ (Figure \\ref{fig:exp1_plot_equal}D)}'))

param_midpoint_equal$`180_upper`<- c(as.character(round(param_midpoint_equal$`180_upper`[1:3], digits = 2)),
                                   paste(as.character(round(param_midpoint_equal$`180_upper`[4], digits = 2)), '\\textsuperscript{a}', sep = ''))


kbl(x = param_midpoint_equal, format = 'latex',digits = 2, 
       longtable = T, booktabs = T, centering = T, escape = F,
        align = c('l', rep('c', times = ncol(param_midpoint_equal) - 1)), 
    col.names = c('Parameter', rep(c('Lower', 'Upper', 'Total'), times = 3)), 
    
    caption = 'Error Bar Lengths Across Nature-of-Change Values Under Equal Spacing in Experiment 1') %>%
  
    add_header_above(header = c(' ' = 1, '80' = 3, '180' = 3, '280' = 3), escape = F) %>%
    add_header_above(header = c(' ' = 1, 'Population Value of $\\\\upbeta_{fixed}$' = 9), escape = F) %>%
  
    column_spec(column = 5:7, background = '#DFDEDE') %>%
    column_spec(column = 1, width = '3cm') %>%
  
  footnote(escape = F, threeparttable = T, general_title = '',
           general = "\\\\textit{Note. }`Total' indicates the total error bar length, which is a sum of the lower (`Lower') and upper (`Upper') whisker lengths. Parameter names and population values are as follows: $\\\\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter = \\{80, 180, 280\\}; $\\\\upgamma_{fixed}$ = fixed-effect triquarter-halfway delta parameter = 20; $\\\\upbeta_{random}$ = random-effect days-to-halfway elevation parameter = 10; $\\\\upgamma_{random}$ = random-effect triquarter-halfway delta parameter = 4. Note that error bar lengths were calculated by computing the average error bar length value across all number-of-measurement (NM) values (NM $\\\\in$ \\\\{5, 7, 9, 11\\\\}). Columns shaded in gray indicate the nature-of-change value that results in the shortest error bar and whisker lengths.", 
           alphabet_title = '',
           alphabet = 'Error bar length is longest in this case because of the existence of high-value outliers (see Figure \\\\ref{fig:density_gamma_equal}).') %>%
  kable_styling(position = 'left')
  
```

\noindent indicates the nature of change where precision was best (i.e., shortest error bar lengths), which occurred with a nature-of-change value of 180 across all day-unit parameters under equal spacing with one exception (see the 'Highest Model Performance' in Table \ref{tab:summary-table-equal-spacing-exp1}). Importantly, with a nature-of-change value of 180, measurements were taken closer to periods of change under equal spacing than with other nature-of-change values (see Figure \ref{fig:equal-spacing-nc}). Therefore, it appears that placing measurements closer to periods of change increased model performance with equal spacing. 

```{=tex}
\begin{apaFigure}
[portrait]
[samepage]
[0cm]
{Model Performance Status Across Nature-of-Change Values With Equal Spacing}
{equal-spacing-nc}
{0.25}
{Figures/midpoint_180_plot}
{Model performance was highest when measurements were taken closer to periods of greater change, which resulted with a nature-of-change value of 180 with equal spacing. Text prints error bar lengths that resulted when model performance was highest (see Table \ref{tab:errorbar-equal-nc}).}
\end{apaFigure}
```


To understand why precision for the random-effect triquarter-halfway elevation parameter ($\upgamma_{random}$) was worse with a nature-of-change value of 180, I looked at the distribution of estimated values. Figure \ref{fig:density_gamma_equal} shows the distribution of values (i.e., density plots) estimated for the random-effect triquarter-halfway elevation parameter ($\upgamma_{random}$) for each nature-of-change level with five measurements. Importantly, the error bars in the bias/precision plot of Figure \ref{fig:exp1_plot_equal}D with five measurements are created from the density plots shown in Figure \ref{fig:density_gamma_equal}. Panel A shows the density plot with a nature-of-change value of 80 ($\upbeta_{fixed}$ = 80). Panel B shows the density plot with a with a nature-of-change value of

```{=tex}
\begin{apaFigure}
[portrait]
[samepage]
[0cm]
{Density Plots of the Random-Effect Triquarter-Halfway Delta ($\upgamma_{random}$; Figure \ref{fig:exp1_plot_equal}D) With Equal Spacing in Experiment 1 (95\% Error Bars)}
{density_gamma_equal}
{0.16}
{Figures/density_plots_equal_gamma_exp1}
{Regions shaded in in gray represent the middle 95\% of estimated values and the width of the shaded regions is indicated by the length of the horizontal error bars. The error bar length if longest when the nature-of-change value is 180. $\upgamma_{random}$ = random-effect triquarter-halfway delta parameter, with population value of 4.00, NM = number of measurements.}
\end{apaFigure}
```

\noindent 180 ($\upbeta_{fixed}$ = 180). Panel C shows the density plot with a with a nature-of-change value of 280 ($\upbeta_{fixed}$ = 280). Regions shaded in gray represent the middle 95% of estimated values and the width of the shaded regions is indicated by the length of the horizontal error bars. As originally confirmed by Table \ref{tab:errorbar-equal-nc}, Figure \ref{fig:density_gamma_equal}B shows that precision was indeed worst (i.e., longer error bars) with a nature of change of 180. In looking across the density plots in Figure \ref{fig:density_gamma_equal}, precision was worst (i.e., longest error bars) for the random-effect triquarter-halfway parameter ($\upgamma_{random}$) with a nature-of-change value of 180 because of the existence of high-value outliers.

In summary, under equal spacing, model performance for all the day-unit parameters was greatest when the nature-of-change value set by the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$) had a value of 180. The one exception to this result was that model performance (as indicated by precision) was lower for the random-effect triquarter-halfway elevation parameter ($\upgamma_{random}$) with a nature-of-change value of 180 because of high-value outliers.


#### Bias {#bias-equal-exp1}

Before presenting the results for bias, I provide a description of the set of bias/precision plots shown in Figure \ref{fig:exp1_plot_equal} and in the results sections for the other spacing schedules in Experiment 1. Figure \ref{fig:exp1_plot_equal} shows the bias/precision plots for each day-unit parameter and Table \ref{tab:omega-exp1-equal} provides the partial $\upomega^2$ values for each independent variable of each day-unit parameter. In Figure \ref{fig:exp1_plot_equal}, blue horizontal lines indicate the population values for each parameter (with population values of $\upbeta_{fixed} \in$ {80, 180, 280}, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, and $\upgamma_{random}$ = 4.00). Gray bands indicate the $\pm 10\%$ margin of error for each

```{r plots-equal-exp1, include=F, eval=F}
generate_day_likert_facet_plot(analytical_data = exp_1_analytical, target_col = 'measurement_spacing', target_value = 'Equal spacing',
                                x_axis_name = expression("Nature of Change (Population Value Set for"~beta[fixed]~')'), 
                                x_axis_var = 'midpoint', exp_num = 'exp1_', beta_lower = -30, beta_upper = 25, beta_ticks = 5)
```

```{=tex}
\begin{apaFigure}
[portrait]
[samepage]
[0cm]
{Bias/Precision Plots for Day-Unit Parameters With Equal Spacing in Experiment 1}
{exp1_plot_equal}
{0.16}
{Figures/exp1_plot_days_equal spacing}
{Panel A: Bias/precision plot for the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$). Panel B: Bias/precision plot for the fixed-effect triquarter-halfway elevation parameter ($\upgamma_{fixed}$). Panel C: Bias/precision plot for the random-effect days-to-halfway elevation parameter ($\upbeta_{random}$). Panel D: Bias/precision plot for the random-effect triquarter-halfway elevation parameter ($\upgamma_{random}$). Blue horizontal lines in each panel represent the population value for each parameter. Population values for each day-unit parameter are as follows: $\upbeta_{fixed} \in$ {80, 180, 280}, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, $\upgamma_{random}$ = 4.00. Gray bands indicate the $\pm 10\%$ margin of error for each parameter and unfilled dots indicate cells with average parameter estimates outside of the margin or biased estimates. Error bars represent the middle 95\% of estimated values, with light blue error bars indicating imprecise estimation. I considered dots that fell outside the gray bands as biased and error bar lengths with at least one whisker length exceeding the 10\% cutoff (i.e., or longer than the portion of the gray band underlying the whisker) as imprecise. Note that random-effect parameter units are in standard deviation units. Importantly, across all nature-of-change values (i.e., population values used for $\upbeta_{fixed}$), the acceptable amount of bias and precision was based on a population value of 180. See Table \ref{tab:param-exp-1} for specific values estimated for each parameter and Table \ref{tab:omega-exp1-equal} for $\upomega^2$ effect size values.}
\end{apaFigure}
```

```{r omega-exp1-equal, echo=F}
print_bias_var_omega_table(exp_data = exp_1_raw, target_col = 'measurement_spacing', target_value = 'equal', 
ind_vars = c('number_measurements', 'midpoint'), 
ind_var_acronyms = c('NM', 'NC', 'NM x NC'), 
caption = 'Partial $\\upomega^2$ Values for Manipulated Variables With Equal Spacing in Experiment 1',
footnote = '\\\\textit{Note. }NM = number of measurements $\\\\in$ \\\\{5, 7, 9, 11\\\\}, NC = nature of change (population value set for $\\\\upbeta_{fixed}$ $\\\\in$ \\\\{80, 180, 280\\\\}), NM x NC = interaction between number of measurements and nature of change,
$\\\\upgamma_{fixed}$ = fixed-effect triquarter-halfway delta parameter, 
           $\\\\upbeta_{random}$ = random-effect days-to-halfway elevation parameter, and 
           $\\\\upgamma_{random}$ = random-effect triquarter-halfway delta parameter.', 
parameter_labels = c('$\\upbeta_{fixed}$ (Figure \\ref{fig:exp1_plot_equal}A)',
                     '$\\upbeta_{random}$ (Figure \\ref{fig:exp1_plot_equal}B)',
                     '$\\upgamma_{fixed}$ (Figure \\ref{fig:exp1_plot_equal}C)',
                     '$\\upgamma_{random}$ (Figure \\ref{fig:exp1_plot_equal}D)'))
```


\noindent parameter and unfilled dots indicate cells with average parameter estimates outside of the margin. Error bars represent the middle 95% of estimated values, with light blue error bars indicating imprecise estimation. I considered dots that fell outside the gray bands as biased and error bar lengths with at least one whisker length exceeding the 10% cutoff (i.e., or longer than the portion of the gray band underlying the whisker) as imprecise. Panels A--B show the bias/precision plots for the fixed- and random-effect days-to-halfway elevation parameters ($\upbeta_{fixed}$ and $\upbeta_{random}$, respectively). Panels C--D show the bias/precision plots for the fixed- and random-effect triquarter-halfway delta parameters ($\upgamma_{fixed}$ and $\upgamma_{random}$, respectively). Note that random-effect parameter units are in standard deviation units. Importantly, across all population values used for the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$), the acceptable amount of bias and precision was based on a population value of 180.

With respect to bias for equal spacing, estimates were biased (i.e., above the acceptable 10% cutoff) for each day-unit parameter in the following cells:

-   fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$; Figure \ref{fig:exp1_plot_equal}A): no cells.
-   fixed-effect triquarter-halfway delta parameter ($\upgamma_{fixed}$; Figure \ref{fig:exp1_plot_equal}B): no cells.
-   random-effect days-to-halfway elevation parameter ($\upbeta_{random}$; Figure \ref{fig:exp1_plot_equal}C): no cells.
-   random-effect triquarter-halfway elevation parameter ($\upgamma_{random}$; Figure \ref{fig:exp1_plot_equal}D): five measurements with all manipulated nature-of-change values and seven measurements with nature-of-change values of 180 and 280.

In summary, with equal spacing, estimation of all the day-unit parameters across all manipulated nature-of-change values was unbiased using nine or more measurements, which is indicated by the emboldened text in the 'Unbiased' column of Table \ref{tab:summary-table-equal-spacing-exp1}.



#### Precision {#precision-equal-exp1}

With respect to precision for equal spacing, estimates were imprecise (i.e., error bar length with at least one whisker length exceeding 10% of a parameter's population value) in the following cells for each day-unit parameter:

-   fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$; Figure \ref{fig:exp1_plot_equal}A): no cells.
-   fixed-effect triquarter-halfway delta parameter ($\upgamma_{fixed}$; Figure \ref{fig:exp1_plot_equal}B): all cells.
-   random-effect days-to-halfway elevation parameter ($\upbeta_{random}$; Figure \ref{fig:exp1_plot_equal}C): all cells.
-   random-effect triquarter-halfway delta parameter [$\upgamma_{random}$] in Figure \ref{fig:exp1_plot_equal}D): all cells.

In summary, with equal spacing, estimation across all manipulated nature-of-change values was only precise for the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$) with five or more measurements. No manipulated measurement number resulted in precise estimation of the fixed-effect triquarter-halfway delta parameter ($\upgamma_{fixed}$) or the random-effect day-unit parameters (see the 'Precise' column of Table \ref{tab:summary-table-equal-spacing-exp1}).


#### Qualitative Description {#qualitative-equal-exp1}

```{r echo=F}
errorbar_lengths <- compute_errorbar_lengths(exp_analytical_days = exp_1_analytical$days, iv_level = 'Equal spacing', num_measurements = 7)$errorbar_length
```

Although no manipulated measurement number resulted in precise estimation of all the day-unit parameters, the largest improvements in precision (and bias) resulted from using moderate measurements numbers. With respect to bias under equal spacing, the largest improvements in bias across all manipulated nature-of-change values resulted from using the following measurement numbers for the following day-unit parameters (note that only the random-effect triquarter halfway delta parameter [$\upgamma_{random}$] had instances of high bias):

-   random-effect triquarter-halfway delta parameters ($\upgamma_{random}$): seven measurements.

\noindent With respect to precision under equal spacing, the largest improvements precision in the estimation of all day-unit parameters (except the fixed-effect days-to-halfway elevation parameter [$\upbeta_{fixed}$]) were obtained with following measurement numbers:

-   fixed-effect triquarter-halfway delta parameter ($\upgamma_{fixed}$): seven measurements, which resulted in a maximum error bar length of `r errorbar_lengths[2]` days.
-   random-effect days-to-halfway elevation parameter ($\upbeta_{random}$): seven measurements, which resulted in a maximum error bar length of `r errorbar_lengths[3]` days.
-   random-effect triquarter-halfway delta parameter ($\upgamma_{random}$): seven measurements, which resulted in a maximum error bar length of `r errorbar_lengths[4]` days.

\noindent Therefore, for equal spacing, seven measurements led to the greatest improvements in bias and precision in the estimation of all day-unit parameters across all manipulated nature-of-change values (see the emboldened text in the 'Qualitative Description' column of Table \ref{tab:summary-table-equal-spacing-exp1}).

#### Summary of Results With Equal Spacing

In summarizing the results for equal spacing, model performance was highest across all day-unit parameters (with the random-effect days-to-halfway elevation parameter ($\upgamma_{random}$) being an exception) when measurements were placed closer to periods of change, which occurred with a nature-of-change value of 180 (see [highest model performance](#nature-change-equal-exp1)). Unbiased estimation of all the day-unit parameters across all manipulated nature-of-change values resulted from using nine or more measurements (see [bias](#bias-equal-exp1)). Precise estimation of all the day-unit parameters was never obtained with any manipulated measurement number (see [precision](#precision-equal-exp1)). Although it may be discouraging that no manipulated measurement number under equal spacing resulted in precise estimation of all the day-unit parameters, the largest improvements in precision (and bias) across all day-unit parameters were obtained with moderate measurement numbers. With equal spacing, the largest improvements in bias and precision in the estimation of all day-unit parameters across all manipulated nature-of-change values were obtained using seven measurements (see [Qualitative Description](#qualitative-equal-exp1)).


### Time-Interval Increasing Spacing

For time-interval increasing spacing, Table \ref{tab:summary-table-time-inc-exp1} provides a concise summary of the results for the day-unit parameters (see Figure \ref{fig:exp1_plot_time_inc} for the corresponding bias/precision plots). The sections that follow will present the results for each column of Table \ref{tab:summary-table-time-inc-exp1} and provide elaboration when necessary (for a description of Table \ref{tab:summary-table-time-inc-exp1}, see [concise summary](#concise-tab)).

```{r summary-table-time-inc-exp1, echo=F}
errorbar_lengths_nm7 <- compute_errorbar_lengths(exp_analytical_days = exp_1_analytical$days, 
                                             iv_level = 'Time-interval increasing', num_measurements = 7)
errorbar_lengths_nm9 <- compute_errorbar_lengths(exp_analytical_days = exp_1_analytical$days, 
                                             iv_level = 'Time-interval increasing', num_measurements = 9)

errorbar_lengths <- c(errorbar_lengths_nm7$errorbar_length[1], errorbar_lengths_nm9$errorbar_length[2], 
                     errorbar_lengths_nm7$errorbar_length[3], errorbar_lengths_nm9$errorbar_length[4])


summary_table <- data.frame('Parameter' = c('\\thead[lt]{$\\upbeta_{fixed}$ \\\\ (Figure \\ref{fig:exp1_plot_time_inc}A)}',
                                            '\\thead[lt]{$\\gamma_{fixed}$ \\\\ (Figure \\ref{fig:exp1_plot_time_inc}B)}', 
                                            '\\thead[lt]{$\\upbeta_{random}$ \\\\ (Figure \\ref{fig:exp1_plot_time_inc}C)}', 
                                            '\\thead[lt]{$\\upgamma_{random}$ \\\\ (Figure \\ref{fig:exp1_plot_time_inc}D)}'), 
                            
                              'Highest Model Performance' = rep(x = '$\\upbeta_{fixed}$ = 80', times = 4), 
                            
                            'Unbiased' = c('All cells', 
                                       'All cells', 
                                       'NM $\\ge$ 7', 
                                       '\\textbf{NM $\\ge$ 9}'), 
                            
                            'Precise' = c('NM $\\ge$ 7', 
                                           'No cells', 
                                           'No cells',
                                           'No cells'), 
                            
                            'Qualitative Description' = c('Largest improvement in precision with NM = 7', 
                                                      'Largest improvement in precision with \\textbf{NM = 9}', 
                                                      'Largest improvement in bias and precision with NM = 7', 
                                                     'Largest improvements in bias and precision with \\textbf{NM = 9}'), 
                            'Error Bar Length' = errorbar_lengths,
                            
                            check.names = F)

kbl(x = summary_table, format = 'latex',
       longtable = T, booktabs = T, centering = T, escape = F,
        linesep = rep('\\cmidrule{1-6}', times  = nrow(summary_table) - 1), 
    caption = 'Concise Summary of Results for Time-Interval Increasing Spacing in Experiment 1', 
    align = c('l','c', 'c', 'c', 'l', 'c')) %>%
   #header
   column_spec(column = 1, width = '2cm') %>%
  column_spec(column = 2, width = '5cm') %>%
  column_spec(column = 3, width = '2.5cm') %>%
  column_spec(column = 4, width = '3cm') %>%
  column_spec(column = 5, width = '6.5cm') %>%
  column_spec(column = 6, width = '3cm') %>%
  add_header_above(header = c(' ' = 4, 'Description' = 2)) %>%
  footnote(escape = F, threeparttable = T, general_title = '',
           general = "\\\\textit{Note. }`Highest Model Performance' indicates the curve that resulted in the highest model performance (largely determined by precision; see \\\\hyperref[nature-change-time-inc-exp1]{nature of change}). Emboldened text in the `Unbiased' and `Qualitative Description' columns indicates the number of measurements that, respectively, resulted in unbiased estimation and the greatest improvements in bias and precision across all day-unit parameters (note that acceptable precision was not obtained in the estimation of all day-unit parameters with time-interval increasing spacing). `Error Bar Length' indicates the average error bar length value across all nature-of-change values that resulted from using the measurement number in the `Qualitative Description' column. Parameter names and population values are as follows: $\\\\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter = \\{80, 180, 280\\}; $\\\\upgamma_{fixed}$ = fixed-effect triquarter-halfway delta parameter = 20; $\\\\upbeta_{random}$ = random-effect days-to-halfway elevation parameter = 10; $\\\\upgamma_{random}$ = random-effect triquarter-halfway delta parameter = 4. NM = number of measurements.") %>% 
  kable_styling(position = 'left') %>%
  landscape(margin = '2.54cm')
```

#### Nature of Change That Leads to the Highest Model Performance {#nature-change-time-inc-exp1}

For time-interval increasing spacing, Table \ref{tab:errorbar-time-inc-nc} lists the precision values (i.e., error bar lengths) for each day-unit parameter across each nature-of-change value. The 'Total' column indicates the total error bar length, which is a sum of the the lower ('Lower') and upper ('Upper') whisker lengths. Given that the lower and upper whisker lengths were largely equivalent for each parameter, they were largely redundant and so were not reported for the remainder of the results for time-interval increasing spacing. Although model performance was determined by bias and precision, results for bias were not reported because the differences in bias across the nature-of-change values were negligible. Note that error bar lengths were obtained by computing the average length across all manipulated number of measurements. The column shaded in gray indicates the nature of change where precision was best (i.e., shortest error bar lengths), which occurred with a nature-of-change value of 80 across all day-unit parameters under time-interval increasing spacing (see the 'Highest Model Performance' in Table \ref{tab:summary-table-time-inc-exp1}). Importantly, with a nature-of-change value of 80, measurements were taken closer to periods of change under time-interval increasing spacing than with other nature-of-change values (see Figure \ref{fig:time-inc-spacing-nc}). Therefore, it appears that placing measurements closer to periods of change increased model performance with time-interval increasing spacing. 

#### Bias {#bias-time-inc-exp1}

With respect to bias for time-interval increasing spacing, estimates were biased (i.e., above the acceptable 10% cutoff) for each day-unit parameter in the following cells:

-   fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$; Figure \ref{fig:exp1_plot_time_inc}A): no cells.

```{r errorbar-time-inc-nc, echo=F}
param_midpoint_time_inc <- exp_1_analytical$days %>%
  filter(str_detect(string = measurement_spacing, pattern = 'increasing')) %>%
  group_by(parameter, midpoint) %>%
  summarize(lower = mean(pop_value - lower_ci, digits = 2), 
            upper = mean(upper_ci - pop_value, digits= 2),
            total_length = mean(errorbar_length, digits = 2)) %>% 
            #bias = round(mean(estimate) - mean(pop_value), digits = 2)) %>%
  pivot_wider(names_from = midpoint, names_glue = "{midpoint}_{.value}",
    values_from = lower:total_length,
    names_vary = 'slowest')

param_midpoint_time_inc$parameter <- factor(
  x = c('\\thead[lt]{$\\upbeta_{fixed}$ \\\\ (Figure \\ref{fig:exp1_plot_time_inc}A)}', 
        '\\thead[lt]{$\\upgamma_{fixed}$ \\\\ (Figure \\ref{fig:exp1_plot_time_inc}B)}', 
        '\\thead[lt]{$\\upbeta_{random}$ \\\\ (Figure \\ref{fig:exp1_plot_time_inc}C)}', 
        '\\thead[lt]{$\\upgamma_{random}$ \\\\ (Figure \\ref{fig:exp1_plot_time_inc}D)}'))


kbl(x = param_midpoint_time_inc, format = 'latex',digits = 2, 
       longtable = T, booktabs = T, centering = T, escape = F,
        align = c('l', rep('c', times = ncol(param_midpoint_time_inc) - 1)), 
    col.names = c('Parameter', rep(c('Lower', 'Upper', 'Total'), times = 3)), 
    
    caption = 'Error Bar Lengths Across Nature-of-Change Values Under Time-Interval Increasing Spacing in Experiment 1') %>%
  
    add_header_above(header = c(' ' = 1, '80' = 3, '180' = 3, '280' = 3), escape = F) %>%
    add_header_above(header = c(' ' = 1, 'Population Value of $\\\\upbeta_{fixed}$' = 9), escape = F) %>%
  
    column_spec(column = 2:4, background = '#DFDEDE') %>%
    column_spec(column = 1, width = '3cm') %>%
  
  footnote(escape = F, threeparttable = T, general_title = '',
           general = "\\\\textit{Note. }`Total' indicates the total error bar length, which is a sum of the lower (`Lower') and upper (`Upper') whisker lengths. Parameter names and population values are as follows: $\\\\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter = \\{80, 180, 280\\}; $\\\\upgamma_{fixed}$ = fixed-effect triquarter-halfway delta parameter = 20; $\\\\upbeta_{random}$ = random-effect days-to-halfway elevation parameter = 10; $\\\\upgamma_{random}$ = random-effect triquarter-halfway delta parameter = 4. Note that error bar lengths were calculated by computing the average error bar length value across all number-of-measurement (NM) values (NM $\\\\in$ \\\\{5, 7, 9, 11\\\\}). Columns shaded in gray indicate the nature-of-change value that results in the shortest error bar and whisker lengths.") %>%
  kable_styling(position = 'left')
```


-   fixed-effect triquarter-halfway delta parameter ($\upgamma_{fixed}$; Figure \ref{fig:exp1_plot_time_inc}B): no cells
-   random-effect days-to-halfway elevation parameter ($\upbeta_{random}$; Figure \ref{fig:exp1_plot_time_inc}C): five measurements with a nature-of-change value of 280.
-   random-effect days-to-halfway elevation parameter ($\upbeta_{random}$; Figure \ref{fig:exp1_plot_time_inc}C): five measurements with all nature-of-change values and seven measurements with nature-of-change values of 180 and 280.

In summary, with time-interval increasing spacing, estimation of all the day-unit

```{=tex}
\begin{apaFigure}
[portrait]
[samepage]
[0cm]
{Model Performance Status Across Nature-of-Change Values With Time-Interval Increasing Spacing}
{time-inc-spacing-nc}
{0.25}
{Figures/midpoint_80_plot}
{Model performance was highest when measurements were taken closer to periods of greater change, which resulted with a nature-of-change value of 80 with equal spacing. Text prints error bar lengths that resulted when model performance was highest (see Table \ref{tab:errorbar-time-inc-nc}).}
\end{apaFigure}
```


\noindent parameters across all manipulated nature-of-change values was unbiased using nine or more measurements, which is indicated by the emboldened text in the 'Unbiased' column of Table \ref{tab:summary-table-time-inc-exp1}.

#### Precision {#precision-time-inc-exp1}

With respect to precision for time-interval increasing spacing, estimates were imprecise (i.e., error bar length with at least one whisker length exceeding 10% of a parameter's population value) in the following cells for each day-unit parameter:

```{=tex}
\begin{apaFigure}
[portrait] %orientation (portrait or landscape)
[samepage] 
[-0.2cm] %spacing between bottom of figure and footnote
{Bias/Precision Plots for Day-Unit Parameters With Time-Interval Increasing Spacing in Experiment 1} %figure title 
{exp1_plot_time_inc} %figure label 
{0.16} %scaling factor: modifying height and width together 
{Figures/exp1_plot_days_time-interval increasing} %location of where to get figure 
{Panel A: Bias/precision plot for the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$). Panel B: Bias/precision plot for the fixed-effect triquarter-halfway elevation parameter ($\upgamma_{fixed}$). Panel C: Bias/precision plot for the random-effect days-to-halfway elevation parameter ($\upbeta_{random}$). Panel D: Bias/precision plot for the random-effect triquarter-halfway elevation parameter ($\upgamma_{random}$). Blue horizontal lines in each panel represent the population value for each parameter. Population values for each day-unit parameter are as follows: $\upbeta_{fixed} \in$ {80.00, 180.00, 280.00}, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, $\upgamma_{random}$ = 4.00. Gray bands indicate the $\pm 10\%$ margin of error for each parameter and unfilled dots indicate cells with average parameter estimates outside of the margin or biased estimates. Error bars represent the middle 95\% of estimated values, with light blue error bars indicating imprecise estimation. I considered dots that fell outside the gray bands as biased and error bar lengths with at least one whisker length exceeding the 10\% cutoff (i.e., or longer than the portion of the gray band underlying the whisker) as imprecise. Note that random-effect parameter units are in standard deviation units. Importantly, across all nature-of-change values (i.e., population values used for $\upbeta_{fixed}$), the acceptable amount of bias and precision was based on a population value of 180. See Table \ref{tab:param-exp-1} for specific values estimated for each parameter and Table \ref{tab:omega-exp1-time-inc} for $\upomega^2$ effect size values.}
\end{apaFigure}
```
```{r omega-exp1-time-inc, echo=F}
print_bias_var_omega_table(exp_data = exp_1_raw, target_col = 'measurement_spacing', target_value = 'time_inc', 
ind_vars = c('number_measurements', 'midpoint'), 
ind_var_acronyms = c('NM', 'NC', 'NM x NC'), 
caption = 'Partial $\\upomega^2$ Values for Manipulated Variables With Time-Interval Decreasing Spacing in Experiment 1',
footnote = '\\\\textit{Note. }NM = number of measurements $\\\\in$ \\\\{5, 7, 9, 11\\\\}, NC = nature of change (population value set for $\\\\upbeta_{fixed}$ $\\\\in$ \\\\{80, 180, 280\\\\}), NM x NC = interaction between number of measurements and nature of change,
           $\\\\upgamma_{fixed}$ = fixed-effect triquarter-halfway delta parameter, 
           $\\\\upbeta_{random}$ = random-effect days-to-halfway elevation parameter, and 
           $\\\\upgamma_{random}$ = random-effect triquarter-halfway delta parameter.', 
parameter_labels = c('$\\upbeta_{fixed}$ (Figure \\ref{fig:exp1_plot_time_inc}A)',
                     '$\\upbeta_{random}$ (Figure \\ref{fig:exp1_plot_time_inc}B)',
                     '$\\upgamma_{fixed}$ (Figure \\ref{fig:exp1_plot_time_inc}C)',
                     '$\\upgamma_{random}$ (Figure \\ref{fig:exp1_plot_time_inc}D)'))
```


-   fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$; Figure \ref{fig:exp1_plot_time_inc}A): five measurements with nature-of-change values of 180 and 280.
-   fixed-effect triquarter-halfway delta parameter ($\upgamma_{fixed}$; Figure \ref{fig:exp1_plot_time_inc}B): all cells.
-   random-effect days-to-halfway elevation parameter ($\upbeta_{random}$; Figure \ref{fig:exp1_plot_time_inc}C): all cells.
-   random-effect triquarter-halfway delta parameter ($\upgamma_{random}$; Figure \ref{fig:exp1_plot_time_inc}D): all cells.

In summary, with time-interval increasing spacing, estimation across all manipulated nature-of-change values was only precise for the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$) with seven or more measurements. No manipulated measurement number resulted in precise estimation of the fixed-effect triquarter-halfway delta parameter ($\upgamma_{fixed}$) or the random-effect day-unit parameters (see the 'Precise' column of Table \ref{tab:summary-table-time-inc-exp1}).


```{r density-plot-functions, include=F, eval=F}
compute_ind_param_error_bar_range <- function(param_search_name, param_data) {
  
  #extract estimates from single parameter
  ind_param_data <-  param_data %>%
    filter(str_detect(string = param_data$parameter, pattern = param_search_name)) %>% 
    pull(estimate)
  
  param_range <- as.numeric(nonlinSimsAnalysis:::compute_middle_95_estimate(param_data = ind_param_data))
  
  return(param_range)
}

compute_80_ind_param_error_bar_range <- function(param_search_name, param_data) {
  
  #extract estimates from single parameter
  ind_param_data <-  param_data %>%
    filter(str_detect(string = param_data$parameter, pattern = param_search_name)) %>% 
    pull(estimate)
  
  param_range <- as.numeric(compute_middle_80_estimate(param_data = ind_param_data))
  
  return(param_range)
}

compute_90_ind_param_error_bar_range <- function(param_search_name, param_data) {
  
  #extract estimates from single parameter
  ind_param_data <-  param_data %>%
    filter(str_detect(string = param_data$parameter, pattern = param_search_name)) %>% 
    pull(estimate)
  
  param_range <- as.numeric(compute_middle_90_estimate(param_data = ind_param_data))
  
  return(param_range)
}

compute_density <- function(error_bar_range, group, param_name, density_data) { 
  
  density_data <- density_data[density_data$group == group , ]
  
  density_lower_x <- min(which(density_data$x >= error_bar_range[1]))
  density_upper_x <- max(which(density_data$x <= error_bar_range[2]))
  
  day_values <- density_data$x[density_lower_x:density_upper_x]
  
  
  density_df <- data.frame('parameter' = param_name,
                           'day_value' = day_values,
                           'probability' = density_data$y[density_lower_x:density_upper_x], 
                           'max_density_value' = max(density_data$y),
                           'lower_ci' = error_bar_range[1], 
                           'upper_ci' = error_bar_range[2])

    return(density_df)
}
```

```{r exp1-density-plot-time-inc, include=F, eval=F}
##generate figure showing density distributions if gamma_fixed at N = 500 and N = 1000 with middle 95% area shaded. Emphasize
##that longer error bars in  N = 1000 are likely a statistical artifact of the random number generating procedure. 
exp_1 <- read_csv('data/exp_1_data.csv') %>% filter(code == 0) #load data 
exp_1 <- nonlinSims:::convert_raw_var_to_sd(raw_data = exp_1) #var to sd conversion 

parameter_names <- c(bquote(expr = bold(A:~gamma[random]~(beta[fixed]~" = 280, 5 measurements"))),
                     bquote(expr =bold(B:~gamma[random]~(beta[fixed]~" = 280, 7 measurements"))))


parameter_names <- c(bquote(expr = bold(A:~beta[fixed]~(beta[fixed]~" = 280, 5 measurements"))))
                     
#1) Extract estimates for four parameter gamma_fixed and beta_rand when N =500 or 1000, num_measurements == 5, spacing == equal. 
##Convert to long format, with parameter name going into unique column and estimate becoming new column 
param_data <- exp_1 %>%
  filter(number_measurements == 5, measurement_spacing == 'time_inc', midpoint == 280, code == 0) %>%
  select(nonlinSimsAnalysis:::locate_ivs(exp_1),'gamma_fixed') %>%
  pivot_longer(cols = c(gamma_fixed), values_to = 'estimate') %>%
  unite(col = 'parameter', c(number_measurements,name))

#2) Replace parameter values with tag labels. 
param_data$parameter <- factor(param_data$parameter, 
                               levels = c("5_gamma_fixed"), 
                               labels = parameter_names)


base_density_plot <- ggplot(data = param_data, mapping = aes(x = estimate, group = parameter)) +
   geom_density(linewidth = 3) 

##create density data for each parameter 
density_data <- ggplot_build(plot = base_density_plot)$data[[1]]

param_search_names <- c("A\\:")

param_error_bar_ranges <- lapply(X = param_search_names, compute_ind_param_error_bar_range, param_data = param_data)
##create density data for each parameter 
plot_ready_data <- rbindlist(pmap(.l = list(error_bar_range = param_error_bar_ranges, 
               group = 1:length(param_error_bar_ranges), 
               param_name =  as.character(parameter_names)), .f = compute_density, density_data = density_data))

plot_ready_data$parameter <- factor(plot_ready_data$parameter)


point_data <- data.frame('estimate' = mean(param_data$estimate),
                         'prob' = 0.02504984)

biased_point_data <- data.frame('estimate' = 16.031588, 
                                'prob' = 0.02655413)

#3) Create base density plot so that density data can be created
base_density_plot <- ggplot(data = param_data, mapping = aes(x = estimate, group = parameter)) +
     #geom_area(data = plot_ready_data, mapping = aes(x = day_value, y = probability), 
     #       show.legend = 'bin',  fill="grey", alpha = 0.5, color = 'black', size = 1) + 

   #geom_rect(xmin = 18, xmax = 22, ymin = -0.05, ymax = max(plot_ready_data$max_density_value) + .01, fill = 'grey', alpha = 0.1) + 
   geom_segment(inherit.aes = F, aes(x = 20, y = 0, xend = 20, yend =  0.05733645), color = "blue", size = 2) + #
  geom_point(inherit.aes = F,data = point_data, mapping = aes(y = prob, x = estimate), size = 7, shape = 22, fill= 'black') + 
  geom_density(linewidth = 1) +
 geom_errorbarh(inherit.aes = F,
                 mapping = aes(xmin =mean(param_data$estimate), xmax = 20, 
                               y = 0.02504984 - 0.003), height = 0.0025, size = 1)

example_plot <- base_density_plot +
    scale_x_continuous(limits = c(0, 40), breaks = c(seq(from = 0, to = 40, by =10)), 
                       name = 'Value of Parameter Estimate') + 
  scale_y_continuous(name = 'Frequency',  breaks = NULL, expand = c(0, 0), limits = c(0, 0.07)) + 

  #shaded filling
   #error bar
  #geom_errorbarh(data = plot_ready_data, inherit.aes = F,
  #               mapping = aes(xmin = lower_ci, xmax = upper_ci, 
  #                             y = max_density_value + .01, height = 0.005), size = 1, color = 'black') + 
  # #vertical dashed lines for error bars
  # ##lower limit 
  # geom_segment(inherit.aes = F, data = plot_ready_data, x = plot_ready_data$lower_ci, xend = plot_ready_data$lower_ci,
  #              y = 0, yend = plot_ready_data$max_density_value + .007, linetype = 2, size = 1) +
  # ##upper limit
  # geom_segment(inherit.aes = F, data = plot_ready_data, x = plot_ready_data$upper_ci, xend = plot_ready_data$upper_ci,
  #              y = 0, yend = plot_ready_data$max_density_value + .007, linetype = 2, size = 1) +
  # 
    #facet_wrap(facets = ~ parameter, nrow = 2, ncol = 2) + 
    
#    facet_wrap_custom( ~ parameter, scales = "free", ncol = 1, nrow = 2 ,
#                                          dir = 'h', labeller = label_parsed,
#                                          scale_overrides = list(scale_override(1,
#                                                                                scale_y_continuous(name =  'Density #(proportion of estimates)',
#                                                                                                   breaks = seq(from #= 0, to = 0.60, by = 0.10),
#                                                                                                   limits = c(0, #0.60))),
#                                                                 scale_override(2, scale_y_continuous(name = #'Density (proportion of estimates)',
#                                                                                                   breaks = seq(from #= 0, to = 0.60, by = 0.10),
#                                                                                                   limits = c(0, #0.60))))) + 
    #plot aesthetics

    theme_classic() + 
    theme(
        #axis details
        axis.text = element_text(size = 14, color = 'black'),
        axis.title = element_text(size = 20, color = 'black'))
  

ggsave(filename = 'example_dist.png', plot = example_plot, width = 8, height = 6)

gamma_fixed_time_inc <- exp_1_analytical$days %>%
  filter(measurement_spacing == 'Time-interval increasing', parameter %in% 'bold(B:~gamma[fixed] ~ (`Triquarter-Halfway` ~ \"Delta\"))')

dodge_position <- position_dodge(width = 0.8)

gamma_fixed_time_inc_filtered <- gamma_fixed_time_inc 

bias_precision_plot <- ggplot(data = gamma_fixed_time_inc_filtered, 
                              mapping = aes(x = midpoint, y = estimate, 
                                                group = number_measurements, 
                                                shape = number_measurements, 
                                                linetype = number_measurements, 
                                                fill = precision_status)) +
  
    geom_hline(mapping = aes(yintercept = 20), color = 'gray', alpha = 0.43, size = 17) + 
    geom_hline(mapping = aes(yintercept = 20), color = 'blue', size = 2) +
      geom_errorbar(position = dodge_position, mapping  = aes(ymin = lower_ci, ymax = upper_ci, color = precision_status),
                  width = 0.4,lwd = 1) +
 geom_point(position = dodge_position, size = 7) + 
  # geom_line(size = 1,  position = dodge_position) +  
 scale_y_continuous(name = 'Value of Parameter Estimate', limits = c(0, 40), 
                    breaks = c(seq(from = 0, to = 40, by = 10), 18, 22))  +
  #labs(x = '') + 
   scale_x_discrete(name = expression("Nature of Change (Population Value Set for"~beta[fixed]~")"), drop = F) +
#expression("Nature of Change (Population Value Set for"~beta[fixed]~")")
  theme_classic(base_family = 'Helvetica') +
   scale_shape_manual(values=c(22,21,24,23),
                       guide  = guide_legend(override.aes = list(fill = c("black"))))+
      scale_linetype_manual( values = rev(c('dotted', 'dashed', 'longdash', 'solid'))) + 
    scale_fill_manual(name = 'Is Biased?',
                     values = c('white', 'black'),
                     labels = c('No', 'Yes'), drop = FALSE) +  #set drop =FALSE s that unused levels are included
  scale_color_manual(name = 'Is Precise?',
                      breaks = c("0", "1"),
                      values = c('black', '#8cb9e3')) + 

      theme(
        legend.position = 'none',
        #axis.text.x = element_blank(), 
        #axis details
        #axis.ticks.x = element_blank(), 
        axis.text = element_text(size = 14, color = 'black'),
        axis.title = element_text(size = 20, color = 'black'))

ggsave(filename = 'ex_bias_precision.png', plot = bias_precision_plot, width = 8, height = 6)

```

```{r exp1-density-plot-time-inc-fixed, include=F, eval=F}
param_error_bar_ranges <- lapply(X = param_search_names, compute_80_ind_param_error_bar_range, param_data = param_data)

#3) Create base density plot so that density data can be created
base_density_plot <- ggplot(data = param_data, mapping = aes(x = estimate, group = parameter)) +
   geom_density(size = 3) 

##create density data for each parameter 
plot_ready_data <- rbindlist(pmap(.l = list(error_bar_range = param_error_bar_ranges, 
               group = 1:length(param_error_bar_ranges), 
               param_name =  as.character(parameter_names)), .f = compute_density, density_data = density_data))
plot_ready_data$parameter <- factor(plot_ready_data$parameter)


time_inc_fixed_density <- base_density_plot +
    scale_x_continuous(limits = c(0, 30), breaks = seq(from = 0, to = 30, by = 5), 
                       name = 'Value of parameter estimate (days)') + 
  
  #shaded filling
      geom_area(data = plot_ready_data, mapping = aes(x = day_value, y = probability), 
                show.legend = 'bin',  fill="grey", alpha = 1, color = 'black', size = 3) + 
    #error bar
    geom_errorbarh(data = plot_ready_data, inherit.aes = F,
                   mapping = aes(xmin = lower_ci, xmax = upper_ci, 
                                 y = max_density_value, height = 0.05), size = 3) + 

    #vertical dashed lines for error bars
    ##lower limit 
    geom_segment(inherit.aes = F, data = plot_ready_data, x = plot_ready_data$lower_ci, xend = plot_ready_data$lower_ci,
                 y = 0, yend = plot_ready_data$max_density_value, linetype = 2, size = 2) +
    ##upper limit
    geom_segment(inherit.aes = F, data = plot_ready_data, x = plot_ready_data$upper_ci, xend = plot_ready_data$upper_ci,
                 y = 0, yend = plot_ready_data$max_density_value, linetype = 2, size = 2) +  
    
    #facet_wrap(facets = ~ parameter, nrow = 2, ncol = 2) + 
    
    facet_wrap_custom( ~ parameter, scales = "free", ncol = 1, nrow = 2 ,
                                          dir = 'h', labeller = label_parsed,
                                          scale_overrides = list(scale_override(1,
                                                                                scale_y_continuous(name =  'Density (proportion of estimates)',
                                                                                                   breaks = seq(from = 0, to = 0.60, by = 0.10),
                                                                                                   limits = c(0, .60))),
                                                                 scale_override(2, scale_y_continuous(name = 'Density (proportion of estimates)',
                                                                                                   breaks = seq(from = 0, to = 0.60, by = 0.10),
                                                                                                   limits = c(0, 0.60))))) + 
  
    #plot aesthetics
    theme_classic() +

    theme(
      #panel details
      strip.background = element_rect(fill = "white", color = "white"),
      #original text size = 60, 150 for pre-results figures
      strip.text.x = element_text(face = 'bold', hjust = 0, size = 55, margin = unit(c(t = 0, r = 6, b = 1, l = 0), "cm")),

      #axis details
      axis.text = element_text(size = 60, color = 'black'),
      axis.title = element_text(size = 70),
      axis.title.x.bottom = element_markdown(),
      axis.line = element_line(size = 2),
      axis.ticks.length.x = unit(x = 1, units = 'cm'),
      axis.title.x = element_text(margin = unit(c(3, 0, 0, 0), "cm")),
      axis.title.y = element_text(margin = unit(c(t = 0, r = 3, b = 0, l = 0), units = 'cm')),
      axis.ticks = element_line(size = 2, colour = 'black'),
      axis.ticks.length.y =  unit(x = 1, units = 'cm'),

      #panel details
      panel.spacing.y = unit(x = 4, units = 'cm'),
      panel.spacing.x = unit(x = 2, units = 'cm'))
  
  
  #create PDF of faceted plot
  set_panel_size(p = time_inc_fixed_density, height = unit(x = 28, units = 'cm'),
                 width = unit(x = 40, units = 'cm'),
                 file =  'Figures/density_plots_time_inc_exp1_fixed.pdf')

```




```{r plots-time-increasing-exp1, include=F, eval=F}
generate_day_likert_facet_plot(analytical_data = exp_1_analytical, target_col = 'measurement_spacing', target_value = 'Time-interval increasing',
                                x_axis_name = expression("Population Value Set for"~beta[fixed]), 
                                x_axis_var = 'midpoint', exp_num = 'exp1_', beta_lower = -60, beta_upper = 60, beta_ticks = 10)
```


#### Qualitative Description {#qualitative-time-inc-exp1}

```{r echo=F}
errorbar_lengths <- c(errorbar_lengths_nm7$errorbar_length[1], errorbar_lengths_nm9$errorbar_length[2], 
                     errorbar_lengths_nm7$errorbar_length[3], errorbar_lengths_nm9$errorbar_length[4])
```

For time-interval increasing spacing in Figure \ref{fig:exp1_plot_time_inc}, although no manipulated measurement number resulted in precise estimation of all the day-unit parameters, the largest improvements in precision (and bias) resulted from using moderate measurements numbers. With respect to bias under time-interval increasing spacing, the largest improvements across all manipulated nature-of-change values in bias occurred with the following measurement numbers for the random-effect day-unit parameters:

-   random-effect days-to-halfway elevation parameter ($\upbeta_{random}$): seven measurements.
-   random-effect triquarter-halfway delta parameters ($\upgamma_{random}$): nine measurements.

\noindent With respect to precision under time-interval increasing spacing, the largest improvements precision in the estimation of all day-unit parameters across all manipulated nature-of-change values resulted with the following measurement numbers:

-   fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$): seven measurements, which results in an average error bar length of `r errorbar_lengths[1]` days.
-   fixed-effect triquarter-halfway delta parameter ($\upgamma_{fixed}$): nine measurements, which results in an average error bar length of `r errorbar_lengths[2]` days.
-   random-effect days-to-halfway elevation parameter ($\upbeta_{random}$): nine measurements, which results in an average error bar length of `r errorbar_lengths[3]` days.
-   random-effect triquarter-halfway delta parameter ($\upgamma_{random}$): nine measurements, which results in an average error bar length of `r errorbar_lengths[4]` days.

\noindent Therefore, for time-interval increasing spacing, nine measurements resulted in the greatest improvements in bias and precision in the estimation of all day-unit parameters across all manipulated nature-of-change values (see the 'Qualitative Description\` column in Table \ref{tab:summary-table-time-inc-exp1}).

#### Summary of Results With Time-Interval Increasing Spacing

In summarizing the results for time-interval increasing spacing, model performance was highest across all day-unit parameters when measurements were placed closer to periods of change, which occurred with a nature-of-change value of 80 ($\upbeta_{fixed}$ = 80; see [highest model performance](#nature-change-time-inc-exp1)). Estimation of all day-unit parameters was unbiased across all manipulated nature-of-change values using nine or more measurements (see [bias](#bias-time-inc-exp1)). Precise estimation was never obtained in the estimation of all day-unit parameters with any manipulated measurement (see [precision](#precision-time-inc-exp1)). Although it may be discouraging that no manipulated measurement number under time-interval increasing spacing resulted in precise estimation of all the day-unit parameters, the largest improvements in precision (and bias) across all day-unit parameters were obtained with moderate measurement numbers. With time-interval increasing spacing, the largest improvements in bias and precision in the estimation of all day-unit parameters across all manipulated nature-of-change values resulted from using nine measurements (see [qualitative description](#qualitative-time-inc-exp1)).

### Time-Interval Decreasing Spacing

For time-interval decreasing spacing, Table \ref{tab:summary-table-time-dec-exp1} provides a concise summary of the results for the day-unit parameters (see Figure \ref{fig:exp1_plot_time_dec} for the corresponding bias/precision plots). The sections that follow will present the results for each column of Table \ref{tab:summary-table-time-dec-exp1} and provide elaboration when necessary (for a description of Table \ref{tab:summary-table-time-dec-exp1}, see [concise summary table](#concise-tab)).

```{r summary-table-time-dec-exp1, echo=F}
errorbar_lengths_nm7 <- compute_errorbar_lengths(exp_analytical_days = exp_1_analytical$days, iv_level = 'Time-interval decreasing', num_measurements = 7)
errorbar_lengths_nm9 <- compute_errorbar_lengths(exp_analytical_days = exp_1_analytical$days, iv_level = 'Time-interval decreasing', num_measurements = 9)

errorbar_lengths <- errorbar_lengths_nm9$errorbar_length

summary_table <- data.frame('Parameter' = c('\\thead[lt]{$\\upbeta_{fixed}$ \\\\ (Figure \\ref{fig:exp1_plot_time_dec}A)}',
                                            '\\thead[lt]{$\\gamma_{fixed}$ \\\\ (Figure \\ref{fig:exp1_plot_time_dec}B)}', 
                                            '\\thead[lt]{$\\upbeta_{random}$ \\\\ (Figure \\ref{fig:exp1_plot_time_dec}C)}', 
                                            '\\thead[lt]{$\\upgamma_{random}$ \\\\ (Figure \\ref{fig:exp1_plot_time_dec}D)}'), 
                            
                            'Highest Model Performance' = rep(x = '$\\upbeta_{fixed}$ = 280', times = 4),

                            'Unbiased' = c('All cells', 
                                       'NM $\\ge$ 7', 
                                       'NM $\\ge$ 7', 
                                       '\\textbf{NM $\\boldsymbol{\\ge}$ 9}'), 
                            
                            'Precise' = c('NM $\\ge$ 9', 
                                           'No cells', 
                                           'No cells',
                                           'No cells'), 
                            

                            'Qualitative Description' = c('Largest improvements in precision with \\textbf{NM = 9}', 
                                                      'Largest improvement in precision with \\textbf{NM = 9}', 
                                                      'Largest improvement in bias and precision with \\textbf{NM = 9}', 
                                                      'Largest improvements in bias and precision with \\textbf{NM = 9}'), 
                            'Error Bar Length' = errorbar_lengths,
                            
                            check.names = F)

kbl(x = summary_table, format = 'latex',
       longtable = T, booktabs = T, centering = T, escape = F,
        linesep = rep('\\cmidrule{1-6}', times  = nrow(summary_table) - 1), 
    caption = 'Concise Summary of Results for Time-Interval Decreasing Spacing in Experiment 1', 
 align = c('l', 'c', 'c', 'c', 'l', 'c')) %>%
     #header
   column_spec(column = 1, width = '2cm') %>%
  column_spec(column = 2, width = '5cm') %>%
  column_spec(column = 3, width = '2.5cm') %>%
  column_spec(column = 4, width = '3cm') %>%
  column_spec(column = 5, width = '6.5cm') %>%
  column_spec(column = 6, width = '3cm') %>%
  add_header_above(header = c(' ' = 4, 'Description' = 2)) %>%
  footnote(escape = F, threeparttable = T, general_title = '',
           general = "\\\\textit{Note. }`Highest Model Performance' indicates the curve that resulted in the highest model performance (largely determined by precision; see \\\\hyperref[nature-change-time-dec-exp1]{nature of change}). Emboldened text in the `Unbiased' and `Qualitative Description' columns indicates the number of measurements that, respectively, resulted in unbiased estimation and the greatest improvements in bias and precision across all day-unit parameters (note that acceptable precision was not obtained in the estimation of all day-unit parameters with time-interval decreasing spacing). `Error Bar Length' indicates the average error bar length value across all nature-of-change values that resulted from using the measurement number in the `Qualitative Description' column. Parameter names and population values are as follows: $\\\\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter = \\{80, 180, 280\\}; $\\\\upgamma_{fixed}$ = fixed-effect triquarter-halfway delta parameter = 20; $\\\\upbeta_{random}$ = random-effect days-to-halfway elevation parameter = 10; $\\\\upgamma_{random}$ = random-effect triquarter-halfway delta parameter = 4. NM = number of measurements.") %>% 
  kable_styling(position = 'left') %>%
  landscape(margin = '2.54cm')
```


#### Nature of Change That Leads to the Highest Model Performance {#nature-change-time-dec-exp1}

For time-interval decreasing spacing, Table \ref{tab:errorbar-time-dec-nc} lists the error bar lengths for each day-unit parameter and nature-of-change value. The 'Total' column indicates the total error bar length, which is a sum of the the lower ('Lower') and upper ('Upper') whisker lengths. Given that the lower and upper whisker lengths were largely equivalent for each parameter, they were largely redundant and so were not reported for the remainder of the results for time-interval decreasing spacing. Although model performance was determined by bias and precision, results for bias were not computed because the differences in bias across the nature-of-change values were negligible. Note that error bar lengths were obtained by computing the average length across all manipulated measurement number values. The column shaded in gray indicates the nature of change where precision was best (i.e., shortest error bar lengths), which occurred with a nature-of-change value of 280 across all day-unit parameters under time-interval decreasing spacing (see the 'Highest Model Performance' in Table \ref{tab:summary-table-time-dec-exp1}). Importantly, with a nature-of-change value of 280, measurements were taken closer to periods of change under time-interval decreasing spacing than with other nature-of-change values (see Figure \ref{fig:time-dec-spacing-nc}). Therefore, it appears that placing measurements closer to periods of change increased model performance with time-interval decreasing spacing. 

#### Bias {#bias-time-dec-exp1}

With respect to bias for time-interval decreasing spacing, estimates were biased (i.e., above the acceptable 10% cutoff) for each day-unit parameter in the following cells:

-   fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$; Figure \ref{fig:exp1_plot_time_dec}A): no cells.
-   fixed-effect triquarter-halfway delta parameter ($\upgamma_{fixed}$; Figure \ref{fig:exp1_plot_time_dec}B): five 

```{r errorbar-time-dec-nc, echo=F}
param_midpoint_time_dec <- exp_1_analytical$days %>%
  filter(str_detect(string = measurement_spacing, pattern = 'decreasing')) %>%
  group_by(parameter, midpoint) %>%
  summarize(
            lower = mean(pop_value - lower_ci, digits = 2), 
            upper = mean(upper_ci - pop_value, digits= 2),
   total_length = mean(errorbar_length, digits = 2)) %>% 
            #bias = round(mean(estimate) - mean(pop_value), digits = 2)) %>%
  pivot_wider(names_from = midpoint, names_glue = "{midpoint}_{.value}",
    values_from = lower:total_length,
    names_vary = 'slowest')


param_midpoint_time_dec$parameter <- factor(x = c('$\\upbeta_{fixed}$ (Figure \\ref{fig:exp1_plot_time_dec}A)', 
                                        '$\\upgamma_{fixed}$ (Figure \\ref{fig:exp1_plot_time_dec}B)', 
                                        '$\\upbeta_{random}$ (Figure \\ref{fig:exp1_plot_time_dec}C)', 
                                       '$\\upgamma_{random}$ (Figure \\ref{fig:exp1_plot_time_dec}D)'))



kbl(x = param_midpoint_time_dec, format = 'latex',digits = 2, 
       longtable = T, booktabs = T, centering = T, escape = F,
        align = c('l', rep('c', times = ncol(param_midpoint_equal) - 1)), 
    col.names = c('Parameter', rep(c('Lower', 'Upper', 'Total'), times = 3)), 
   
    caption = 'Error Bar Lengths Across Nature-of-Change Values Under Time-Interval Decreasing Spacing in Experiment 1') %>%
  
    #header
    add_header_above(header = c(' ' = 1, '80' = 3, '180' = 3, '280' = 3), escape = F) %>%
    add_header_above(header = c(' ' = 1, 'Population Value of $\\\\upbeta_{fixed}$' = 9), escape = F) %>%
  
    column_spec(column = 8:10, background = '#DFDEDE') %>%
    column_spec(column = 1, width = '3.5cm') %>%
   # column_spec(column = c(2:4), width = '3cm') %>%
  footnote(escape = F, threeparttable = T, general_title = '',
           general = "\\\\textit{Note. }Parameter names and population values are as follows: $\\\\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter = \\{80, 180, 280\\}; $\\\\upgamma_{fixed}$ = fixed-effect triquarter-halfway delta parameter = 20; $\\\\upbeta_{random}$ = random-effect days-to-halfway elevation parameter = 10; $\\\\upgamma_{random}$ = random-effect triquarter-halfway delta parameter = 4. Note that error bar lengths were calculated by computing the average error bar length value across all number-of-measurement (NM) values (NM $\\\\in$ \\\\{5, 7, 9, 11\\\\}). Columns shaded in gray indicate the nature-of-change value that results in the shortest error bar and whisker lengths.")%>%
  kable_styling(position = 'left')
```


measurements with a nature-of-change value of 80.

-   random-effect days-to-halfway elevation parameter ($\upbeta_{random}$; Figure \ref{fig:exp1_plot_time_dec}C): five measurements with a nature-of-change value of 80.
-   random-effect triquarter-halfway delta parameter ($\upgamma_{random}$; Figure \ref{fig:exp1_plot_time_dec}D): five measurements across all manipulated nature-of-change values and seven measurements with nature-of-change values of 80 and 180.

In summary, with time-interval decreasing spacing, unbiased estimation was obtained for all day-unit parameters across all manipulated nature-of-change values using nine or more measurements, which is indicated by the emboldened text in the 'Unbiased' column of Table \ref{tab:summary-table-time-dec-exp1}.

```{=tex}
\begin{apaFigure}
[portrait]
[samepage]
[0cm]
{Model Performance Status Across Nature-of-Change Values With Time-Interval Decreasing Spacing}
{time-dec-spacing-nc}
{0.25}
{Figures/midpoint_80_plot}
{Model performance was highest when measurements were taken closer to periods of greater change, which resulted with a nature-of-change value of 280 with equal spacing. Text prints error bar lengths that resulted when model performance was highest (see Table \ref{tab:errorbar-time-dec-nc}).}
\end{apaFigure}
```




#### Precision {#precision-time-dec-exp1}

With respect to precision for time-interval decreasing spacing, estimates were imprecise (i.e., error bar length with at least one whisker length exceeding 10% of a parameter's population value) in the following cells for each day-unit parameter:

-   fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$; Figure \ref{fig:exp1_plot_time_dec}A): five measurements with nature-of-change values of 80 and 180 an seven measurements with a nature-of-change value of 80.
-   fixed-effect triquarter-halfway delta parameter ($\upgamma_{fixed}$; Figure \ref{fig:exp1_plot_time_dec}B): all cells.

```{r plots-time-decreasing-exp1, include=F, eval=F}
generate_day_likert_facet_plot(analytical_data = exp_1_analytical, target_col = 'measurement_spacing', target_value = 'Time-interval decreasing',
                                x_axis_name = expression("Population Value Set for"~beta[fixed]),
                                x_axis_var = 'midpoint', exp_num = 'exp1_', beta_lower = -80, beta_upper = 60,  beta_ticks = 10)
```

```{=tex}
\begin{apaFigure}
[portrait]
[samepage]
[-0.2cm] %distance between bottom of figure and beggining of the note 
{Bias/Precision Plots for Day-Unit Parameters With Time-Interval Decreasing Spacing in Experiment 1} 
{exp1_plot_time_dec}
{0.16} %scaling factor 
{Figures/exp1_plot_days_time-interval decreasing} %path to figure 
{Panel A: Bias/precision plot for the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$). Panel B: Bias/precision plot for the fixed-effect triquarter-halfway elevation parameter ($\upgamma_{fixed}$). Panel C: Bias/precision plot for the random-effect days-to-halfway elevation parameter ($\upbeta_{random}$). Panel D: Bias/precision plot for the random-effect triquarter-halfway elevation parameter ($\upgamma_{random}$). Blue horizontal lines in each panel represent the population value for each parameter. Population values for each day-unit parameter are as follows: $\upbeta_{fixed} \in$ {80.00, 180.00, 280.00}, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, $\upgamma_{random}$ = 4.00. Gray bands indicate the $\pm 10\%$ margin of error for each parameter and unfilled dots indicate cells with average parameter estimates outside of the margin or biased estimates. Error bars represent the middle 95\% of estimated values, with light blue error bars indicating imprecise estimation. I considered dots that fell outside the gray bands as biased and error bar lengths with at least one whisker length exceeding the 10\% cutoff (i.e., or longer than the portion of the gray band underlying the whisker) as imprecise. Note that random-effect parameter units are in standard deviation units. Importantly, across all nature-of-change values (i.e., population values used for $\upbeta_{fixed}$), the acceptable amount of bias and precision was based on a population value of 180. See Table \ref{tab:param-exp-1} for specific values estimated for each parameter and Table \ref{tab:omega-exp1-time-dec} for $\upomega^2$ effect size values.}
\end{apaFigure}
```
```{r omega-exp1-time-dec, echo=F}
print_bias_var_omega_table(exp_data = exp_1_raw, target_col = 'measurement_spacing', target_value = 'time_dec', 
ind_vars = c('number_measurements', 'midpoint'), 
ind_var_acronyms = c('NM', 'NC', 'NM x NC'), 
caption = 'Partial $\\upomega^2$ Values for Manipulated Variables With Time-Interval Decreasing Spacing in Experiment 1',
footnote = '\\\\textit{Note. }NM = number of measurements $\\\\in$ \\\\{5, 7, 9, 11\\\\}, NC = nature of change (population value set for $\\\\upbeta_{fixed}$ $\\\\in$ \\\\{80, 180, 280\\\\}), NM x NC = interaction between number of measurements and nature of change,
           $\\\\upgamma_{fixed}$ = fixed-effect triquarter-halfway delta parameter, 
           $\\\\upbeta_{random}$ = random-effect days-to-halfway elevation parameter, and 
           $\\\\upgamma_{random}$ = random-effect triquarter-halfway delta parameter.', 
parameter_labels = c('$\\upbeta_{fixed}$ (Figure \\ref{fig:exp1_plot_time_dec}A)',
                     '$\\upbeta_{random}$ (Figure \\ref{fig:exp1_plot_time_dec}B)',
                     '$\\upgamma_{fixed}$ (Figure \\ref{fig:exp1_plot_time_dec}C)',
                     '$\\upgamma_{random}$ (Figure \\ref{fig:exp1_plot_time_dec}D)'))
```

-   random-effect days-to-halfway elevation parameter ($\upbeta_{random}$; Figure \ref{fig:exp1_plot_time_dec}C): all cells.
-   random-effect triquarter-halfway delta parameter ($\upgamma_{random}$; Figure \ref{fig:exp1_plot_time_dec}D): all cells.

In summary, with time-interval increasing spacing, estimation across all manipulated nature-of-change values was only precise for the estimation of the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$) with nine or more measurements. No manipulated measurement number resulted in precise estimation of the fixed-effect triquarter-halfway delta parameter ($\upgamma_{fixed}$) or the random-effect day-unit parameters (see the 'Precise' column of Table \ref{tab:summary-table-time-dec-exp1}).



#### Qualitative Description {#qualitative-time-dec-exp1}

```{r echo=F}
errorbar_lengths <- c(errorbar_lengths_nm7$errorbar_length[1], 
                      errorbar_lengths_nm9$errorbar_length[2], 
                      errorbar_lengths_nm7$errorbar_length[3], 
                      errorbar_lengths_nm9$errorbar_length[4])
```

For time-interval decreasing spacing in Figure \ref{fig:exp1_plot_time_dec}, although no manipulated measurement number resulted in precise estimation of all day-unit parameters, the largest improvements in precision (and bias) were obtained using moderate measurements numbers. With respect to bias under time-interval decreasing spacing, the largest improvements across all manipulated nature-of-change values in bias occurred with the following measurement numbers for the random-effect day-unit parameters:

-   random-effect days-to-halfway elevation parameter ($\upbeta_{random}$): seven measurements
-   random-effect triquarter-halfway delta parameters ($\upgamma_{random}$): nine measurements

\noindent With respect to precision under time-interval decreasing spacing, the largest improvements precision in the estimation of all day-unit parameters across all manipulated nature-of-change values were obtained with the following measurement numbers:

-   fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$): seven measurements, which results in a maximum error bar length of `r errorbar_lengths[1]` days.
-   fixed-effect triquarter-halfway delta parameter ($\upgamma_{fixed}$): nine measurements, which results in a maximum error bar length of `r errorbar_lengths[2]` days.
-   random-effect days-to-halfway elevation parameter ($\upbeta_{random}$): nine measurements, which results in a maximum error bar length of `r errorbar_lengths[3]` days.
-   random-effect triquarter-halfway delta parameter ($\upgamma_{random}$): nine measurements, which results in a maximum bar length of `r errorbar_lengths[4]` days.

\noindent Therefore, for time-interval decreasing spacing, nine measurements resulted in the greatest improvements in bias and precision in the estimation of all day-unit parameters across all manipulated nature-of-change values (see the emboldened text in the 'Qualitative Description' column in Table \ref{tab:summary-table-time-dec-exp1}).

#### Summary of Results Time-Interval Decreasing Spacing

In summarizing the results for time-interval decreasing spacing, model performance was highest across all day-unit parameters when measurements were placed closer to periods of change, which occurred with a nature-of-change value of 280 ($\upbeta_{fixed}$ = 280; see [highest model performance](#nature-change-time-dec-exp1)). Unbiased estimation of the day-unit parameters across all manipulated nature-of-change values resulted from using nine or more measurements (see [bias](#bias-time-dec-exp1)). Precise estimation of all the day-unit parameters was never obtained using any of the manipulated measurement numbers (see [precision](#precision-time-dec-exp1)). Although it may be discouraging that no manipulated measurement number under time-interval decreasing spacing resulted in precise estimation of all day-unit parameters, the largest improvements in precision (and bias) across all day-unit parameters were obtained with moderate measurement numbers. With time-interval decreasing spacing, the largest improvements in bias and precision in the estimation of all day-unit parameters across all manipulated nature-of-change values were obtained using nine measurements (see [qualitative description](#qualitative-time-inc-exp1)).

### Middle-and-Extreme Spacing

For middle-and-extreme spacing, Table \ref{tab:summary-table-mid-ext-exp1} provides a concise summary of the results for the day-unit parameters (see Figure \ref{fig:exp1_plot_time_mid_ext} for the corresponding bias/precision plots). The sections that follow will present the results for each column of Table \ref{tab:summary-table-mid-ext-exp1} and provide elaboration when necessary (for a description of Table \ref{tab:summary-table-mid-ext-exp1}, see [concise summary table](#concise-tab)).

```{r summary-table-mid-ext-exp1, echo=F}
errorbar_lengths_nm7 <- compute_errorbar_lengths(exp_analytical_days = exp_1_analytical$days, iv_level = 'Middle-and-extreme spacing', num_measurements = 7)
errorbar_lengths_nm9 <- compute_errorbar_lengths(exp_analytical_days = exp_1_analytical$days, iv_level = 'Middle-and-extreme spacing', num_measurements = 9)

errorbar_lengths <- c(errorbar_lengths_nm7$errorbar_length[1], 
                      errorbar_lengths_nm7$errorbar_length[2], 
                      errorbar_lengths_nm9$errorbar_length[3], 
                      errorbar_lengths_nm7$errorbar_length[4])

summary_table <- data.frame('Parameter' = c('\\thead[lt]{$\\upbeta_{fixed}$ \\\\ (Figure \\ref{fig:exp1_plot_time_mid_ext}A)}',
                                            '\\thead[lt]{$\\gamma_{fixed}$ \\\\ (Figure \\ref{fig:exp1_plot_time_mid_ext}B)}', 
                                            '\\thead[lt]{$\\upbeta_{random}$ \\\\ (Figure \\ref{fig:exp1_plot_time_mid_ext}C)}', 
                                            '\\thead[lt]{$\\upgamma_{random}$ \\\\ (Figure \\ref{fig:exp1_plot_time_mid_ext}D)}'), 
                            
                            'Highest Model Performance' = rep(x = '$\\upbeta_{fixed}$ = 180', times = 4),
                            
                            'Unbiased' = c('All cells', 
                                       'NM $\\ge$ 7',
                                       'NM $\\ge$ 9', 
                                       '\\textbf{NM = 11}'), 
                            
                            'Precise' = c('NM $\\ge$ 7', 
                                            'No cells', 
                                            'No cells',
                                            'No cells'), 
                            
                             
                            
                            'Qualitative Description' = c('Largest improvements in precision with NM = 7', 
                                                      'Largest improvements in bias and precision with NM = 7', 
                                                      'Largest improvements in bias and precision with \\textbf{NM = 9}', 
                                                      'Largest improvements in bias and precision with NM = 7'), 
                            
                            'Error Bar Length' = errorbar_lengths, 
                            
                            check.names = F)

kbl(x = summary_table, format = 'latex',
       longtable = T, booktabs = T, centering = T, escape = F,
        linesep = rep('\\cmidrule{1-6}', times  = nrow(summary_table) - 1), 
    caption = 'Concise Summary of Results for Middle-and-Extreme Spacing in Experiment 1', 
     align = c('l', 'c', 'c', 'c', 'l', 'c')) %>%
        #header
   column_spec(column = 1, width = '2cm') %>%
  column_spec(column = 2, width = '5cm') %>%
  column_spec(column = 3, width = '2.5cm') %>%
  column_spec(column = 4, width = '3cm') %>%
  column_spec(column = 5, width = '6.5cm') %>%
  column_spec(column = 6, width = '3cm') %>%
  add_header_above(header = c(' ' = 4, 'Description' = 2)) %>%
 footnote(escape = F, threeparttable = T, general_title = '',
           general = "\\\\textit{Note. }`Highest Model Performance' indicates the curve that resulted in the highest model performance (largely determined by precision; see \\\\hyperref[nature-change-mid-ext-exp1]{nature of change}). Emboldened text in the `Unbiased' and `Qualitative Description' columns indicates the number of measurements that, respectively, resulted in unbiased estimation and the greatest improvements in bias and precision across all day-unit parameters (note that acceptable precision was not obtained in the estimation of all day-unit parameters with middle-and-extreme spacing). `Error Bar Length' indicates the average error bar length value across all nature-of-change values that resulted from using the measurement number in the `Qualitative Description' column. Parameter names and population values are as follows: $\\\\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter = \\{80, 180, 280\\}; $\\\\upgamma_{fixed}$ = fixed-effect triquarter-halfway delta parameter = 20; $\\\\upbeta_{random}$ = random-effect days-to-halfway elevation parameter = 10; $\\\\upgamma_{random}$ = random-effect triquarter-halfway delta parameter = 4. NM = number of measurements.") %>% 
  kable_styling(position = 'left') %>%
  landscape(margin = '2.54cm')
```

#### Nature of Change That Leads to the Highest Model Performance {#nature-change-mid-ext-exp1}

For middle-and-extreme spacing, Table \ref{tab:errorbar-mid-ext-nc} lists the error bar lengths for each day-unit parameter and nature-of-change value. The 'Total' column indicates the total error bar length, which is a sum of the the lower ('Lower') and upper ('Upper') whisker lengths. Given that the lower and upper whisker lengths were largely equivalent for each parameter, they were largely redundant and so were not reported for the remainder of the results for middle-and-extreme spacing. Although model performance was determined by bias and precision, results for bias were not reported because the differences in bias across the nature-of-change values were negligible. Note that error bar lengths were obtained by computing the average length across all manipulated number-of-measurement values. The column shaded in gray indicates the nature of change where precision was best (i.e., shortest error bar lengths), which occurred with a nature-of-change value of 180 across all day-unit parameters under middle-and-extreme spacing (see the 'Highest Model Performance' in Table \ref{tab:summary-table-mid-ext-exp1}). Importantly, with a nature-of-change value of 180, measurements were taken closer to periods of change under middle-and-extreme spacing than with other nature-of-change values (see Figure \ref{fig:mid-ext-nc}). Therefore, it appears that placing measurements closer to periods of change increased model performance with middle-and-extreme spacing. 

#### Bias {#bias-mid-ext-exp1}

With respect to bias for middle-and-extreme spacing, estimates were biased (i.e., above the acceptable 10% cutoff) for each day-unit parameter in the following cells:

-   fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$; Figure \ref{fig:exp1_plot_time_dec}A): no cells.
-   fixed-effect triquarter-halfway delta parameter ($\upgamma_{fixed}$; Figure \ref{fig:exp1_plot_time_mid_ext}B): five measurements with nature-of-change values of 80 and 280.
-   random-effect days-to-halfway elevation parameter ($\upbeta_{random}$; Figure \ref{fig:exp1_plot_time_mid_ext}C): five and seven measurements with nature-of-change values of 80 and 280.
-   random-effect triquarter-halfway delta parameter ($\upgamma_{random}$; Figure \ref{fig:exp1_plot_time_mid_ext}D): five, seven, and nine measurements with nature-of-change values of 80 and 280.

In summary, with middle-and-extreme spacing, estimation of all the day-unit parameters across all manipulated nature-of-change values were unbiased using 11 measurements, which is indicated by the emboldened text in the 'Unbiased' column of Table \ref{tab:summary-table-mid-ext-exp1}.


```{r errorbar-mid-ext-nc, echo=F}
param_midpoint_mid_ext <- exp_1_analytical$days %>%
  filter(str_detect(string = measurement_spacing, pattern = 'Middle-and')) %>%
  group_by(parameter, midpoint) %>%
  summarize(
            lower = mean(pop_value - lower_ci, digits = 2), 
            upper = mean(upper_ci - pop_value, digits= 2),
   total_length = mean(errorbar_length, digits = 2)) %>% 
            #bias = round(mean(estimate) - mean(pop_value), digits = 2)) %>%
  pivot_wider(names_from = midpoint, names_glue = "{midpoint}_{.value}",
    values_from = lower:total_length,
    names_vary = 'slowest')

param_midpoint_mid_ext$parameter <- factor(x = c('$\\upbeta_{fixed}$ (Figure \\ref{fig:exp1_plot_time_mid_ext}A)', 
                                        '$\\upgamma_{fixed}$ (Figure \\ref{fig:exp1_plot_time_mid_ext}B)', 
                                        '$\\upbeta_{random}$ (Figure \\ref{fig:exp1_plot_time_mid_ext}C)', 
                                       '$\\upgamma_{random}$ (Figure \\ref{fig:exp1_plot_time_mid_ext}D)'))


kbl(x = param_midpoint_mid_ext, format = 'latex',digits = 2, 
       longtable = T, booktabs = T, centering = T, escape = F,
        align = c('l', rep('c', times = ncol(param_midpoint_equal) - 1)), 
    col.names = c('Parameter', rep(c('Lower', 'Upper', 'Total'), times = 3)), 
   
    caption = 'Error Bar Lengths Across Nature-of-Change Values Under Middle-and-Extreme Spacing in Experiment 1') %>%
  
    #header
     add_header_above(header = c(' ' = 1, '80' = 3, '180' = 3, '280' = 3), escape = F) %>%
    add_header_above(header = c(' ' = 1, 'Population Value of $\\\\upbeta_{fixed}$' = 9), escape = F) %>%
    column_spec(column = 5:7, background = '#DFDEDE') %>%
    column_spec(column = 1, width = '3.5cm') %>%
  
  footnote(escape = F, threeparttable = T, general_title = '',
           general = "\\\\textit{Note. }Parameter names and population values are as follows: $\\\\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter = \\{80, 180, 280\\}; $\\\\upgamma_{fixed}$ = fixed-effect triquarter-halfway delta parameter = 20; $\\\\upbeta_{random}$ = random-effect days-to-halfway elevation parameter = 10; $\\\\upgamma_{random}$ = random-effect triquarter-halfway delta parameter = 4. Note that error bar lengths were calculated by computing the average error bar length value across all number-of-measurement (NM) values (NM $\\\\in$ \\\\{5, 7, 9, 11\\\\}). Columns shaded in gray indicate the nature-of-change value that results in the shortest error bar and whisker lengths.") %>%
  kable_styling(position = 'left')
```

```{=tex}
\begin{apaFigure}
[portrait]
[samepage]
[0cm]
{Model Performance Status Across Nature-of-Change Values With Middle-and-Extreme Spacing}
{mid-ext-nc}
{0.25}
{Figures/midpoint_180_plot}
{Model performance was highest when measurements were taken closer to periods of greater change, which resulted with a nature-of-change value of 180 with middle-and-extreme spacing. Text prints error bar lengths that resulted when model performance was highest (see Table \ref{tab:errorbar-mid-ext-nc}).}
\end{apaFigure}
```


#### Precision {#precision-mid-ext-exp1}

With respect to precision for middle-and-extreme spacing, estimates were imprecise (i.e., error bar length with at least one whisker length exceeding 10% of a parameter's population value) in the following cells for each day-unit parameter:

-   fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$; Figure \ref{fig:exp1_plot_time_mid_ext}A): five measurements with nature-of-change values of 80 and 280.
-   fixed-effect triquarter-halfway delta parameter ($\upgamma_{fixed}$; Figure \ref{fig:exp1_plot_time_mid_ext}B): five and seven, an nine measurements with nature-of-change values of 80 and 280 (shown on x-axis).
-   random-effect days-to-halfway elevation parameter ($\upbeta_{random}$; Figure \ref{fig:exp1_plot_time_mid_ext}C): all cells.
-   random-effect triquarter-halfway delta parameter ($\upgamma_{random}$; Figure \ref{fig:exp1_plot_time_mid_ext}D): all cells.

\noindent In summary, with middle-and-extreme spacing, precise estimation of the fixed-effect day-unit parameters across all manipulated nature-of-change values was obtained with 11 measurements, but no manipulated measurement number resulted in precise estimation of the random-effect day-unit parameters (see the 'Precise' column of Table \ref{tab:summary-table-mid-ext-exp1}).

```{r plots-mid-ext-exp1, include=F, eval=F}
generate_day_likert_facet_plot(analytical_data = exp_1_analytical, target_col = 'measurement_spacing', target_value = 'Middle-and-extreme spacing',
                                x_axis_name = expression("Population Value Set for"~beta[fixed]), 
                                x_axis_var = 'midpoint', exp_num = 'exp1_', beta_lower = -80, beta_upper = 80, beta_ticks = 20)
```

```{=tex}
\begin{apaFigure}
[portrait]
[samepage]
[-0.2cm]
{Bias/Precision Plots for Day-Unit Parameters With Middle-and-Extreme Spacing in Experiment 1}
{exp1_plot_time_mid_ext}
{0.16}
{Figures/exp1_plot_days_middle-and-extreme spacing}
{Panel A: Bias/precision plot for the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$). Panel B: Bias/precision plot for the fixed-effect triquarter-halfway elevation parameter ($\upgamma_{fixed}$). Panel C: Bias/precision plot for the random-effect days-to-halfway elevation parameter ($\upbeta_{random}$). Panel D: Bias/precision plot for the random-effect triquarter-halfway elevation parameter ($\upgamma_{random}$). Blue horizontal lines in each panel represent the population value for each parameter. Population values for each day-unit parameter are as follows: $\upbeta_{fixed} \in$ {80.00, 180.00, 280.00}, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, $\upgamma_{random}$ = 4.00. Gray bands indicate the $\pm 10\%$ margin of error for each parameter and unfilled dots indicate cells with average parameter estimates outside of the margin or biased estimates. Error bars represent the middle 95\% of estimated values, with light blue error bars indicating imprecise estimation. I considered dots that fell outside the gray bands as biased and error bar lengths with at least one whisker length exceeding the 10\% cutoff (i.e., or longer than the portion of the gray band underlying the whisker) as imprecise. Note that random-effect parameter units are in standard deviation units. Importantly, across all nature-of-change values (i.e., population values used for $\upbeta_{fixed}$), the acceptable amount of bias and precision was based on a population value of 180. See Table \ref{tab:param-exp-1} for specific values estimated for each parameter and Table \ref{tab:omega-exp1-mid-ext} for $\upomega^2$ effect size values.}
\end{apaFigure}
```
```{r omega-exp1-mid-ext, echo=F}
print_bias_var_omega_table(exp_data = exp_1_raw, target_col = 'measurement_spacing', target_value = 'mid_ext', 
ind_vars = c('number_measurements', 'midpoint'), 
ind_var_acronyms = c('NM', 'NC', 'NM x NC'), 
caption = 'Partial $\\upomega^2$ Values for Manipulated Variables With Middle-and-Extreme Spacing in Experiment 1',
footnote = '\\\\textit{Note. }NM = number of measurements $\\\\in$ \\\\{5, 7, 9, 11\\\\}, NC = nature of change (population value set for $\\\\upbeta_{fixed}$ $\\\\in$ \\\\{80, 180, 280\\\\}), NM x NC = interaction between number of measurements and nature of change,
           $\\\\upgamma_{fixed}$ = fixed-effect triquarter-halfway delta parameter, 
           $\\\\upbeta_{random}$ = random-effect days-to-halfway elevation parameter, and 
           $\\\\upgamma_{random}$ = random-effect triquarter-halfway delta parameter.', 
parameter_labels = c('$\\upbeta_{fixed}$ (Figure \\ref{fig:exp1_plot_time_mid_ext}A)',
                     '$\\upbeta_{random}$ (Figure \\ref{fig:exp1_plot_time_mid_ext}B)',
                     '$\\upgamma_{fixed}$ (Figure \\ref{fig:exp1_plot_time_mid_ext}C)',
                     '$\\upgamma_{random}$ (Figure \\ref{fig:exp1_plot_time_mid_ext}D)'))
```

#### Qualitative Description {#qualitative-mid-ext-exp1}

```{r echo=F}
errorbar_lengths <- c(errorbar_lengths_nm7$errorbar_length[1], 
                      errorbar_lengths_nm9$errorbar_length[2], 
                      errorbar_lengths_nm7$errorbar_length[3], 
                      errorbar_lengths_nm9$errorbar_length[4])
```

For middle-and-extreme spacing in Figure \ref{fig:exp1_plot_time_mid_ext}, although no manipulated measurement number resulted in precise estimation of all day-unit parameters, the largest improvements in precision (and bias) were obtained using moderate measurements numbers. With respect to bias under middle-and-extreme spacing, the largest improvements across all manipulated nature-of-change values in bias occurred with the following measurement numbers for the following day-unit parameters:

-   random-effect days-to-halfway elevation parameter ($\upgamma_{fixed}$): seven measurements
-   random-effect days-to-halfway elevation parameter ($\upbeta_{random}$): nine measurements
-   random-effect triquarter-halfway delta parameters ($\upgamma_{random}$): 11 measurements

\noindent With respect to precision under middle-and-extreme spacing, the largest improvements precision in the estimation of all day-unit parameters across all manipulated nature-of-change values result with the following measurement numbers:

-   fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$): seven measurements, which results in a maximum error bar length of `r errorbar_lengths[1]` days.
-   fixed-effect triquarter-halfway delta parameter ($\upgamma_{fixed}$): seven measurements, which results in a maximum error bar length of `r errorbar_lengths[2]` days.
-   random-effect days-to-halfway elevation parameter ($\upbeta_{random}$): nine measurements, which results in a maximum error bar length of `r errorbar_lengths[3]` days.
-   random-effect triquarter-halfway delta parameter ($\upgamma_{random}$): seven measurements, which results in a maximum error bar length of `r errorbar_lengths[4]` days.

\noindent Therefore, for middle-and-extreme spacing, nine measurements resulted in the greatest improvements in bias and precision in the estimation of all day-unit parameters across all manipulated nature-of-change values (see the emboldened text in the 'Qualitative Description' column in Table \ref{tab:summary-table-mid-ext-exp1}).

#### Summary of Results With Middle-and-Extreme Spacing

In summarizing the results for middle-and-extreme spacing, model performance was highest across all day-unit parameters when measurements were placed closer to periods of change, which occurred with a nature-of-change value of 180 ($\upbeta_{fixed}$ = 180); see [highest model performance](#nature-change-mid-ext-exp1)). Unbiased estimation of the day-unit parameters across all manipulated nature-of-change values resulted from using nine or more measurements (see [bias](#bias-time-dec-exp1)). Precise estimation of all the day-unit parameters was never obtained using any of the manipulated measurement numbers (see [precision](#precision-time-dec-exp1)). Although it may be discouraging that no manipulated measurement number under time-interval decreasing spacing resulted in precise estimation of all the day-unit parameters, the largest improvements in precision (and bias) across all day-unit parameters were obtained with moderate measurement numbers. With time-interval decreasing spacing, the largest improvements in bias and precision in the estimation of all day-unit parameters across all manipulated nature-of-change values resulted from using nine measurements (see [qualitative description](#qualitative-time-inc-exp1)).

### Addressing My Research Questions

#### Does Placing Measurements Near Periods of Change Increase Model Performance? {#meas-placing}

In Experiment 1, one question I had was whether placing measurements near periods of change increases model performance. To answer this question, I have recorded the nature of change values that result in the highest model performance for each spacing schedule in Table \ref{tab:summary-table-exp1-nc}. Text in the 'Highest Model Performance' column indicates the 

```{r summary-table-exp1-nc, echo=F}
#data set containing error bar widths for each parameter under each spacing schedule 
param_midpoint_equal <- exp_1_analytical$days %>%
  filter(str_detect(string = measurement_spacing, pattern = 'Equal')) %>%
  group_by(parameter, midpoint) %>%
  summarize(errorbar_length = mean(errorbar_length, digits = 2)) %>%
  pivot_wider(names_from = midpoint, values_from =  errorbar_length)


param_midpoint_time_inc <- exp_1_analytical$days %>%
  filter(str_detect(string = measurement_spacing, pattern = 'increasing')) %>%
  group_by(parameter, midpoint) %>%
  summarize(errorbar_length = mean(errorbar_length, digits = 2)) %>%
  pivot_wider(names_from = midpoint, values_from =  errorbar_length)


param_midpoint_time_dec <- exp_1_analytical$days %>%
  filter(str_detect(string = measurement_spacing, pattern = 'decreasing')) %>%
  group_by(parameter, midpoint) %>%
  summarize(errorbar_length = mean(errorbar_length, digits = 2)) %>%
  pivot_wider(names_from = midpoint, values_from =  errorbar_length)


param_midpoint_mid_ext <- exp_1_analytical$days %>%
  filter(str_detect(string = measurement_spacing, pattern = 'Middle-and')) %>%
  group_by(parameter, midpoint) %>%
  summarize(errorbar_length = mean(errorbar_length, digits = 2)) %>%
  pivot_wider(names_from = midpoint, values_from =  errorbar_length)

#combine vectors into a list 
errorbar_lengths_list <- list('equal' = param_midpoint_equal[[3]], 
                              'time_inc' = param_midpoint_time_inc[[2]], 
                              'time_dec' =  param_midpoint_time_dec[[4]], 
                              'mid_ext' =  param_midpoint_mid_ext[[3]])

beta_fixed_errorbar_lengths <- as.numeric(unlist(lapply(X = errorbar_lengths_list, FUN = function(x){return(x[1])})))
gamma_fixed_errorbar_lengths <- as.numeric(unlist(lapply(X = errorbar_lengths_list, FUN = function(x){return(x[2])})))
beta_rand_errorbar_lengths <- as.numeric(unlist(lapply(X = errorbar_lengths_list, FUN = function(x){return(x[3])})))
gamma_rand_errorbar_lengths <- as.numeric(unlist(lapply(X = errorbar_lengths_list, FUN = function(x){return(x[4])})))


summary_table <- data.frame('Spacing Schedule' = c('\\thead[lt]{Equal \\\\ 
                                                   (see Figure \\ref{fig:exp1_plot_equal} and Table \\ref{tab:errorbar-equal-nc})}',
                                                   '\\thead[lt]{Time-interval increasing \\\\ 
                                                   (see Figure \\ref{fig:exp1_plot_time_inc} and Table \\ref{tab:errorbar-time-inc-nc})}', 
                                                   '\\thead[lt]{Time-interval decreasing \\\\ 
                                                   (see Figure \\ref{fig:exp1_plot_time_dec} and Table \\ref{tab:errorbar-time-dec-nc})}', 
                                                   '\\thead[lt]{Middle-and-extreme \\\\ 
                                                   (see Figure \\ref{fig:exp1_plot_time_mid_ext} and Table \\ref{tab:errorbar-mid-ext-nc})}'), 
                            'Highest Model Performance' = c('$\\upbeta_{fixed}$ = 180', 
                                                         '$\\upbeta_{fixed}$ = 80', 
                                                         '$\\upbeta_{fixed}$ = 280', 
                                                         '$\\upbeta_{fixed}$ = 180'), 
                        
                            '$\\upbeta_{fixed}$' = beta_fixed_errorbar_lengths, 
                            '$\\upgamma_{fixed}$' = gamma_fixed_errorbar_lengths, 
                            '$\\upbeta_{random}$' = beta_rand_errorbar_lengths, 
                            '$\\upgamma_{random}$' = gamma_rand_errorbar_lengths, 
                            
                            
                            check.names = F)

kbl(x = summary_table, format = 'latex', digits = 2,
    linesep = c('\\cmidrule{1-6}', '\\cmidrule{1-6}', '\\cmidrule{1-6}'), 
       longtable = T, booktabs = T, centering = T, escape = F,
    caption = 'Nature-of-Change Values That Lead to the Highest Model Performance for Each Spacing Schedule in Experiment 1', 
   align = c(rep('l', times = 1), rep('c', times = 4))) %>%
     #header
    add_header_above(header = c(' ' = 2, 'Error Bar Summary' = 4)) %>%
  column_spec(column = 1, width = '4.86cm') %>%
  column_spec(column = 2, width = '6cm') %>%
  column_spec(column = 3:6, width = '1.5cm') %>%
    footnote(escape = F, threeparttable = T, general_title = '', 
           general = "\\\\textit{Note. }`Highest Model Performance' indicates the curve that results in the highest model performance. `Error Bar Summary' columns lists error bar lengths for each day-unit parameter such that error bar lengths are computed by taking the average error bar length value across all the number-of-measurement (NM) values (NM $\\\\in$ \\\\{5, 7, 9, 11\\\\}). Parameter names and population values are as follows: $\\\\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter $\\\\in$ \\\\{80, 180, 280\\\\}; $\\\\upgamma_{fixed}$ = fixed-effect triquarter-halfway delta parameter = 20; $\\\\upbeta_{random}$ = random-effect days-to-halfway elevation parameter = 10; $\\\\upgamma_{random}$ = random-effect triquarter-halfway delta parameter = 4.") %>%
  kable_styling(position = 'left') %>%
  landscape(margin = '2.54cm')
```


\noindent nature-of-change with which each spacing schedule obtains its highest model performance. The 'Error Bar Summary' columns list the error bar lengths obtained for each day-unit parameter using the nature-of-change value listed in the 'Highest Model Performance' column.\footnote{Bias values are not presented because the differences across the schedules are negligible.} Note that the error bar lengths are obtained by computing the average error bar length across all manipulated measurement numbers for the optimal nature-of-change value. Model performance for each spacing schedule is highest with the following nature-of-change values:

-   equal spacing: $\upbeta_{fixed}$ = 180
-   time-interval increasing spacing: $\upbeta_{fixed}$ = 80
-   time-interval decreasing spacing: $\upbeta_{fixed}$ = 280
-   middle-and-extreme spacing: $\upbeta_{fixed}$ = 180

To understand why the model performance of each spacing schedule is highest with a specific nature of change, it is important to consider the locations on the curve where each schedule samples data. Figure \ref{fig:midpoint_plot} shows the measurement locations (indicated by dots) where each spacing schedule samples data for each manipulated nature of change ($\upbeta_{fixed} \in$ {80, 180, 180}). In Figure \ref{fig:midpoint_plot}A, data are sampled according to the equal spacing schedule. In Figure \ref{fig:midpoint_plot}B, data are sampled according to the time-interval increasing spacing schedule. In Figure \ref{fig:midpoint_plot}C, data are sampled according to the time-interval decreasing spacing schedule. In Figure \ref{fig:midpoint_plot}D, data are sampled according to the middle-and-extreme spacing schedule. Black curves indicate curves for which model performance is highest and gray curves indicating curves where model performance is not at its highest. Error bar lengths (i.e., precision) for the estimation of each day-unit parameter are copied 


```{r midpoint_plot, echo=F, eval=F}
#log function data 
t <- 0:360
theta <- 3
alpha <- 3.32
beta_80 <- 80
beta_180 <- 180
beta_280 <- 280
gamma <- 20

#log function
log_function <- expression(theta + (alpha - theta)/(1 + exp((beta_180 - t)/gamma)))

log_function_80 <- theta + (alpha - theta)/((1 + exp((beta_80 - t)/gamma)))
log_function_180 <- theta + (alpha - theta)/((1 + exp((beta_180 - t)/gamma)))
log_function_280 <- theta + (alpha - theta)/((1 + exp((beta_280 - t)/gamma)))
log_function_180b <- theta + (alpha - theta)/((1 + exp((beta_280 - t)/gamma)))

log_func_wide <- data.frame(cbind(t, log_function_180, log_function_80, log_function_280, log_function_180b,
                                  'midpoint_80' = log_function_80,
                                  'midpoint_180' = log_function_180,
                                  'midpoint_280' = log_function_280))

log_func_long <- log_func_wide %>%
  pivot_longer(cols = 2:5,
               #names_pattern = c('^log', '^midpoint'), 
               names_to = c('midpoint'),# 'midpoint_grouping'), 
               values_to = c('curve_value'), 
                names_transform = factor) %>% 
  pivot_longer(cols = 2:4, 
             names_to = c('midpoint_grouping'), 
            values_to = c('curve_value_group'), 
             names_transform = factor)

#add grouping variable for curve_value_group to indicate if the curve is the optimal one or not
##find the rows where the number in midpoint matches that in midpoint_grouping 
#1) Extract number from midpoint column 

log_func_long$optimal <- factor(extract_numeric(x = log_func_long$midpoint) != extract_numeric(x = log_func_long$midpoint_grouping))

log_func_long$midpoint <-  recode_factor(log_func_long$midpoint,   
                                    'log_function_180' = "atop(bold(A:beta[fixed]==180~With~Equal~Spacing), phantom(randomtextforalignment))",
                                    'log_function_80' = "atop(bold(B:beta[fixed]==80~With~`Time-Interval`~ phantom(randomtextfor)), bold(Increasing~Spacing)~phantom(text~forleftaligniextrattt))",
                                    'log_function_280' = "atop(bold(C:beta[fixed]==280~With~`Time-Interval`~ phantom(randomtextfor)), bold(Decreasing~Spacing)~phantom(text~forleftaligniextratta))",
                                    'log_function_180b' = "atop(bold(D:beta[fixed]==180~With~`Middle-and-`~phantom(text~forleftaligni)), bold(`Extreme`~Spacing)~phantom(text~forleftalandalmorerand))")


#spacing schedule data
num_measurements <- 5
time_period <- 360 
smallest_int_length <- 30
schedules <- c('equal', 'time_inc', 'time_dec', 'mid_ext')

list_out <- unlist(do.call(rbind, pmap(.l = list('num_measurements' = num_measurements, 
               'time_period' = time_period, 
               'smallest_int_length' = smallest_int_length, 
               measurement_spacing = schedules), 
     .f = compute_measurement_schedule))[, 2])

measurement_days_wide <- data.frame(matrix(data = list_out, nrow = 4, ncol = num_measurements, byrow = T, 
       dimnames = list(schedules, sprintf('measurement_day_%d', 1:num_measurements)))) %>%
  rownames_to_column(var = 'schedule')

measurement_days_wide$midpoint <- c('180', '80', '280', '180a')

#add midpoint 
measurement_days_wide$midpoint <-  recode_factor(measurement_days_wide$midpoint,  
                                    '180' = "atop(bold(A:beta[fixed]==180~With~Equal~Spacing), phantom(randomtextforalignment))",
                                    '80' = "atop(bold(B:beta[fixed]==80~With~`Time-Interval`~ phantom(randomtextfor)), bold(Increasing~Spacing)~phantom(text~forleftaligniextrattt))",
                                    '280' = "atop(bold(C:beta[fixed]==280~With~`Time-Interval`~ phantom(randomtextfor)), bold(Decreasing~Spacing)~phantom(text~forleftaligniextratta))",
                                    '180a' = "atop(bold(D:beta[fixed]==180~With~`Middle-and-`~phantom(text~forleftaligni)), bold(`Extreme`~Spacing)~phantom(text~forleftalandalmorerand))")

measurement_days_long <- measurement_days_wide %>% 
  pivot_longer(cols = 2:(num_measurements + 1), names_to = 'measurement_num', values_to = 'day_number') %>%
  mutate_if(.predicate = is.character, .funs = factor)

#add curve values; match log_func_long on midpoint and then add the corresponding curve value 
measurement_days_long <- left_join(x = measurement_days_long, y = log_func_long, by = c('midpoint', 'day_number' = 't'))


#combine vectors into a list 
errorbar_lengths_list <- list('equal' =  sprintf("%.2f", round(param_midpoint_equal[[3]], digits = 3)),  
                              'time_inc' = sprintf("%.2f", round(param_midpoint_time_inc[[2]], digits = 3)), 
                              'time_dec' =   sprintf("%.2f", round(param_midpoint_time_dec[[4]], digits = 3)), 
                              'mid_ext' =  sprintf("%.2f", round(param_midpoint_mid_ext[[3]], digits = 3)))

beta_fixed_errorbar_lengths <- as.numeric(unlist(lapply(X = errorbar_lengths_list, FUN = function(x){return(x[1])})))
gamma_fixed_errorbar_lengths <- as.numeric(unlist(lapply(X = errorbar_lengths_list, FUN = function(x){return(x[2])})))
beta_rand_errorbar_lengths <- as.numeric(unlist(lapply(X = errorbar_lengths_list, FUN = function(x){return(x[3])})))
gamma_rand_errorbar_lengths <- as.numeric(unlist(lapply(X = errorbar_lengths_list, FUN = function(x){return(x[4])})))

equation_data <- data.frame(
  midpoint =c(rep("atop(bold(A:beta[fixed]==180~With~Equal~Spacing), phantom(randomtextforalignment))", times = 4), 
               rep("atop(bold(B:beta[fixed]==80~With~`Time-Interval`~ phantom(randomtextfor)), bold(Increasing~Spacing)~phantom(text~forleftaligniextrattt))", times = 4), 
               rep("atop(bold(C:beta[fixed]==280~With~`Time-Interval`~ phantom(randomtextfor)), bold(Decreasing~Spacing)~phantom(text~forleftaligniextratta))", times = 4), 
               rep("atop(bold(D:beta[fixed]==180~With~`Middle-and-`~phantom(text~forleftaligni)), bold(`Extreme`~Spacing)~phantom(text~forleftalandalmorerand))", times = 4)),
  
  label = c(paste("beta[fixed] == ", beta_fixed_errorbar_lengths[1], sep = ''), 
            paste("gamma[fixed] == ", gamma_fixed_errorbar_lengths[1], sep = ''), 
            paste("beta[random] == ", beta_rand_errorbar_lengths[1], sep = ''), 
            paste("gamma[random] == ", gamma_rand_errorbar_lengths[1], sep = ''), 
            
            paste("beta[fixed] == ",sprintf("`%.2f`", round(beta_fixed_errorbar_lengths[2], digits = 3)), sep = ''), 
            paste("gamma[fixed] == ",  sprintf("`%.2f`", round(gamma_fixed_errorbar_lengths[2], digits = 3)), sep = ''), 
            paste("beta[random] == ",sprintf("`%.2f`", round(beta_rand_errorbar_lengths[2], digits = 3)), sep = ''), 
            paste("gamma[random] == ", gamma_rand_errorbar_lengths[2], sep = ''), 
            
            paste("beta[fixed] == ", beta_fixed_errorbar_lengths[3], sep = ''), 
            paste("gamma[fixed] == ", gamma_fixed_errorbar_lengths[3], sep = ''), 
            paste("beta[random] == ", beta_rand_errorbar_lengths[3], sep = ''), 
            paste("gamma[random] == ", gamma_rand_errorbar_lengths[3], sep = ''), 
            
            paste("beta[fixed] == ", beta_fixed_errorbar_lengths[4], sep = ''), 
            paste("gamma[fixed] == ", gamma_fixed_errorbar_lengths[4], sep = ''), 
            paste("beta[random] == ", beta_rand_errorbar_lengths[4], sep = ''), 
            paste("gamma[random] == ", gamma_rand_errorbar_lengths[4], sep = '')), 

  x = c(rep(c(-2.50, -1.5, -10.5, -9), times = 4)),
        #280, 280, 287, 290, 
        #rep(c(80, 80, 87, 90), times = 2)), 
  y = c(rep(c(3.24, 3.20, 3.16, 3.12), times = 4)))


#add optimal spacing midpoint column
midpoint_plot <- ggplot(data = log_func_long, mapping = aes(x = t, y = curve_value_group, 
                                                            group = midpoint_grouping, color = optimal, alpha = optimal)) + 
  geom_line(size = 4) +
  scale_y_continuous(name = 'Curve Value (Likert Units [Scale 1-5])') + 
  geom_point(data = measurement_days_long, aes(x = day_number, y = curve_value_group,
                                               group = midpoint_grouping, color = optimal, alpha = optimal), size = 15) +
  scale_color_manual(name = 'Highest Model Performance?', values = c('#0C0301', '#D3CFCE'),  labels = c('Yes', 'No')) + 
  scale_alpha_manual(name = 'Highest Model Performance?', values = c(1, 1),labels = c('Yes', 'No')) + 
  
  geom_text(data = equation_data, inherit.aes = F, mapping = aes(x = x, y = y, label = label), parse = T, size = 17.5) +
  nonlinSimsAnalysis:::facet_wrap_custom( ~ midpoint, scales = "free", ncol = 2, nrow = 2 , dir = 'h',
                     labeller = label_parsed,  

                            scale_overrides = list(
                            nonlinSimsAnalysis:::scale_override(1,
                              scale_x_continuous(name = 'Day', 
                                breaks = c(0, 80, 180, 280, 360),
                                limits = c(-60, 360))), 
                          
                             nonlinSimsAnalysis:::scale_override(which = 2,
                              scale_x_continuous(name = 'Day', 
                                breaks = c(0, 80, 180, 280, 360),
                                limits = c(-60, 360))), 
                            
                            nonlinSimsAnalysis:::scale_override(which = 3,
                              scale_x_continuous(name = 'Day', 
                                breaks = c(0, 80, 180, 280, 360),
                                limits = c(-60, 360))), 
                            
                              
                            nonlinSimsAnalysis:::scale_override(which = 4,
                              scale_x_continuous(name = 'Day', 
                                breaks = c(0, 80, 180, 280, 360),
                                limits = c(-60, 360))))) +
  
     
                         
  theme_classic(base_family = 'Helvetica') + 
  theme(
      #panel details
      strip.background = element_rect(fill = "white", color = "white"),
      #original text size = 60, 150 for pre-results figures
      strip.text.x = element_text(face = 'bold', hjust = 0, size = 60, margin = unit(c(t = 0, r = 0, b = 1, l = 0), "cm")),

      #axis details
      axis.text = element_text(size = 60, color = 'black'),
      axis.title = element_text(size = 70),
       
      #axis.title.x.bottom = element_markdown(),
      axis.line = element_line(size = 2),
      axis.ticks.length.x = unit(x = 1, units = 'cm'),
      axis.title.x = element_text(margin = unit(c(3, 0, 0, 0), "cm")),
      axis.title.y = element_text(margin = unit(c(t = 0, r = 3, b = 0, l = 0), units = 'cm')),
      axis.ticks = element_line(size = 2, colour = 'black'),
      axis.ticks.length.y =  unit(x = 1, units = 'cm'),

      #legend details
      legend.text = element_text(size = 50),
      legend.margin = margin(unit(c(0, 0, 0, 10), "cm")),
      legend.title = element_text(size = 60),
      legend.key.size = unit(3, 'cm'),
      legend.position = c(0.5, 0.52), 
      legend.direction = 'vertical',
      legend.box.background = element_rect(colour = 'black', size = 3),

      #panel details
      panel.spacing.y = unit(x = 18, units = 'cm'), 
       panel.spacing.x = unit(x = 2, units = 'cm')) 


set_panel_size(p = midpoint_plot, height = unit(x = 28, units = 'cm'),
                 width = unit(x = 40, units = 'cm'),
                 file =  'Figures/midpoint_plot.pdf')
```

```{r individual_midpoint_plots, echo=F, eval=F} 
#filter for midpoint = 80 
midpoint_80_data <- log_func_long %>%
  filter(midpoint == 'atop(bold(B:beta[fixed]==80~With~`Time-Interval`~ phantom(randomtextfor)), bold(Increasing~Spacing)~phantom(text~forleftaligniextrattt))')

measurement_days_long_80 <- measurement_days_long %>%
    filter(midpoint == 'atop(bold(A:beta[fixed]==180~With~Equal~Spacing), phantom(randomtextforalignment))')

equation_data_80 <- equation_data %>%
  filter(midpoint == 'atop(bold(B:beta[fixed]==80~With~`Time-Interval`~ phantom(randomtextfor)), bold(Increasing~Spacing)~phantom(text~forleftaligniextrattt))')


#filter for midpoint = 180 
midpoint_180_data <- log_func_long %>%
  filter(midpoint == 'atop(bold(A:beta[fixed]==180~With~Equal~Spacing), phantom(randomtextforalignment))')

measurement_days_long_180 <- measurement_days_long %>%
    filter(midpoint == 'atop(bold(A:beta[fixed]==180~With~Equal~Spacing), phantom(randomtextforalignment))')

equation_data_180 <- equation_data %>%
  filter(midpoint == 'atop(bold(A:beta[fixed]==180~With~Equal~Spacing), phantom(randomtextforalignment))')

#filter for midpoint = 80 
midpoint_280_data <- log_func_long %>%
  filter(midpoint == 'atop(bold(C:beta[fixed]==280~With~`Time-Interval`~ phantom(randomtextfor)), bold(Decreasing~Spacing)~phantom(text~forleftaligniextratta))')

measurement_days_long_280 <- measurement_days_long %>%
  filter(midpoint == 'atop(bold(C:beta[fixed]==280~With~`Time-Interval`~ phantom(randomtextfor)), bold(Decreasing~Spacing)~phantom(text~forleftaligniextratta))')

equation_data_280 <- equation_data %>%
  filter(midpoint == 'atop(bold(C:beta[fixed]==280~With~`Time-Interval`~ phantom(randomtextfor)), bold(Decreasing~Spacing)~phantom(text~forleftaligniextratta))')
  


midpoint_280_plot <- ggplot(data = midpoint_280_data, mapping = aes(x = t, y = curve_value_group, 
                                                            group = midpoint_grouping, color = optimal, alpha = optimal)) + 
  geom_line(size = 4) +
  scale_y_continuous(name = 'Curve Value (Likert Units [Scale 1-5])') + 
  geom_point(data = measurement_days_long_280, aes(x = day_number, y = curve_value_group,
                                               group = midpoint_grouping, color = optimal, alpha = optimal), size = 17.5) +
  scale_color_manual(name = 'Highest Model Performance?', values = c('#0C0301', '#D3CFCE'),  labels = c('Yes', 'No')) + 
  scale_alpha_manual(name = 'Highest Model Performance?', values = c(1, 1),labels = c('Yes', 'No')) + 
  
  geom_text(data = equation_data_280, inherit.aes = F, mapping = aes(x = x, y = y, label = label), parse = T, size = 15) +
 
  scale_x_continuous(name = 'Day', 
    breaks = c(0, 80, 180, 280, 360),
    limits = c(-60, 360)) +
  theme_classic(base_family = 'Helvetica') +
  theme(
      #panel details
      strip.background = element_rect(fill = "white", color = "white"),
      #original text size = 60, 150 for pre-results figures
      strip.text.x = element_text(face = 'bold', hjust = 0, size = 60, margin = unit(c(t = 0, r = 0, b = 1, l = 0), "cm")),

      #axis details
      axis.text = element_text(size = 40, color = 'black'),
      axis.title = element_text(size = 50),
       
      #axis.title.x.bottom = element_markdown(),
      axis.line = element_line(size = 2),
      axis.ticks.length.x = unit(x = 1, units = 'cm'),
      axis.title.x = element_text(margin = unit(c(t = 1, r = 0, b = 2, l = 0), "cm")),
      axis.title.y = element_text(hjust = 1, margin = unit(c(t = 0, r = 3, b = 0, l = 0), units = 'cm')),
      axis.ticks = element_line(size = 2, colour = 'black'),
      axis.ticks.length.y =  unit(x = 1, units = 'cm'),

      #legend details
      legend.text = element_text(size = 40),
      legend.margin = margin(unit(c(0, 0, 0, 10), "cm")),
      legend.title = element_text(size = 50),
      legend.key.size = unit(3, 'cm'),
      legend.position = "bottom", 
      legend.direction = 'vertical',
      legend.box.background = element_rect(colour = 'black', size = 3),

      #panel details
      panel.spacing.y = unit(x = 18, units = 'cm'), 
       panel.spacing.x = unit(x = 2, units = 'cm'))

set_panel_size(p = midpoint_280_plot, height = unit(x = 28, units = 'cm'),
                 width = unit(x = 40, units = 'cm'),
                 file =  'Figures/midpoint_80_plot.pdf')


#ggsave(filename = "Figures/midpoint_180_plot.pdf", plot = midpoint_180_plot, width = 10, height = 7, units = "cm")
```

```{=tex}
\begin{apaFigure}
[portrait]
[samepage]
[0cm]
{Nature-of-Change Curves for Each Spacing Schedule Have Highest Model Performance When Measurements are Taken Near Periods of Change}
{midpoint_plot}
{0.16}
{Figures/midpoint_plot}
{Panel A: Measurement sampling locations on each manipulated nature-of-change curve under equal spacing. Panel B: Measurement sampling locations on each manipulated nature-of-change curve under time-interval increasing spacing. Panel C: Measurement sampling locations on each manipulated nature-of-change curve under time-interval decreasing spacing. Panel D: Measurement sampling locations on each manipulated nature-of-change curve under middle-and-extreme spacing. Black curves indicate the natures of change that lead to the highest model performance for each spacing schedule, and so are optimal. Gray curves indicate the natures of change that lead to suboptimal model performance for each spacing schedule, and so are not optimal. Text on each panel indicates the error bar lengths when model performance is highest (see Table \ref{tab:summary-table-exp1-nc}).}
\end{apaFigure}
```

\noindent over from Table \ref{tab:summary-table-exp1-nc} to provide a reference with which to compare model performance between the spacing schedules with the optimal nature of change.

To investigate whether placing measurements near periods of change increases model performance, it is first important to define change. For the purpose of this discussion, change occurs when the first derivative of the logistic function has a nonzero value, with a larger (absolute) first derivative value implying greater change. Figure \ref{fig:logistic_function_first_dev} shows each nature of change used in Experiment 1 (solid line) along with its corresponding first derivative curve (dotted line). For each nature of change, the first derivative value reaches its peak at the value set for the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$). In Figure \ref{fig:logistic_function_first_dev}A, the first derivative is greatest at day 80. In Figure \ref{fig:logistic_function_first_dev}B, the first derivative is greatest at day 180. In Figure \ref{fig:logistic_function_first_dev}C, the first derivative is greatest at day 280. Therefore, for each manipulated nature of change, change is greatest at the value set for the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$).

Revisiting the question of whether placing measurements near periods of change increases model performance, I believe there are reasons to support this idea, and each reason is depicted in Figure \ref{fig:midpoint_plot}. Figure \ref{fig:midpoint_plot} shows the measurement locations where each spacing schedules samples its measurements. Black curves indicate the curve that leads to the highest model performance for each spacing schedule and gray curves indicate the curves that lead to suboptimal model performance. In looking at the black curves (i.e., curves that lead to the highest model performance) for each spacing schedule, more measurements lie closer to the period of greatest change on the black curves than on 

```{r first-deriv-curve, echo=F, eval=F}
#log function data 
t <- 0:360
theta <- 0
alpha <- 0.25
beta_80 <- 80
beta_180 <- 180
beta_280 <- 280
gamma <- 20

theta_deriv <- 0
alpha_deriv <- 10

#log function
log_function_80 <- expression(theta + (alpha - theta)/(1 + exp((beta_80 - t)/gamma)))
log_function_180 <- expression(theta + (alpha - theta)/(1 + exp((beta_180 - t)/gamma)))
log_function_280 <- expression(theta + (alpha - theta)/(1 + exp((beta_280 - t)/gamma)))

#expressions for derivatives (allows lines to occupy same y-axis range)
log_function_80_der <- expression(theta_deriv + (alpha_deriv - theta_deriv)/(1 + exp((beta_80 - t)/gamma)))
log_function_180_der <- expression(theta_deriv + (alpha_deriv - theta_deriv)/(1 + exp((beta_180 - t)/gamma)))
log_function_280_der <- expression(theta_deriv + (alpha_deriv - theta_deriv)/(1 + exp((beta_280 - t)/gamma)))

#compute derivatives
log_function_list <- list(log_function_80_der, log_function_180_der, log_function_280_der)
log_function_deriv_ls <- rapply(object = log_function_list, f = D, name = 't', how = 'unlist')

log_function_df <- data.frame('time' = t,
                              'log_function_80' = eval(log_function_80),
                              'log_function_180' = eval(log_function_180),
                              'log_function_280' = eval(log_function_280))

deriv_function_df <- data.frame('time' = t, 
  'log_function_80' =  eval(log_function_deriv_ls[[1]]), 
                                'log_function_180' =  eval(log_function_deriv_ls[[2]]), 
                                'log_function_280' =  eval(log_function_deriv_ls[[3]]))

#convert long function and deriv curves to long and then join on log_curve
log_func_long <- log_function_df %>% 
  pivot_longer(cols = log_function_80:log_function_280, names_to = 'log_curve', values_to = 'curve_value', names_transform = factor) 

deriv_func_long <- deriv_function_df %>% 
  pivot_longer(cols = log_function_80:log_function_280, names_to = 'log_curve', values_to = 'deriv_value', names_transform = factor)

log_deriv_func_long <- log_func_long %>% 
  left_join(y = deriv_func_long, by = c('log_curve', 'time')) 
log_deriv_func_long$log_curve <- recode_factor(.x =log_deriv_func_long$ log_curve, 
                     'log_function_80' = 'bold(A:beta[fixed]==80)', 
                     'log_function_180' = 'bold(B:beta[fixed]==180)', 
                     'log_function_280' = 'bold(C:beta[fixed]==280)')

log_deriv_func_long <- log_deriv_func_long %>% pivot_longer(cols = 'curve_value':'deriv_value', values_to = 'value', names_to = 'curve_type', 
                                     names_transform = factor)

deriv_plot <- ggplot(data = log_deriv_func_long, mapping = aes(x = time, y = value, 
                                                               group = curve_type, linetype = curve_type)) + 
  geom_line(size = 4) + 
  theme_classic() +
  scale_y_continuous(name = ' ', breaks = NULL) + 
  scale_linetype_manual(name = 'Curve Type', values = c(1, 3), 
                        labels = c('Logistic curve', 'Rate of change \n (first derivative')) + 
 facet_wrap_custom( ~ log_curve, scales = "free", ncol = 1, nrow = 3 , dir = 'h',
                     labeller = label_parsed,  

                            scale_overrides = list(
                            scale_override(1,
                              scale_x_continuous(name = 'Day', 
                                breaks = c(0, 80, 180, 240, 300, 360),
                                limits = c(0, 360))), 
                          
                             scale_override(which = 2,
                              scale_x_continuous(name = 'Day', 
                                breaks = c(0, 60, 120, 180, 240, 300, 360),
                                limits = c(0, 360))), 
                            
                            scale_override(which = 3,
                              scale_x_continuous(name = 'Day', 
                                breaks = c(0, 60, 120, 180, 280, 360),
                                limits = c(0, 360))))) + 
    
                         
  theme_classic(base_family = 'Helvetica') + 
  theme(
      #panel details
      strip.background = element_rect(fill = "white", color = "white"),
      #original text size = 60, 150 for pre-results figures
      strip.text.x = element_text(face = 'bold', hjust = 0, size = 60, margin = unit(c(t = 0, r = 0, b = 1, l = 0), "cm")),

      #axis details
      axis.text = element_text(size = 60, color = 'black'),
      axis.title = element_text(size = 70),
       
      #axis.title.x.bottom = element_markdown(),
      axis.line = element_line(size = 2),
      axis.ticks.length.x = unit(x = 1, units = 'cm'),
      axis.title.x = element_text(margin = unit(c(3, 0, 0, 0), "cm")),
      axis.title.y = element_text(margin = unit(c(t = 0, r = 3, b = 0, l = 0), units = 'cm')),
      axis.ticks = element_line(size = 2, colour = 'black'),
      axis.ticks.length.y =  unit(x = 1, units = 'cm'),

      #legend details
      legend.text = element_text(size = 50),
      legend.margin = margin(unit(c(0, 0, 0, 10), "cm")),
      legend.title = element_text(size = 60),
      legend.key.size = unit(3, 'cm'),
     # legend.position = c(0.2, 0.3), 
     legend.position = 'right', 
      legend.direction = 'vertical',
      legend.box.background = element_rect(colour = 'black', size = 3),

      #panel details
      panel.spacing.y = unit(x = 4, units = 'cm'))

set_panel_size(p = deriv_plot, height = unit(x = 28, units = 'cm'),
                 width = unit(x = 40, units = 'cm'),
                 file =  'Figures/deriv_plot.pdf')

```

```{=tex}
\begin{apaFigure}
[portrait]
[samepage]
[0cm]
{Rate of Change (First Derivative Curve) for Each Nature of Change Curve Manipulated in Experiment 1}
{logistic_function_first_dev}
{0.16}
{Figures/deriv_plot}
{Panel A: Logistic curve defined by $\upbeta_{fixed}$ = 80, with first-derivative curve peaking at day 80. Panel B: Logistic curve defined by $\upbeta_{fixed}$ = 180, with first-derivative curve peaking at day 180. Panel C: Logistic curve defined by $\upbeta_{fixed}$ = 280, with first-derivative curve peaking at day 280.}
\end{apaFigure}
```

\noindent the respective gray curves the gray curves that result in lower model performance. One clear example can be observed for the measurement locations under middle-and-extreme spacing (see Figure \ref{fig:midpoint_plot}D). In looking across the nature-of-change curves, only the measurement locations of the middle three measurements on each curve are different. For the optimal black nature of change, the middle three measurements are centered on the period of greatest change. For the gray suboptimal nature-of-change curves, the middle three measurements are taken near regions of little change (near-zero first derivative value). Therefore, model performance is highest when spacing schedules place measurement near periods of greatest change.

Second, model performance under time-interval increasing and decreasing spacing is nearly identical because each spacing schedule samples data at the exact same regions of change. In looking at Table \ref{tab:summary-table-exp1-nc}, it is important to realize that the precision (i.e., error bar lengths) obtained with time-interval increasing and decreasing spacing are nearly identical when model performance is highest. As an example of the precision obtained when model performance is highest, the average error bar length obtained for the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$) is 5.80 days with time-interval increasing spacing and 5.84 days with time-interval decreasing spacing. The nearly equivalent precision obtained with time-interval increasing and decreasing spacing occurs because the rates of change (i.e., first derivative values) at the sampled locations are the exact same. As an example with five measurements, Table \ref{tab:first-deriv} lists the curve values and measurement days when the time-interval increasing and decreasing spacing schedules sample the each of five unique first-derivative values. Note that the time-interval increasing and decreasing spacing schedules sample the first-derivative values in opposite orders. In summary, although the time-interval increasing and decreasing spacing schedules sample data on different days on their respective optimal curves, they result in (nearly) identical model performance because they place measurements at the same periods of change.

```{r first-deriv, echo=F}
#log function data 
t <- 0:360
theta <- 3
alpha <- 3.32
beta_80 <- 80
beta_180 <- 180
beta_280 <- 280
gamma <- 20

#log function
log_function <- expression(theta + (alpha - theta)/(1 + exp((beta_180 - t)/gamma)))
log_function_deriv <- eval(D(log_function, name = 't'))

log_function_df <- data.frame('time' = t, 
                              'log_function' = round(eval(log_function), digits = 2), 
                              'first_deriv' = log_function_deriv)

#compute measurements days 
time_inc_days <- compute_measurement_schedule(time_period = 360, num_measurements = 5, smallest_int_length = 30, measurement_spacing = 'time_inc')$measurement_days
time_dec_days <- compute_measurement_schedule(time_period = 360, num_measurements = 5, smallest_int_length = 30, measurement_spacing = 'time_dec')$measurement_days

#combine measurement days into df
time_inc_table <- data.frame('id' = 1:length(time_inc_days),
           'time_inc' = time_inc_days) %>%
  pivot_longer(cols = 2, names_to = 'schedule', values_to = 'measurement_day', names_transform = factor) %>%
  left_join(y = log_function_df, by = c('measurement_day' = 'time')) %>%
   pivot_wider(names_from = 'schedule', values_from = c('measurement_day', 'first_deriv', 'log_function')) %>% 
  select(first_deriv_time_inc, log_function_time_inc, measurement_day_time_inc)


time_dec_table <- data.frame('id' = 1:length(time_dec_days),
           'time_dec' = time_dec_days) %>%
  pivot_longer(cols = 2, names_to = 'schedule', values_to = 'measurement_day', names_transform = factor) %>%
  left_join(y = log_function_df, by = c('measurement_day' = 'time')) %>%
   pivot_wider(names_from = 'schedule', values_from = c('measurement_day', 'first_deriv', 'log_function')) %>%
  select(first_deriv_time_dec, log_function_time_dec, measurement_day_time_dec) %>% 
  arrange(desc(measurement_day_time_dec))

time_inc_table$first_deriv_time_inc <- signif(x = time_inc_table$first_deriv_time_inc, digits = 3)
time_dec_table$first_deriv_time_dec <- signif(x = time_dec_table$first_deriv_time_dec, digits = 3)

combined_table <- cbind(time_inc_table, time_dec_table) %>% 
  select(first_deriv_time_inc, log_function_time_inc, measurement_day_time_inc, 
         log_function_time_dec, measurement_day_time_dec)

kbl(x = combined_table, format = 'latex', 
   longtable = T, booktabs = T, centering = T, escape = F, 
   col.names = c('First Derivative Value', 'Curve Value', 'Measurement Day', 'Curve Value', 'Measurement Day'), 
    align = c('l', rep(x = 'c', times = ncol(combined_table) - 1)), 
    caption = 'Identical First-Derivative Sampling of Time-Interval Increasing and Decreasing Spacing Schedules') %>% 
  kable_styling(position = 'left') %>% 
   #header
  column_spec(column = 1, width = '4cm') %>%
  column_spec(column = 2:5, width = '2.5cm') %>%
  add_header_above(header = c(' ' = 1, 'Time-Interval Increasing' = 2,' Time-Interval Decreasing' = 2)) %>% 
   footnote(escape = F, threeparttable = T, general_title =  ' ', general = " ")
```

```{r echo=F}
equal_5_180 <- exp_1_analytical$days %>% 
  filter (measurement_spacing == 'Equal spacing', number_measurements == 5, midpoint == 180) %>% 
  group_by(parameter) %>% 
  summarize(errorbar_length = mean(upper_ci) - mean(lower_ci))

mid_5_180 <- exp_1_analytical$days %>% 
  filter (measurement_spacing == 'Middle-and-extreme spacing', number_measurements == 5, midpoint == 180) %>% 
  group_by(parameter) %>% 
  summarize(errorbar_length = mean(upper_ci) - mean(lower_ci))
```

Third, middle-and-extreme spacing obtains higher model performance than equal spacing by sampling data at periods of greater change. Importantly, both equal and middle-and-extreme spacing obtain their highest model performance with a with a nature-of-change value of 180 ($\upbeta_{fixed}$ = 180), with middle-and-extreme spacing obtaining higher precision (i.e., shorter error bars) than equal spacing (see Figure \ref{fig:midpoint_plot} and Table \ref{tab:summary-table-exp1-nc}). An inspection of Figures \ref{fig:midpoint_plot}A and \ref{fig:midpoint_plot}D reveals that middle-and-extreme spacing samples measurements at moments of greater change. As an example, consider the measurement locations of equal and middle-and-extreme spacing with five measurements, where only second and fourth measurement locations differ between the schedules. For equal spacing, the second and fourth measurements are respectively sampled on days 90 and 270. For middle-and-extreme spacing, the second and fourth measurements are respectively taken on days 150 and 210. By consulting the first-derivative curve in Figure \ref{fig:logistic_function_first_dev}, change is greater on days 150 and 210 than on days 90 and 270. Therefore, precision across all manipulated measurement numbers is greater (i.e., shorter error bars) with middle-and-extreme spacing than with equal spacing because middle-and-extreme spacing takes measurements closer to periods of change than equal spacing (see Figures \ref{fig:midpoint_plot}A and \ref{fig:midpoint_plot}D and Table \ref{tab:summary-table-exp1-nc}).

The idea that model performance increases when data are sampled during periods of greater change has received considerable discussion and preliminary support. Over the past 20 years, researchers have recommended that measurements be sampled during periods of greater change [@siegler2006; @ployhart2010], with one recent simulation study finding evidence to support this idea [@timmons2015]. Unfortunately, the evidence from @timmons2015 is preliminary for two reasons. First, the model used to estimate nonlinear change only ever included one random-effect parameter. Given that multilevel models often include several random-effect parameter in practice, the model employed in @timmons2015 may not necessary be realistic. Second, the estimates were obtained by using an impractical starting value procedure: Population values were used as starting values. Because practitioners never know the population value, it is not known whether the results of @timmons2015 replicate with a realistic starting value procedure.

My simulations in Experiment 1 replicated the finding that model performance increases from measuring change near periods of change under more realistic conditions. In contrast to the one-random-effect-parameter models used in @timmons2015, my simulations used a four-parameter model where each parameter was modelled as a fixed and random effect. For the starting value procedure, my simulations did not use the population values as starting values, but used the starting value procedure available in OpenMx, which uses an unweighted lease squares model to compute starting values.

Therefore, three results in Experiment 1 suggest that sampling data closer to periods of change leads to higher model performance. First, for each spacing schedule, model performance is highest when measurements are taken closer to periods of change. Second, the time-interval increasing and decreasing spacing schedules obtain nearly identical modelling accuracies for different curves because the sampled locations have the exact same rates of change. Third, middle-and-extreme spacing results in higher model performance than equal spacing by sampling measurements at periods of greater change. Although several researchers have posited model performance increases by sampling data closer to periods of change, with one simulation study (to my knowledege) having found support for this idea under unrealistic modelling conditions, my simulations in Experiment 1 support it under realistic modelling conditions.

#### When the Nature of Change is Unknown, How Should Measurements be Spaced? {#unknown}

A second question I had in Experiment 1 was how to space measurements when the nature of change is unknown. To answer this question, I first recorded the number of measurements needed to obtain the greatest improvements in model performance for each spacing schedule in Table \ref{tab:summary-table-exp1}. Text within the 'Qualitative Description' column indicates the number of measurements needed to obtain the largest improvements in bias and precision across all manipulated nature-of-change values for each spacing schedule. The 'Error Bar Summary' columns list the error bar lengths obtained for each day-unit parameter using the measurement number listed in the 'Qualitative Description' column. Note that the error bar lengths in the 'Error Bar Summary' column are obtained by computing the average length across all manipulated nature-of-change values for the measurement number listed Qualitative Description' column. For comprehensiveness, I also recorded the number of measurements needed to obtain unbiased and precise estimation of all the day-unit parameters across all manipulated nature-of-change values in the 'Unbiased' and 'Precise' columns.

The following number of measurements are needed to obtain unbiased estimation and the greatest improvements in bias and precision across all manipulated nature-of-change values for all day-unit parameters under each spacing schedule:

-   equal spacing: nine or more measurements to obtain unbiased estimation and seven measurements to obtain the greatest improvements in bias and precision.
-   time-interval increasing spacing: nine or more measurements to obtain unbiased estimation and nine measurements to obtain the greatest improvements in bias and precision.
-   time-interval decreasing spacing: nine or more measurements to obtain unbiased estimation and nine measurements to obtain the greatest improvements in bias and precision.
-   middle-and-extreme spacing: 11 measurements to obtain unbiased estimation and nine measurements to obtain the greatest improvements in bias and precision.

```{r summary-table-exp1, echo=F}
#error bar lengths for each spacing schedule
errorbar_lengths_equal <- compute_errorbar_lengths(exp_analytical_days = exp_1_analytical$days, iv_level = 'Equal spacing', num_measurements = 7)$errorbar_length

errorbar_lengths_time_inc_nm9 <- compute_errorbar_lengths(exp_analytical_days = exp_1_analytical$days, iv_level = 'Time-interval increasing', num_measurements = 9)$errorbar_length

errorbar_lengths_time_dec_nm9<- compute_errorbar_lengths(exp_analytical_days = exp_1_analytical$days, iv_level = 'Time-interval decreasing', num_measurements = 9)$errorbar_length

errorbar_lengths_mid_ext_nm9<- compute_errorbar_lengths(exp_analytical_days = exp_1_analytical$days, iv_level = 'Middle-and-extreme spacing', num_measurements = 9)$errorbar_length

#combine vectors into a list 
errorbar_lengths_list <- list('equal' = errorbar_lengths_equal, 
                              'time_inc' = errorbar_lengths_time_inc_nm9, 
                              'time_dec' = errorbar_lengths_time_dec_nm9, 
                              'mid_ext' = errorbar_lengths_mid_ext_nm9)

beta_fixed_errorbar_lengths <- as.numeric(unlist(lapply(X = errorbar_lengths_list, FUN = function(x){return(x[1])})))
gamma_fixed_errorbar_lengths <- as.numeric(unlist(lapply(X = errorbar_lengths_list, FUN = function(x){return(x[2])})))
beta_rand_errorbar_lengths <- as.numeric(unlist(lapply(X = errorbar_lengths_list, FUN = function(x){return(x[3])})))
gamma_rand_errorbar_lengths <- as.numeric(unlist(lapply(X = errorbar_lengths_list, FUN = function(x){return(x[4])})))


summary_table <- data.frame('Spacing Schedule' = c('\\thead[lt]{Equal \\\\ (see Figure \\ref{fig:exp1_plot_equal} and Table \\ref{tab:summary-table-equal-spacing-exp1})}', 
                                                   '\\thead[lt]{Time-interval increasing \\\\
                                                   (see Figure \\ref{fig:exp1_plot_time_inc} and Table \\ref{tab:summary-table-time-inc-exp1})}', 
                                                   
                                                   '\\thead[lt]{Time-interval decreasing \\\\ 
                                                   (see Figure \\ref{fig:exp1_plot_time_dec} and Table \\ref{tab:summary-table-time-dec-exp1})}', 
                                                   '\\thead[lt]{Middle-and-extreme \\\\ 
                                                   (see Figure \\ref{fig:exp1_plot_time_mid_ext} and Table \\ref{tab:summary-table-time-dec-exp1})}'), 
                                                   
                            'Unbiased' = c('NM $\\ge$ 9', 
                                           'NM $\\ge$ 9', 
                                           'NM $\\ge$ 9', 
                                           'NM = 11'), 
                            'Precise' = c('No cells', 
                                            'No cells', 
                                            'No cells',
                                            'No cells'), 
                            'Qualitative Description' = c('Largest improvements in bias and precision with NM = 7', 
                                                      'Largest improvements in bias and precision with NM = 9', 
                                                      'Largest improvements in bias and precision with NM = 9', 
                                                      'Largest improvements in bias and precision with NM = 9'), 
                            
                            '$\\upbeta_{fixed}$' = beta_fixed_errorbar_lengths, 
                            '$\\upgamma_{fixed}$' = gamma_fixed_errorbar_lengths, 
                            '$\\upbeta_{random}$' = beta_rand_errorbar_lengths, 
                            '$\\upgamma_{random}$' = gamma_rand_errorbar_lengths, 
                            
                            
                            check.names = F)

kbl(x = summary_table, format = 'latex',
    linesep = c('\\cmidrule{1-8}', '\\cmidrule{1-8}', '\\cmidrule{1-8}'), #\\cmidrule(l{0.25cm}r{0.25cm}){1-8}
       longtable = T, booktabs = T, centering = T, escape = F,
    caption = 'Concise Summary of Results Across All Spacing Schedule Levels in Experiment 1', 
   align = c('l', 'c', 'c', 'l', rep('c', times = 4))) %>%
     #header
  column_spec(column = 1, width = '5cm') %>%
  column_spec(column = 2, width = '2cm') %>%
  column_spec(column = 3, width = '4cm') %>%
  column_spec(column = 4, width = '6cm') %>%
  column_spec(column = 5:8, width = '1cm') %>%
  add_header_above(header = c(' ' = 4, 'Error Bar Summary' = 4)) %>%
  
  #row highlighting 
  row_spec(1, background = "#DFDEDE") %>%

   #footnotes
  footnote(escape = F, threeparttable = T, general_title = '',
           general = "\\\\textit{Note. }Row shaded in gray indicates the spacing schedules that results in the highest modelling accurac across all manipulated nature-of-change curves. `Qualitative Description' column indicates the number of measurements that obtains the greatest improvements in bias and precision across all day-unit parameters and manipulated nature-of-change values. `Error Bar Summary' columns list the error bar lengths that result for each day-unit parameter using the measurement number listed in the `Qualitative Description' column. Note that error bar lengths were calculated by computing the average length across all manipulated measurement numbers for the nature-of-change value listed in the `Qualitative Description' column. Parameter names and population values are as follows: $\\\\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter $\\\\in$ \\\\{80, 180, 280\\\\}; $\\\\upgamma_{fixed}$ = fixed-effect triquarter-halfway delta parameter = 20; $\\\\upbeta_{random}$ = random-effect days-to-halfway elevation parameter = 10; $\\\\upgamma_{random}$ = random-effect triquarter-halfway delta parameter = 4. NM = number of measurements.") %>%
  kable_styling(position = 'left') %>%
  landscape(margin = '2.54cm')
```

An important point to mention is that the error bar lengths for each day-unit parameter across each spacing schedule are comparable. That is, each spacing schedule obtains similar model performance when using the number of measurements listed in the 'Qualitative Description' column. Because model performance is similar across the spacing schedules, then the schedule that requires the fewest number of measurements to obtain the greatest improvements in bias and precision can be said to model change most accurately when the nature of change is unknown. With equal spacing using fewer measurements than all the other manipulated spacing schedules and obtaining similar model performance---using seven measurements instead of the nine measurements used by all other spacing schedules---equal spacing is the most effective schedule to use when the nature of change is unknown.

The finding that equal spacing results in the highest model performance when the nature of change is unknown is not unexpected. Given the previous finding that model performance increases by sampling data closer to periods of change, then, if the nature of change is unknown, change may occur at any point in time, and so it is prudent to space measurements equally over time so maximize the probability of sample measurements during a period of change.

## Summary of Experiment 1

I designed Experiment 1 to investigate two questions. The first question was whether placing measurements near periods of change increases model performance. For each spacing schedule, model performance was highest when measurements were sampled at periods of greater change. Therefore, when a researcher has some knowledge of the nature of change, measurements should be placed near periods of change to increase model performance.

The second question was how to space measurements when the nature of change is unknown. Although no manipulated measurement number under any spacing schedule resulted in accurate estimation of all parameters, the improvements in model performance began to diminish under each spacing schedule at a specific measurement number and plateaued at similar level of model performance. With each spacing schedule plateauing at a similar level of model performance at a specific measurement number, I concluded that the spacing schedule that used the fewest number of measurements to arrive at this plateau was most the effective schedule to use when the nature of change was unknown. With equal spacing using the fewest number of measurements to obtain the greatest improvements in model performance and reach its plateau, I concluded that equal spacing was the most effective schedule to use when the nature of change was unknown.


