
```{r package_loading_int_c3, include=F}
#devtools::install_github(repo = 'sciarraseb/nonlinSimsAnalysis', force = T)
library(easypackages)
packages <- c('tidyverse', 'RColorBrewer', 'parallel', 'data.table', 'kableExtra', 'ggtext', 'egg', 'ggbrace', 'cowplot', 'nonlinSimsAnalysis', 'nonlinSims', 'ggpubr')
libraries(packages)

knitr::opts_chunk$set(message = F)
```

```{r knitting_setup_int_c3, echo=F, message = F, warning = F}
#import raw data files (needed for computing variances)
exp_1_raw <- nonlinSimsAnalysis:::convert_raw_var_to_sd(raw_data = read_csv('data/exp_1_data.csv')) %>%
  mutate_at(.vars = c("number_measurements", "measurement_spacing", "midpoint"), factor)

exp_2_raw <-nonlinSimsAnalysis:::convert_raw_var_to_sd(raw_data = read_csv('data/exp_2_data.csv')) %>%
  mutate_at(.vars = c("number_measurements", "measurement_spacing", "sample_size"), factor)

exp_3_raw <-nonlinSimsAnalysis:::convert_raw_var_to_sd(raw_data = read_csv('data/exp_3_data.csv')) %>%
  mutate_at(.vars = c("number_measurements", "time_structuredness", "sample_size"), factor)

exp_3_def_raw <-nonlinSimsAnalysis:::convert_raw_var_to_sd(raw_data = read_csv('data/exp_3_def.csv')) %>%
  mutate_at(.vars = c("number_measurements", "time_structuredness", "sample_size"), factor)


#unfiltered data 
param_summary_exp_1 <- readRDS(file = 'data/uf_param_summary_exp_1.RData')
param_summary_exp_2 <- readRDS(file = 'data/uf_param_summary_exp_2.RData')
param_summary_exp_3 <- readRDS(file = 'data/uf_param_summary_exp_3.RData')
param_summary_exp_3_def <- readRDS(file = 'data/uf_param_summary_exp_3_def.RData')

#create analytical versions of summary data + converts vars to sds
exp_1_analytical <- generate_likert_days_data_sets(summary_data = param_summary_exp_1, exp_num = '1')
exp_2_analytical <- generate_likert_days_data_sets(summary_data = param_summary_exp_2, exp_num = '2')
exp_3_analytical <- generate_likert_days_data_sets(summary_data = param_summary_exp_3, exp_num = '3')
exp_3_def_analytical <- generate_likert_days_data_sets(summary_data = param_summary_exp_3_def, exp_num = '3')
exp_3_def_analytical$days$time_structuredness <-  factor(x = 'slow_response',labels = 'Time unstructured (slow response)')
exp_3_def_analytical$likert$time_structuredness <-  factor(x = 'slow_response',labels = 'Time unstructured (slow response)')

combined_analytical_exp_1 <- rbind(exp_1_analytical$likert, exp_1_analytical$days)
combined_analytical_exp_2 <- rbind(exp_2_analytical$likert, exp_2_analytical$days)
combined_analytical_exp_3 <- rbind(exp_3_analytical$likert, exp_3_analytical$days)
combined_analytical_exp_3_def <- rbind(exp_3_def_analytical$likert, exp_3_def_analytical$days)


#create condition summary data sets 
cond_summary_exp_1 <- compute_condition_summary(param_summary_data = combined_analytical_exp_1, facet_var = 'measurement_spacing', 
                          ind_vars = c('number_measurements', 'measurement_spacing', 'midpoint'))
cond_summary_exp_2 <- compute_condition_summary(param_summary_data = combined_analytical_exp_2, facet_var = 'measurement_spacing', 
                      ind_vars = c('number_measurements', 'measurement_spacing', 'sample_size'))

cond_summary_exp_3 <- compute_condition_summary(param_summary_data = combined_analytical_exp_3, facet_var = 'time_structuredness', 
                          ind_vars = c('number_measurements', 'sample_size', 'time_structuredness'))

cond_summary_exp_3_def <- compute_condition_summary(param_summary_data = combined_analytical_exp_3_def, facet_var = 'time_structuredness', 
                          ind_vars = c('number_measurements', 'sample_size', 'time_structuredness'))

```

```{r pre_knitting_setup_unfiltered_int_c3, echo=F, eval=F, include=F}
#code should be computed before knitting to decrease knitting time 
#load data from experiments
exp_1 <- read_csv(file = 'data/exp_1_data.csv') %>% filter(code == 0)
exp_2 <- read_csv(file = 'data/exp_2_data.csv')
exp_3 <- read_csv(file = 'data/exp_3_data.csv')
exp_3_def <-  read_csv(file = 'data/exp_3_def.csv')

#compute parameter summary statistics  
exp_1_long <- exp_1 %>%
    filter(code == 0) %>%
    #place parameter estimates in one column
    pivot_longer(cols = contains(c('theta', 'alpha', 'beta', 'gamma', 'epsilon')),
                 names_to = 'parameter', values_to = 'estimate') %>%
    filter(parameter == 'beta_fixed') %>%
    mutate(pop_value = midpoint)

exp_1_ordered <- nonlinSimsAnalysis:::order_param_spacing_levels(data = exp_1_long)


param_summary_exp_1 <- compute_parameter_summary(data = exp_1, exp_num = 1)
param_summary_exp_2 <- compute_parameter_summary(data = exp_2, exp_num = 2)
param_summary_exp_3 <- compute_parameter_summary(data = exp_3, exp_num = 3)
param_summary_exp_3_def <- compute_parameter_summary(data = exp_3_def, exp_num = 2)

#necessary factor conversions 
param_summary_exp_1$number_measurements <- factor(param_summary_exp_1$number_measurements, levels = c(5, 7, 9,11))
param_summary_exp_1$midpoint <- factor(param_summary_exp_1$midpoint, levels = c(80, 180,280))

param_summary_exp_2$number_measurements <- factor(param_summary_exp_2$number_measurements, levels = c(5, 7, 9,11))
param_summary_exp_2$sample_size <- factor(param_summary_exp_2$sample_size, levels = c(30, 50, 100, 200, 500, 1000))

param_summary_exp_3$number_measurements <- factor(param_summary_exp_3$number_measurements, levels = c(5, 7, 9,11))
param_summary_exp_3$sample_size <- factor(param_summary_exp_3$sample_size, levels = c(30, 50, 100, 200, 500, 1000))

param_summary_exp_3_def$number_measurements <- factor(param_summary_exp_3_def$number_measurements, levels = c(5, 7, 9,11))
param_summary_exp_3_def$sample_size <- factor(param_summary_exp_3_def$sample_size, levels = c(30, 50, 100, 200, 500, 1000))


#write data sets 
#save parameter summary files as RData files so that metadata are correctly stored (e.g., factor levels, variable types)
saveRDS(object = param_summary_exp_1, file = 'data/uf_param_summary_exp_1.RData')
saveRDS(object = param_summary_exp_2, file = 'data/uf_param_summary_exp_2.RData')
saveRDS(object = param_summary_exp_3, file = 'data/uf_param_summary_exp_3.RData')
saveRDS(object = param_summary_exp_3_def, file = 'data/uf_param_summary_exp_3_def.RData')

```


# Experiment 3 {#Exp3}

In Experiment 3, I was interested in examining how time structuredness affected model performance. Before presenting the results of Experiment 3, I present my design and analysis goals. For my design goals, I conducted a 3 (time structuredness: time-structured data, time-unstructured data resulting from a fast response rate, time-unstructured data resulting from a slow response rate) x 4 (number of measurements: 5, 7, 9, 11) x 6 (sample size: 30, 50, 100, 200, 500, 1000) study. For my analysis goals, I examined whether the number of measurements and sample sizes needed to obtain high model performance (i.e., low bias, high precision) increased as time structuredness decreased.


## Methods
### Variables Used in Simulation Experiment 

#### Independent Variables

##### Number of Measurements

For the number of measurements, I used the same values as in Experiment 1 of  5, 7, 9, and 11 measurements (see [number of measurements](#number-measurements) for more discussion). 

##### Sample Size

For sample size, I used the same values as in Experiment 2 of 30, 50, 100, 200, 500, and 1000 (see [sample size](#sample-size) for more discussion). 

##### Time Structuredness 

*Time structuredness* describes the extent to which participants provide data over time with the same response pattern. That is, at each time point, do participants provide their data at the exact same time point. If one response pattern characterizes the way in which participants provide their data, then participants always provide data at the exact same moment, and the resulting data are *time structured*. If response patterns differ between participants, the resulting data lose their time structuredness and become *time unstructured*, with the extent of the time unstructuredness depending on the extent to which response patterns differ between participants. The manipulation of time structuredness was adopted from the manipulation used in @coulombe2016 with a slight modification. Below, I describe the original procedure used in @coulombe2016 and, following this explanation, I describe my improved procedure. 

In  @coulombe2016, time-unstructured data were generated according to an exponential pattern such that most data were obtained at the beginning of the response window, with a smaller amount of data being obtained towards the end of the response window. Importantly, @coulombe2016 employed a non-continuous function for generating time-unstructured data: A binning method was employed such that 80% of the data were obtained within a time period equivalent to 12% (fast response rate) or 30% (slow response rate) of the entire response window. Using a response window length of 10 days with a fast response rate, the procedure employed by @coulombe2016 for generating time-unstructured data would have generated the following percentages of data in each of the four bins (note that, using the data generation procedure for @coulombe2016, the effective response window length for a fast response rate would be 4 days in the current example instead of 10 days):\footnote{The data generation procedure in \textcite{coulombe2016} for a fast response rate assumed that all of the data were collected within the initial 40\% length of the nominal response window length (i.e., 4 days in the current example).}

1) Bin 1: 60% of the data would be generated in the initial 10% length of the response window (0–0.40 day).
2) Bin 2: 20% of the data would be generated in the next 20% length of the response response window (0.40–1.20 days).
3) Bin 3: 10% of the data would be generated in the next 30% length of the response window (1.20–2.40 days).
4) Bin 4: the remaining 10% of the data would be generated in the remaining 40% length of the response window (2.40–4.00 days).

\noindent Note that, summing the data percentages and time durations from the first two bins yields an 80% cumulative response rate that is obtained in the initial 12% length of the full-length response window of 10 days (i.e., $(\frac{1.2}{10})100\% = 12\%$). Also note that, in @coulombe2016, a data point in each bin was randomly assigned a measurement time within the bin’s time range. In the current example where the full-length response window had a length of 10 days, a data point obtained in the first bin would be randomly assigned a measurement time between 0–0.40. Although @coulombe2016 generated time-unstructured data to resemble data collection conditions---response rates have been shown to follow an exponential pattern [@dillman2014; @pan2010]---the use of a pseudo-continuous binning function for generating time-unstructured data lacked ecological validity because response patterns are more likely to follow a continuous function. 

To improve on the time structuredness manipulation of @coulombe2016, I developed a more ecologically valid manipulation by using a continuous function. Specifically, I used the exponential function shown below in Equation \ref{eq:exp-function} to generate time-unstructured data:

\begin{align}
y = M(1 - e^{-ax}),
(\#eq:exp-function) 
\end{align}

\noindent where $x$ stores the time delay for a measurement at a particular time point, $y$ represents the cumulative response percentage achieved at a given $x$ time delay, $a$ sets the rate of growth of the cumulative response percentage over time, and $M$ sets the range of possible $y$ values. Two important points need to be made with respect to the $M$ parameter (range of possible $y$ values) and the response window length used in the current simulations. First, because the range of possible values for the cumulative response percentage ($y$) is 0–1 (data can be collected from a 0% to a maximum of 100% of respondents; $\{y : 0 \le y \le 1\}$), the M parameter had a value of 1 (M = 1). Second, the response window length in the current simulations was 36 days, and so the range of possible time delay values was between 0–36 ($\{x:0\le x \le36\}$).\footnote{A value of 36 days was used because the generation of time-unstructured data had to remain independent of the manipulation of measurement number (i.e., the response window lengths used in generating time-unstructured data could not vary with the number of measurements). To ensure the manipulations of measurement number and time structuredness remained independent, the response window length had to remain constant for all measurement number conditions with equal spacing. Looking at Table \ref{tab:measurementDays}, the longest possible response window that fit within all measurement number conditions with equal spacing was the interval length of the 11-measurement condition (i.e., 36 days).}

To replicate the time structuredness manipulation in  @coulombe2016 using the continuous exponential function of Equation \ref{eq:exp-function}, the growth rate parameter ($a$) had to be calibrated to achieve a cumulative response rate of 80% after either 12% or 30% of the response window length of 36 days. The derivation below solves for $a$, with Equation \ref{eq:growth-rate} showing the equation for computing $a$.

\begin{align}
y  &= M(1 - e^{-ax}) \nonumber \\
y &= M - Me^{-ax} \nonumber \\
y &= 1 -e^{-ax} \nonumber \\
e^{-ax} &= 1-y \nonumber \\
-ax\log(e) &= \log(1 - y) \nonumber \\
a &= \frac{\log(1 - y)}{-x}
(\#eq:growth-rate)
\end{align}

\noindent Because the target response rate was 80%, $y$ took on a value of .80 ($y = .80$). Given that the response window length in the current simulations was 36 days, $x$ took on a value of 4.32 (12% of 36) when time-unstructured data were defined by a fast response rate and 10.80 (30% of 36) when time-unstructured data were defined by a slow response rate. Using Equation \ref{eq:growth-rate} yielded the following growth rate parameter values for fast and slow response rates ($a_{fast}$, $a_{slow}$):

\begin{align}
a_{fast} &= \frac{\log(1 - .80)}{-4.32} = 0.37 \nonumber \\
a_{slow} &= \frac{\log(1 - .80)}{-10.80} = 0.15 \nonumber
\end{align}

\noindent Therefore, to obtain 80% of the data with a fast response rate (i.e., in 4.32 days), the growth parameter ($a$) needed to have a value of 0.37 ($a_{fast}$ = 0.37) and, to obtain 80% of the data with a slow response rate (i.e., in 10.80 days), the growth parameter ($a$) needed to have a value of 0.15 ($a_{slow}$ = 0.15). Using the above growth rate values derived for the fast and slow response growth rate parameters ($a_{fast}$, $a_{slow}$), the following functions were generated for fast and slow response rates:

\begin{align}
f_{fast}(x) = M(1 - e^{a_{fast}x}) = M(1 - e^{-0.37x}) \text{ and} \label{eq:cdf-fast}\\
f_{slow}(x) = M(1 - e^{a_{slow}x}) = M(1 - e^{-0.15x}).\label{eq:cdf-slow}
\end{align}

\noindent Using Equations \ref{eq:cdf-fast}--\ref{eq:cdf-slow}, Figure \ref{fig:cdf-plots} shows the resulting cumulative distribution functions (CDF) for time-unstructured data that show the cumulative response percentages as a function of time. Figure \ref{fig:cdf-plots}A shows the cumulative distribution function for a fast response rate (Equation \ref{eq:cdf-fast}), where an 80% response rate was obtained in 4.32 days. Figure \ref{fig:cdf-plots}B shows the cumulative distribution function for a slow response rate (Equation \ref{eq:cdf-slow}), where an 80% response rate was obtained in 10.80 days.

```{r cdf-fast-slow, eval=F, include=F}
#1) Generate CDFs
day <- seq(from = 0, to = 36, by = 0.01)
M <- 1
satiation_value <- 0.8
satiation_point_fast <- 4.32
satiation_point_slow <- 10.80

a_fast <- log(1 - satiation_value)/-satiation_point_fast
a_slow <- log(1 - satiation_value)/-satiation_point_slow

#y data (response rate)
y_fast <- M*(1 - exp(-a_fast*day))
y_slow <- M*(1 - exp(-a_slow*day))

cdf_data <- data.frame('dist_type' = factor(c(rep('bold(A:~CDF~(Fast~Response~Rate))', times = length(y_fast)), 
                                           rep('bold(B:~CDF~(Slow~Response~Rate))', times = length(y_slow)))), 
                       'day' = rep(day, times = 2), 
                       'CDF' = c(y_fast, y_slow)) 

#lines showing 80% mark    
v_line_data <- data.frame(
  dist_type =c("bold(A:~CDF~(Fast~Response~Rate))", "bold(B:~CDF~(Slow~Response~Rate))"), 
  x = c(4.32, 10.80), 
  x_end = c(4.32, 10.80), 
  y = c(0.8, 0.8), 
  y_end = c(0, 0))

h_line_data <- data.frame(
  dist_type =c("bold(A:~CDF~(Fast~Response~Rate))", "bold(B:~CDF~(Slow~Response~Rate))"), 
  x = c(0, 0), 
  x_end = c(4.32, 10.80), 
  y = c(0.8, 0.8), 
  y_end = c(0.8, 0.8))


cdf_plot <- ggplot(cdf_data, aes(x = day, y = CDF)) + 
  geom_line(size = 2.5) + 
  scale_y_continuous(name = 'Cumulative Response Percentage', breaks = c(0.00, 0.25, 0.50, 0.80, 1.00)) +
  theme_classic(base_family = 'Helvetica') + 
  

    #vertical lines 
   geom_segment(data = v_line_data, mapping = aes(x = x, y = y, xend = x_end, yend = y_end), linetype = 2, size = 2) + 
   geom_segment(data = h_line_data, mapping = aes(x = x, y = y, xend = x_end, yend = y_end), linetype = 2, size = 2)  + 
 

  nonlinSimsAnalysis:::facet_wrap_custom( ~ dist_type, scales = "free", ncol = 2, nrow = 1 ,
                     labeller = label_parsed,  

                            scale_overrides = list(
                              nonlinSimsAnalysis:::scale_override(1,
                              scale_x_continuous(
                                breaks = c(0, 4.32, 18, 24, 36),
                                limits = c(0, 36))), 
                          
                               nonlinSimsAnalysis:::scale_override(which = 2,
                              scale_x_continuous(breaks = c(0, 10.80, 18, 24, 36),
                                limits = c(0, 36))))) + 
                            


  labs( x = 'Response Window Day') +
  
  theme(strip.text.x = element_text(face = 'bold', hjust = 0, size = 50, margin = unit(c(t = 0, r = 0, b = 1, l = 0), "cm")),
        strip.background = element_rect(fill = "white", color = "white"), 

        #axis details
        axis.text = element_text(size = 40, color = 'black'),
        axis.title = element_text(size = 50),
        axis.line = element_line(size = 1),
        axis.ticks.length.x = unit(x = 0.5, units = 'cm'), 
        axis.title.x = element_text(margin = unit(c(1, 0, 0, 0), "cm")),
        axis.ticks = element_line(size = 1, colour = 'black'),
        
        axis.text.y = element_text(margin = margin(t = 0, r = 0, b = 0, l = 20)), 

      panel.spacing.y = unit(x = 3, units = 'cm'))

set_panel_size(p = cdf_plot, height = unit(x = 28, 
        units = "cm"), width = unit(x = 33, units = "cm"), file = 'Figures/cdf_plot.pdf')
       
```


```{=tex}
\begin{apaFigure}
[portrait]
[samepage]
[0cm]
{Cumulative Distribution Functions (CDF) With Fast and Slow Response Rates}
{cdf-plots}
{.20}
{Figures/cdf_plot}
{Panel A: Cumulative distribution function for a fast response rate (Equation \ref{eq:cdf-fast}), where an 80\% response rate is obtained in 4.32 days. Panel B: Cumulative distribution function for a slow response rate (Equation \ref{eq:cdf-slow}), where an 80\% response rate is obtained in 10.80 days.}
\end{apaFigure}
```


#### Constants 

Given that each simulation experiment manipulated no more than three independent variables so that results could be readily interpreted [@halford2005], other variables had to be set to constant values. In Experiment 3, two important variables were set to constant values: nature of change and measurement spacing. For nature of change, I set the value for the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$) across all cells to have a value of 180. For measurement spacing, I set the value across all cells to have equal spacing. 

#### Dependent Variables

##### Convergence Success Rate

The proportion of iterations in a cell where models converged defined
the *convergence success rate*.\footnote{Specifically, convergence was obtained if the convergence code returned by OpenMx was 0.} Equation \@ref(eq:convergence) below shows the calculation used to compute the convergence success rate:

```{=tex}
\begin{align}
  \text{Convergence success rate} =  \frac{\text{Number of models that successfully converged in a cell}}{n},
  (\#eq:convergence) 
\end{align}
```
\noindent where *n* represents the total number of models run in a cell.

##### Model Performance 

Model performance was the combination of two metrics: bias and precision. More specifically, two questions were of importance in the estimation of a given logistic function parameter: 1) How well was the parameter estimated on average (bias) and 2) what was a range of values that could be expected for an estimate from the output of a single model (precision). In the two sections that follow, I will discuss each metric of model performance and the cutoffs used to determine whether estimation was unbiased and precise. 

###### Bias

Bias was calculated to evaluate the accuracy with which each logistic
function parameter was estimated in each experimental cell. As shown below in Equation
\@ref(eq:bias-3), *bias* was obtained by summing the differences
between the population value set for a parameter and the value estimated for the parameter by each $i$ converged model and then dividing the sum by the number of $N$ converged models. 

```{=tex}
\begin{align}
  \text{Bias} = \frac{\sum_i^N\text{(Population value for parameter} - \text{Average estimated value}_i)}{N}
  (\#eq:bias-3) 
\end{align}
```

\noindent Bias was calculated for the fixed- and random-effect parameters of the baseline ($\uptheta_{fixed}$, $\uptheta_{random}$), maximal elevation ($\upalpha_{fixed}$, $\upalpha_{random}$), days-to-halfway elevation ($\upbeta_{fixed}$, $\upbeta_{random}$), and the halfway-triquarter delta parameters ($\upgamma_{fixed}$, $\upgamma_{random}$) and the error parameter ($\upepsilon$). 

###### Precision

In addition to computing bias, precision was calculated to evaluate the variability with which each parameter was estimated. Importantly, metrics used to evaluate precision in previous studies assume estimates are normally distributed (e.g., mean-squared error and empirical standard error). Because some parameters in my simulations had skewed distributions, using a metric that assumed a normal distribution would likely yield inaccurate results. Correspondingly, I used a distribution-independent definition of precision. In my simulations, *precision* was defined as the range of values covered by the middle 95% of values estimated for a logistic function parameter. 



### Overview of Data Generation

Data generation was computed the same way as in Experiment 1 (see [data generation](#data-generation)) with one addition to the procedure needed for time structuredness. The section that follows details how time structuredness was simulated. Note that the code used to run the simulations and create the data set can be found in Appendix \ref{simulation-code} and the data file (`exp_3_data.csv`) can be found in the following GitHub repository: [https://github.com/sciarraseb/dissertation](https://github.com/sciarraseb/dissertation). 

##### Simulation Procedure for Time Structuredness {#simulating-time-struc}

To simulate time-unstructured data, response rates at each collection
point followed an exponential pattern described by either a fast or slow
response rate (for a review, see [time structuredness](#time-structuredness)). Importantly, data generated
for each person at each time point had to be sampled according to a
probability density function defined by either the fast or slow response
rate cumulative distribution function (respectively, see Equations \ref{eq:cdf-fast}--{eq:cdf-slow}). In the current context, a
*probability density function* describes the probability of sampling
any given time delay value $x$ where the range of time delay values is
0--36 ($\{x : 0 \le x \le  36 \}$). To obtain the probability density functions
for fast and slow response rates, the response rate function shown in
Equation \@ref(eq:exp-function) was differentiated with respect to $x$ to
obtain the function shown below in Equation \ref{eq:pdf-function}:\footnote{Euler's notation for differentiation is used to represent derivatives. In words, $\frac{\partial f(x)}{\partial x}$ means that the derivative of the function $f(x)$ is taken with respect to $x$.}

```{=tex}
\begin{align}
f^\prime = \frac{\partial f(x)}{\partial x} &= \frac{\partial}{\partial x}M(1 - e^{-ax}). \nonumber \\
&= M (e^{-ax}a)
(\#eq:pdf-function)
\end {align}
```

\noindent To compute the probability density function for the fast
response rate cumulative distribution function, the growth rate
parameter $a$ was set to 0.37 in Equation \ref{eq:pdf-function} to
obtain the following function in Equation \ref{eq:fast-pdf-function}:

```{=tex}
\begin{align}
f^\prime_{fast}(x) = M (e^{-a_{fast}x}a_{fast}) = M (e^{-0.37x}0.37). 
(\#eq:fast-pdf-function)
\end {align}
```

\noindent To compute the probability density function for the slow
response rate cumulative distribution function, the growth rate
parameter $a$ was set to 0.15 in Equation \ref{eq:pdf-function} to
obtain the following function in Equation \ref{eq:slow-pdf-function}:

```{=tex}
\begin{align}
f^\prime_{slow}(x) = M (e^{-0.15}a_{slow}) = M (e^{-0.15}0.15). 
(\#eq:slow-pdf-function)
\end {align}
```

Figure \ref{fig:cdf-pdf-plots} shows the fast and slow response
cumulative distribution functions (CDF) and their corresponding
probability density functions (PDF). Panel A shows the cumulative
distribution function for the fast response rate (with a growth
parameter value $a$ set to 0.37; see Equation \ref{eq:cdf-fast}) and
Panel B shows the probability density function that results from
computing the derivative of the fast response rate cumulative
distribution function 

```{r pdf-time-structuredness, eval=F, include=F}
#1) Generate CDFs
day <- seq(from = 0, to = 36, by = 0.01)
M <- 1
satiation_value <- 0.8
satiation_point_fast <- 4.32
satiation_point_slow <- 10.80

a_fast <- log(1 - satiation_value)/-satiation_point_fast
a_slow <- log(1 - satiation_value)/-satiation_point_slow

#y data
y_fast <- M*(1 - exp(-a_fast*day))
y_slow <- M*(1 - exp(-a_slow*day))

#probability values
cdf_fast <- expression(M*(1 - exp(-a_fast*day)))
cdf_slow <- expression(M*(1 - exp(-a_slow*day)))

pdf_fast <- D(expr = cdf_fast, 'day')
pdf_slow <- D(expr = cdf_slow, 'day')

probability_values_fast<- eval(pdf_fast)
probability_values_slow <- eval(pdf_slow)


cdf_pdf_data <- data.frame('response_rate' = factor(c(rep('fast', times = length(y_fast)), 
                                           rep('slow', times = length(y_slow)))), 
                       'day' = rep(day, times = 2), 
                       'CDF' = c(y_fast, y_slow), 
                       'PDF' = c(probability_values_fast, probability_values_slow))

cdf_pdf_data_long <- cdf_pdf_data %>%
  pivot_longer(cols = c(CDF, PDF), names_to = 'prob_dist',
  names_ptypes = factor(levels = c('CDF', 'PDF'))) %>% 
  unite('dist_type', c('response_rate', 'prob_dist')) %>%
  mutate(dist_type = factor(dist_type, levels = c('fast_CDF', 'slow_CDF','fast_PDF', 
                                                   'slow_PDF')))

cdf_pdf_data_long$dist_type <- recode_factor(cdf_pdf_data_long$dist_type,   
                                             fast_CDF = 'bold(A:~CDF~(Fast~Response~Rate))', 
                                             slow_CDF = 'bold(C:~CDF~(Slow~Response~Rate))', 
                                             fast_PDF = 'bold(B:~PDF~(Fast~Response~Rate))', 
                                             slow_PDF = 'bold(D:~PDF~(Slow~Response~Rate))')
                
#lines showing 80% mark    
v_line_data <- data.frame(
  dist_type =c("bold(A:~CDF~(Fast~Response~Rate))", "bold(C:~CDF~(Slow~Response~Rate))"), 
  x = c(4.32, 10.80), 
  x_end = c(4.32, 10.80), 
  y = c(0.8, 0.8), 
  y_end = c(0, 0))

h_line_data <- data.frame(
  dist_type = c("bold(A:~CDF~(Fast~Response~Rate))", "bold(C:~CDF~(Slow~Response~Rate))"), 
  x = c(0, 0), 
  x_end = c(4.32, 10.80), 
  y = c(0.8, 0.8), 
  y_end = c(0.8, 0.8))

#needed for shading
pdf_shading_data <- cdf_pdf_data_long %>% 
  filter(str_detect(dist_type, pattern = 'bold\\(B') & day <= 4.32 | 
         str_detect(dist_type, pattern = 'bold\\(D') & day <= 10.80)

#needed for points 
point_data <- data.frame(
  dist_type =c(rep("bold(A:~CDF~(Fast~Response~Rate))", times = 1), 
               rep("bold(C:~CDF~(Slow~Response~Rate))", times = 1)),
  x = c(4.32, 10.80), 
  y = c(0.8, 0.8))

#arrows 
arrow_data <- data.frame(
  dist_type =c(rep("bold(A:~CDF~(Fast~Response~Rate))", times = 1), 
               rep("bold(C:~CDF~(Slow~Response~Rate))", times = 1)),
  xmin = c(4.32, 10.80), 
  xmax = c(10, 17), 
  ymin = c(0.8, 0.8), 
  ymax = c(0.25, 0.25))


#equations 
equation_data <- data.frame(
  dist_type =c(rep("bold(A:~CDF~(Fast~Response~Rate))", times = 4), 
               rep("bold(C:~CDF~(Slow~Response~Rate))", times = 4), 
               rep("bold(B:~PDF~(Fast~Response~Rate))", times = 3), 
               rep("bold(D:~PDF~(Slow~Response~Rate))", times = 3)),
  
  label = c("f[fast](x) == M(1 - e^{-a[fast]~x})", "a[fast] == 0.37", "M ==1", "0.80 == 1(1-e^{-0.37(4.32)})", 
            "f[slow](x) == M(1 - e^{-a[slow]~x})", "a[slow] == 0.15", "M == 1", "0.80 == 1(1-e^{-0.15(10.80)})",
            
            "f[fast]^{phantom() * minute }(x) * {phantom() == phantom()} * frac(partialdiff *f[fast](x),  partialdiff *x) * {phantom() == phantom()} * M(e^{a[fast]*x} * a[fast])",
            "integral(f[fast]^{phantom() * minute}, 0, 4.32)*(x) == f[fast](4.32) - f[fast](0)", "phantom() == 0.80", 
            
            "f[slow]^{phantom() * minute }(x) * {phantom() == phantom()} * frac(partialdiff *f[slow](x),  partialdiff *x) * {phantom() == phantom()} * M(e^{a[slow]*x} * a[slow])",
            "integral(f[slow]^{phantom() * minute}, 0, 10.80)*(x) == f[slow](10.80) - f[slow](0)", "phantom() == 0.80"), 
  x = c(18, 17, 18, 18, 
        24, 25, 24, 24, 
        22, 22, 20.5, 
        22, 22, 20.5),
  y = c(rep(c(0.8, 0.65, 0.50, 0.2), times = 2), 
        0.35, 0.15, 0.10, 
        0.35, 0.15, 0.10))


cdf_pdf_plot <- ggplot(cdf_pdf_data_long, aes(x = day, y = value)) + 
  geom_line(size = 1.5) + 
  scale_y_continuous(breaks = c(0, 0.25, 0.50, 0.80, 1.00)) +
  theme_classic(base_family = 'Helvetica') + 
  
  geom_area(data = pdf_shading_data, mapping = aes(x = day, y = value), 
                show.legend = 'bin',  fill="grey", alpha = 1, color = 'black', size = 1.5) +
  geom_text(data = equation_data, inherit.aes = F, mapping = aes(x = x, y = y, label = label), parse = T, size = 9) + 
  geom_point(data = point_data, inherit.aes = F, mapping = aes(x = x , y = y), size = 4) + 
  
  #arrows
  geom_segment(data = arrow_data, inherit.aes = F, mapping = aes(x = xmin, xend = xmax, y = ymin, yend = ymax), 
               arrow = arrow(length = unit(0.3, 'cm')), size = 1)  + 
  
    #vertical lines 
  geom_segment(data = v_line_data, mapping = aes(x = x, y = y, xend = x_end, yend = y_end), linetype = 2, size = 1) + 
  geom_segment(data = h_line_data, mapping = aes(x = x, y = y, xend = x_end, yend = y_end), linetype = 2, size = 1)  + 



  nonlinSimsAnalysis:::facet_wrap_custom( ~ dist_type, scales = "free", ncol = 2, nrow = 2 , dir = 'v',
                     labeller = label_parsed,  

                            scale_overrides = list(
                            nonlinSimsAnalysis:::scale_override(1,
                              scale_x_continuous(
                                breaks = c(0, 4.32, 18, 24, 36),
                                limits = c(0, 36))), 
                          
                            nonlinSimsAnalysis:::scale_override(which = 2,
                              scale_y_continuous(breaks = c(0, 0.1, 0.2, 0.3, 0.4),
                                limits = c(0, 0.4))),
                            
                             nonlinSimsAnalysis:::scale_override(which = 2,
                              scale_x_continuous(breaks = c(0, 4.32, 18, 24, 36),
                                limits = c(0, 36))),
                            
                            nonlinSimsAnalysis:::scale_override(which = 3,
                               scale_x_continuous(
                                breaks = c(0, 10.80, 18, 24, 36),
                                limits = c(0, 36))), 
                         
                            nonlinSimsAnalysis:::scale_override(4,
                              scale_x_continuous(
                                breaks = c(0, 10.80, 18, 24, 36),
                                limits = c(0, 36))), 
                            
                            nonlinSimsAnalysis:::scale_override(which = 4,
                                scale_y_continuous(breaks = c(0, 0.1, 0.2, 0.3, 0.4),
                                limits = c(0, 0.4))))) +  


  labs( x = 'Response Window Day') + 
  
  theme(strip.text.x = element_text(face = 'bold', hjust = 0, size = 30, margin = unit(c(t = 0, r = 0, b = 1, l = 0), "cm")),
        strip.background = element_rect(fill = "white", color = "white"), 

        #axis details
        axis.text = element_text(size = 22, color = 'black'),
        axis.title = element_text(size = 28),
        axis.line = element_line(size = 1),
        axis.ticks.length.x = unit(x = 0.5, units = 'cm'), 
        axis.title.x = element_text(margin = unit(c(1, 0, 0, 0), "cm")),
        axis.ticks = element_line(size = 1, colour = 'black'),

      panel.spacing.y = unit(x = 2, units = 'cm'),
      panel.spacing.x = unit(x = 2, units = 'cm'))
       

g <- ggplotGrob(cdf_pdf_plot)

#customize y-axis label 
g$grobs[[28]]$children$GRID.text.4670$label <- paste("Density (Probability, f'(x))", str_pad('', width = 13), "Response Percentage (f(x))")
g$grobs[[28]]$children$GRID.text.4670$y <- grid::unit(0.52,"npc")
g$grobs[[28]]$children$GRID.text.4670$x <- grid::unit(-0.2,"npc")

plot_converted <- as_ggplot(g)

#create PDF of faceted plot
set_panel_size(p = plot_converted, height = unit(x = 32, units = 'cm'),
                 width = unit(x = 40, units = 'cm'),
                 file =  'Figures/cdf_pdf_plots.pdf')
```

```{=tex}
\begin{apaFigure}
[portrait]
[samepage]
[0cm]
{Cumulative Distribution Functions (CDF) and Probability Density Functions (PDF) for Fast and Slow Response Rates}
{cdf-pdf-plots}
{.38}
{Figures/cdf_pdf_plots}
{Panel A: Cumulative distribution function for the fast response rate (with a growth parameter value $a$ set to 0.37; see Equation \ref{eq:cdf-fast}). Panel B: Probability density function that results from computing the derivative of the fast response rate cumulative distribution function with respect to $x$ (see Equation \ref{eq:fast-pdf-function}). Panel C: Cumulative distribution function for the slow response rate (with a growth parameter value $a$ set to 0.15; see Equation \ref{eq:cdf-slow}). Panel D: Probability density function that results from computing the derivative of the slow response rate cumulative distribution function with respect to $x$ (see Equation \ref{eq:slow-pdf-function} and \nameref{time-structuredness} for more discussion on time structuredness). For the fast response rate functions, an 80\% response rate is obtained after 4.32 days or, equivalently, 80\% of the area underneath the probability density function is obtained at 4.32 days ($\int^{4.32}_{0} f_{fast}^\prime (x) = 0.80$). For the slow response rate functions, an 80\% response rate is obtained after 10.80 days or, equivalently, 80\% of the area underneath the probability density function is obtained at 10.80 days ($\int^{10.80}_{0} f_{slow}^\prime (x) = 0.80$).}
\end{apaFigure}
```


\noindent with respect to $x$ (see Equation
\ref{eq:fast-pdf-function}). Panel C shows the cumulative distribution
function for the slow response rate (with a growth parameter value $a$
set to 0.15; see Equation \ref{eq:cdf-slow})) and Panel D shows the
probability density function that results from computing the derivative
of the slow response rate cumulative distribution function with respect
to $x$ (see Equation \ref{eq:slow-pdf-function} and section on [time
structuredness](#sec:time-structuredness) for more discussion). For the
fast response rate functions, an 80% response rate is obtained after
4.32 days or, equivalently, 80% of the area underneath the probability
density function is obtained at 4.32 days
($\int^{4.32}_{0} f_{fast}^\prime (x) = 0.80$; the integral from 0 to 4.32 of the probability density function for a fast response rate $f^\prime(x)_{fast}$ is 0.80). For the slow response
rate functions, an 80% response rate is obtained after 10.80 days or,
equivalently, 80% of the area underneath the probability density
function is obtained at 10.80 days
($\int^{10.80}_{0} f_{slow}^\prime (x) = 0.80$; the integral from 0 to 10.80 of the probability density function for a slow response rate $f^\prime(x)_{slow}$ is 0.80).


Having computed probability density functions for fast and slow response rates, time delays could be generated to create time-unstructured data. To generate time-unstructured data, a time delay was first
generated by sampling values according to the probability density function defined by either a fast or slow response rate (Equations \ref{eq:fast-pdf-function}--\ref{eq:slow-pdf-function}). The sampled time delay was then added to the value of the current measurement day for a person at a given time point. That is, if the collection window opened on day 60 and the generated time delay for a given person was 4.50 days, then their data would be generated by inserting a value of 64.50 for the $time_i$ parameter of the logistic function (Equation \ref{eq:logFunction-generation}; along with the fixed-effect parameter values and the person-specific parameter values [or random-effects]). 

### Modelling of Each Generated Data Set {#data-modelling-exp3}

Each generated data set was modelled using the structured latent growth curve model outlined in Experiment 1 (see [data modelling](#data-modelling) and explanation in Appendix \ref{structured-lgc}). 

### Analysis of Data Modelling Output and Accompanying Visualizations

Analysis and visualization was conducted as outlined in Experiment 1 (see [analysis and visualization](#analysis-visualization)). 

## Results and Discussion

In the sections that follow, I organize the results by presenting them for each level of time structuredness (time-structured data, time-unstructured data resulting from a fast response rate, time-unstructured data resulting from a slow response rate). Importantly, only the results for the day-unit parameters will be presented (i.e., fixed- and random-effect days-to-halfway elevation and halfway-triquarter delta parameters [$\upbeta_{fixed}$, $\upbeta_{random}$, $\upgamma_{fixed}$, $\upgamma_{random}$, respectively]). The results for the likert-unit parameters (i.e., fixed- and random-effect baseline and maximal elevation parameters [$\uptheta_{fixed}$, $\uptheta_{random}$, $\upalpha_{fixed}$, $\upalpha_{random}$, respectively]) were largely trivial and so are presented in Appendix \ref{complete-versions}. 

For each level of time structuredness, I first provide a concise summary of the results and then provide a detailed report of the estimation accuracy of each day-unit parameter of the logistic function. Because the lengths of the detailed reports are considerable, I first provide concise summaries to establish a framework to interpret the detailed reports. The detailed report for the results of each time structuredness level will summarize the results of each (day-unit) parameter's bias/precision plot, report partial $\upomega^2$ values, and then provide a qualitative summary.

### Framework for Interpreting Results

To conduct Experiment 3, the three variables of number of measurements (4 levels), sample size (6 levels), and time structuredness (3 levels) were manipulated, which yielded a total of 72 cells. Importantly, within each cell, bias and precision values were also computed for each of the nine parameters estimated by the structured latent growth curve model (for a review, see [modelling of each generated data set](#modelling-data-sets)). Thus, because the analysis of Experiment 3 computed values for many dependent variables, interpreting the results can become overwhelming. Therefore, I will provide a framework to help the reader efficiently navigate the results section. 

Because I will present the results of Experiment 3 by each level of time structuredness, the framework I will describe in Figure \ref{fig:results-plot-primer-exp-3} shows a template for the bias/precision plots that I will present for each level of time structuredness. The results presented for each time structuredness level contain a bias/precision plot for each of the nine estimated parameters. Each bias/precision plot shows the bias and precision for the estimation of one parameter across all measurement number and nature-of change levels. Within each bias/precision plot, dots indicate the average estimated value (which indicates bias) and error bars represent the middle 95% range of estimated values (which indicates precision). Bias/precision plots with black border show the results for day-unit parameters and plots with gray borders show the results for Likert-unit parameters. Importantly, only the results for the day-unit parameters will be presented (i.e., fixed- and random-effect days-to-halfway elevation and halfway-triquarter delta parameters [$\upbeta_{fixed}$, $\upbeta_{random}$, $\upgamma_{fixed}$, $\upgamma_{random}$, 

```{=tex}
\begin{apaFigure}
[portrait]
[samepage]
[-0.2cm]
{Set of Bias/Precision Plots Constructed for Each Spacing Schedule in Experiment 2}
{results-plot-primer-exp-3}
{.77}
{Figures/logistic_results_plot_exp2}
{A bias/precision plot is constructed for each parameter of the logistic function (see Equation \ref{eq:logFunction-generation}). Bias/precision plots with black borders show the results for day-unit parameters and plots with gray border show the results for Likert-unit parameters. For each parameter, bias and precision are shown across each combination of measurement number and time structuredness.}
\end{apaFigure}
```

\noindent respectively]). The results for the Likert-unit parameters (i.e., fixed- and random-effect baseline and maximal elevation parameters [$\uptheta_{fixed}$, $\uptheta_{random}$, $\upalpha_{fixed}$, $\upalpha_{random}$, respectively]) were largely trivial and so are presented in Appendix \ref{complete-versions}. Therefore, the results of time structuredness level will only present the bias/precision plots for four parameters (i.e., the day-unit parameters). 


### Pre-Processing of Data and Model Convergence

After collecting the output from the simulations, non-converged models
(and their corresponding parameter estimates) were removed from
subsequent analyses. Table \ref{tab:conv-exp-3} in Appendix \ref{convergence-tables} provides the convergence
success rates for each cell in Experiment 3. Model convergence never goes below 90%. 

### Time-Structured Data {#concise-example-exp3}

For time-structured data, Table \ref{tab:summary-table-time-struc-exp3} provides a concise summary of the results for the day-unit parameters (see Figure \ref{fig:exp3_plot_days_time_struc} for the corresponding bias/precision plots). The sections that follow will present the results for each column of Table \ref{tab:summary-table-time-struc-exp3} and provide elaboration when necessary. 

Before presenting the results for equal spacing, I provide a brief description of the concise summary table created for each level of time structuredness and shown below for time-structured data in Table \ref{tab:summary-table-time-struc-exp3}. Text in the 'Unbiased' and 'Precise' columns indicates the measurement number/sample size pairings that, respectively, resulted in unbiased and precise estimation. Emboldened text in the 'Unbiased' and 'Qualitative Description' columns indicates the measurement number/sample size pairing that, respectively, resulted in unbiased estimation and the greatest improvements in bias and precision across 

\noindent

```{r summary-table-time-struc-exp3, echo=F}

errorbar_lengths_nm5_s30 <- compute_errorbar_lengths(exp_analytical_days = exp_3_analytical$days, iv_level = 'Time structured', num_measurements = 5, sample_size = 30)

errorbar_lengths_nm9_s30 <- compute_errorbar_lengths(exp_analytical_days = exp_3_analytical$days, iv_level = 'Time structured', num_measurements = 9, sample_size = 30)
errorbar_lengths_nm7_s30 <- compute_errorbar_lengths(exp_analytical_days = exp_3_analytical$days, iv_level = 'Time structured', num_measurements = 7, sample_size = 30)


errorbar_lengths_ts <- c(paste(errorbar_lengths_nm5_s30$errorbar_length[1]),
                      paste(errorbar_lengths_nm9_s30$errorbar_length[2]),
                      paste(errorbar_lengths_nm7_s30$errorbar_length[3]), 
                      paste(errorbar_lengths_nm9_s30$errorbar_length[4]))
                  


summary_table <- data.frame('Parameter' = c('\\thead[lt]{$\\upbeta_{fixed}$ \\\\ (Figure \\ref{fig:exp3_plot_days_time_struc}A)}',
                                            '\\thead[lt]{$\\gamma_{fixed}$ \\\\ (Figure \\ref{fig:exp3_plot_days_time_struc}B)}', 
                                            '\\thead[lt]{$\\upbeta_{random}$ \\\\ (Figure \\ref{fig:exp3_plot_days_time_struc}C)}', 
                                            '\\thead[lt]{$\\upgamma_{random}$ \\\\ (Figure \\ref{fig:exp3_plot_days_time_struc}D)}'), 
                            
                            'Unbiased' =  c('All cells', 
                                           'All cells', 
                                           'All cells', 
                                           '\\thead[lt]{\\textbf{NM $\\boldsymbol{\\ge}$ 9 with \\textit{N} $\\ge$ 200}}'),
                            
                            'Precise' = c('All cells', 
                                           'NM $\\ge$ 9 with \\textit{N} = 500', 
                                           'No cells',
                                           'No cells'), 
                            
                            'Qualitative Description' = c('Unbiased and precise estimation in all cells', 

                                                      '\\thead[lt]{Largest improvements in precision \\\\ 
                                                      using \\textbf{NM = 7 with \\textit{N} $\\ge$ 200} or \\\\
                                                      \\textbf{NM = 9 with \\textit{N} $\\le$ 100}}', 
                                                     
                                                      'Largest improvements in precision with NM = 7',
                                                     
                                                      '\\thead[lt]{Largest improvements in precision \\\\ 
                                                      using \\textbf{NM = 7 with \\textit{N} $\\ge$ 200} or \\\\
                                                      \\textbf{NM = 9 with \\textit{N} $\\le$ 100}}'),
                            
                            'Error Bar Length' = errorbar_lengths_ts,
                            
                            check.names = F)

kbl(x = summary_table, format = 'latex',
       longtable = T, booktabs = T, centering = T, escape = F,
       align = c('l', rep('l', times = ncol(summary_table) - 1)), 
    caption = 'Concise Summary of Results for Time-Structured Data in Experiment 3') %>%
  #header
     column_spec(column = 1, width = '3cm') %>%
  column_spec(column = 2, width = '5cm') %>%
  column_spec(column = 3, width = '5cm') %>%
  column_spec(column = 4, width = '6.5cm') %>%
  column_spec(column = 5, width = '3cm') %>%
  add_header_above(header = c(' ' = 3, 'Description' = 2)) %>%
  footnote(escape = F, threeparttable = T, general_title = '',
           general = "\\\\textit{Note. }Text in the `Unbiased' and `Precise' columns indicates the measurement number/sample size pairings that, respectively, resulted in unbiased and precise estimation. Emboldened text in the `Unbiased' and `Qualitative Description' columns indicates the number of measurements that, respectively, resulted in unbiased estimation and the greatest improvements in bias and precision across all day-unit parameters (acceptable precision was not obtained in the estimation of all day-unit parameters with time-structured data). `Error Bar Length' column indicates the maximum error bar length that resulted from using the measurement number/sample size recommendation listed in the `Qualitative Description' column. Parameter names and population values are as follows: $\\\\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter = 180; $\\\\upgamma_{fixed}$ = fixed-effect halfway-triquarter delta parameter = 20; $\\\\upbeta_{random}$ = random-effect days-to-halfway elevation parameter = 10; $\\\\upgamma_{random}$ = random-effect halfway-triquarter delta parameter = 4. NM = number of measurements.") %>% 
  kable_styling(position = 'left') %>%
  landscape(margin = '2.54cm')
```

all day-unit parameters (acceptable precision was not obtained in the estimation of all day-unit parameters with time-structured data). The 'Error Bar Length' column indicates the error bar length that results from using the lower-bounding measurement number/sample size pairing listed in the 'Qualitative Description' column (i.e., the maximum error bar length).


##### Bias {#bias-time-struc-exp3}

Before presenting the results for bias, I provide a description of the set of bias/precision plots shown in Figure \ref{fig:exp3_plot_days_time_struc} and in the results sections for the other level of time structuredness in Experiment 3. Figure \ref{fig:exp3_plot_days_time_struc} shows the bias/precision plots for each day-unit parameter and Table \ref{tab:omega-exp2-equal} provides the partial $\upomega^2$ values for each independent variable of each day-unit parameter. In Figure \ref{fig:exp3_plot_days_time_struc}, blue horizontal lines indicate the population values for each parameter (with population values of $\upbeta_{fixed}$ = 180.00, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, and $\upgamma_{random}$ = 4.00). Gray bands indicate the $\pm 10\%$ margin of error for each parameter and unfilled dots indicate cells with average parameter estimates outside of the margin. Error bars represent the middle 95% of estimated values, with light blue error bars indicating imprecise estimation. I considered dots that fell outside the gray bands as biased and error bar lengths with at least one whisker length exceeding the 10% cutoff (i.e., or longer than the portion of the gray band underlying the whisker) as imprecise. Panels A--B show the bias/precision plots for the fixed- and random-effect days-to-halfway elevation parameters ($\upbeta_{fixed}$ and $\upbeta_{random}$, respectively). Panels C--D show the bias/precision plots for the fixed- and random-effect triquarter-halfway delta parameters ($\upgamma_{fixed}$ and $\upgamma_{random}$, respectively). Note that random-effect parameter units are in standard deviation units.

```{r figure-time-struc-exp3, include=F, eval=F}
generate_day_likert_facet_plot(analytical_data = exp_3_analytical, 
                               target_col = 'time_structuredness', target_value = 'Time structured',
                                                              x_axis_name = expression("Sample Size ("*italic(N)*")"), 

                               x_axis_var = 'sample_size', exp_num = 'exp3_', beta_lower = 160, beta_upper = 210,
                                beta_ticks = 5)
```

```{=tex}
\begin{apaFigure}
[portrait]
[samepage]
[-0.2cm]
{Bias/Precision Plots for Day-Unit Parameters With Time-Structured Data in Experiment 3}
{exp3_plot_days_time_struc}
{0.165}
{Figures/exp3_plot_days_time structured}
{Panel A: Bias/precision plot for the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$). Panel B: Bias/precision plot for the fixed-effect triquarter-halfway elevation parameter ($\upgamma_{fixed}$). Panel C: Bias/precision plot for the random-effect days-to-halfway elevation parameter ($\upbeta_{random}$). Panel D: Bias/precision plot for the random-effect triquarter-halfway elevation parameter ($\upgamma_{random}$). Blue horizontal lines in each panel represent the population value for each parameter. Population values for each day-unit parameter are as follows: $\upbeta_{fixed}$ = 180.00, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, $\upgamma_{random}$ = 4.00. Gray bands indicate the $\pm 10\%$ margin of error for each parameter and unfilled dots indicate cells with average parameter estimates outside of the margin or biased estimates. Error bars represent the middle 95\% of estimated values, with light blue error bars indicating imprecise estimation. I considered dots that fell outside the gray bands as biased and error bar lengths with at least one whisker length exceeding the 10\% cutoff (i.e., or longer than the portion of the gray band underlying the whisker) as imprecise. Note that random-effect parameter units are in standard deviation units. See Table \ref{tab:param-exp-3} for specific values estimated for each parameter and Table \ref{tab:omega-exp3-time-struc} for $\upomega^2$ effect size values.}
\end{apaFigure}
```

```{r omega-exp3-time-struc, echo=F}
print_bias_var_omega_table(exp_data = exp_3_raw, target_col = 'time_structuredness', target_value = 'time_structured', 
ind_vars = c('number_measurements', 'sample_size'), 
ind_var_acronyms = c('NM', 'S', 'NM x S'), 
caption = 'Partial $\\upomega^2$ Values for Manipulated Variables With Time-Structured Data in Experiment 3',
footnote = '\\\\textit{Note. }NM = number of measurements $\\\\in$ \\\\{5, 7, 9, 11\\\\},  S = sample size $\\\\in$ \\\\{30, 50, 100, 200, 500, 1000\\\\}, NM x S = interaction between number of measurements and sample size.', 
parameter_labels = c('$\\upbeta_{fixed}$ (Figure \\ref{fig:exp3_plot_days_time_struc}A)',
                     '$\\upbeta_{random}$ (Figure \\ref{fig:exp3_plot_days_time_struc}B)',
                     '$\\upgamma_{fixed}$ (Figure \\ref{fig:exp3_plot_days_time_struc}C)',
                     '$\\upgamma_{random}$ (Figure \\ref{fig:exp3_plot_days_time_struc}D)'))

```


With respect to bias for time-structured data, estimates were biased (i.e., above the acceptable 10% cutoff) for each day-unit parameter in the following cells:

* fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$; Figure \ref{fig:exp3_plot_days_time_struc}A): no cells. 
* fixed-effect halfway-triquarter delta parameter ($\upgamma_{fixed}$; Figure \ref{fig:exp3_plot_days_time_struc}B): no cells.
* random-effect days-to-halfway elevation parameter ($\upbeta_{random}$; Figure \ref{fig:exp3_plot_days_time_struc}C): no cells. 
* random-effect triquarter-halfway elevation parameter ($\upgamma_{random}$; Figure \ref{fig:exp3_plot_days_time_struc}D): five and seven measurements across all sample sizes and nine and 11 measurements with $N \le 100$.

In summary, with time-structured data, estimation of all the day-unit parameters across all manipulated nature-of-change values were unbiased using at least nine measurements with $N \ge 200$, which is indicated by the emboldened text in the 'Unbiased' column of Table \ref{tab:summary-table-time-struc-exp3}. 


##### Precision {#precision-time-struc-exp3}

With respect to precision for time-structured data, estimates were imprecise (i.e., error bar length with at least one whisker length exceeding 10% of a parameter's population value) in the following cells for each day-unit parameter: 

* fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$; Figure \ref{fig:exp3_plot_days_time_struc}A): no cells. 
* fixed-effect halfway-triquarter delta parameter ($\upgamma_{fixed}$; Figure \ref{fig:exp3_plot_days_time_struc}B): five and seven measurements across all sample sizes and nine and 11 measurements with $N \le 200$.
* random-effect days-to-halfway elevation parameter ($\upbeta_{random}$; Figure \ref{fig:exp3_plot_days_time_struc}C): all cells. 
* random-effect halfway-triquarter delta parameter [$\upgamma_{random}$] in Figure \ref{fig:exp3_plot_days_time_struc}D): all cells. 

In summary, with time-structured data, precise estimation for the fixed-effect day-unit parameters resulted from using at least nine measurements with $N \ge 500$, but no manipulated measurement number/sample size pairing resulted in precise estimation of the random-effect day-unit parameters (see the 'Precise' column of Table \ref{tab:summary-table-time-struc-exp3}). 


##### Qualitative Description {#qualitative-time-struc-exp3}

For time-structured data in Figure \ref{fig:exp3_plot_days_time_struc}, although no manipulated measurement number resulted in precise estimation of all the day-unit parameters, the largest improvements in precision (and bias) resulted from using moderate measurement number/sample size pairings. With respect to bias under time-structured data, the largest improvements resulted with the following measurement number/sample size pairing(s) for the random-effect triquarter-halfway delta parameter ($\upgamma_{fixed}$): 

* random-effect triquarter-halfway delta parameter ($\upgamma_{random}$): seven measurements with $N \ge 100$ or nine measurements with $N \le 50$. 

\noindent With respect to precision under time-structured data, the largest improvements in the estimation of all the day-unit parameters (except the fixed-effect days-to-halfway elevation parameter [$\upbeta_{fixed}$]) resulted from using the following measurement number/sample size pairings:

* fixed-effect triquarter-halfway delta parameter ($\upgamma_{fixed}$): seven measurements with $N \ge 200$ or nine measurements with $N \le 100$, which resulted in a maximum error bar length of `r errorbar_lengths_ts[2]` days. 
* random-effect days-to-halfway elevation parameter ($\upbeta_{random}$): seven measurements across all manipulated sample sizes, which resulted in a error bar length of `r errorbar_lengths_ts[3]` days.
* random-effect triquarter-halfway delta parameter ($\upgamma_{random}$):  seven measurements with $N \ge 200$ or nine measurements with $N \le 100$, which resulted in a maximum error bar length of `r errorbar_lengths_ts[4]` days.

For an applied researcher, one plausible question might be what measurement number/sample size pairing(s) results in the greatest improvements in bias and precision in the estimation of all day-unit parameters with time-structured data. In looking across the measurement number/sample size pairings in the above lists, it becomes apparent that the greatest improvements in bias and precision in the estimation of all day-unit parameters resulted from using seven measurements with $N \ge 200$ or nine measurements with $N \le 100$ (see the emboldened text in the 'Qualitative Description' column of Table \ref{tab:summary-table-time-struc-exp3}).

#### Summary of Results for Time-Structured Data

In summarizing the results for time-structured data, estimation of all the day-unit parameters was unbiased using at least nine measurements with $N \ge 200$ (see [bias](#bias-time-struc-exp3)). Precise estimation was never obtained in the estimation of all day-unit parameters with any manipulated measurement number/sample size pairing (see [precision](#precision-time-struc-exp3)). Although it may be discouraging that no manipulated measurement number/sample size pairing under equal spacing resulted in precise estimation of all the day-unit parameters, the largest improvements in precision (and bias) across all the day-unit parameters resulted from using moderate measurement number/sample size pairings. With time-structured data, the largest improvements in bias and precision in the estimation of all the day-unit parameters resulted from using seven measurements with $N \ge 200$ or nine measurements with $N \le 100$ (see [qualitiative description](#qualitative-time-struc-exp3)). 


### Time-Unstructured Data Characterized by a Fast Response Rate

For time-unstructured data characterized by a fast response rate, Table \ref{tab:summary-table-fast-exp3} provides a concise summary of the results for the day-unit parameters (see Figure \ref{fig:exp3_plot_days_fast} for the corresponding bias/precision plots). The sections that follow will present the results for each column of Table \ref{tab:summary-table-fast-exp3} and provide elaboration when necessary (for a description of Table \ref{tab:summary-table-fast-exp3}, see [concise summary](#concise-example-exp3)). 

#### Bias {#bias-fast-exp3}

With respect to bias for time-unstructured data characterized by a fast response rate, estimates were biased (i.e., above the acceptable 10% cutoff) for each day-unit parameter in the following cells:

* fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$; Figure \ref{fig:exp3_plot_days_fast}A): no cells. 
* fixed-effect halfway-triquarter delta parameter ($\upgamma_{fixed}$; Figure \ref{fig:exp3_plot_days_fast}B): no cells.
* random-effect days-to-halfway elevation parameter ($\upbeta_{random}$; Figure \ref{fig:exp3_plot_days_fast}C): no cells.


```{r summary-table-fast-exp3, echo=F}

errorbar_lengths_nm5_s30 <- compute_errorbar_lengths(exp_analytical_days = exp_3_analytical$days, iv_level = 'fast response', num_measurements = 5, sample_size = 30)

errorbar_lengths_nm9_s30 <- compute_errorbar_lengths(exp_analytical_days = exp_3_analytical$days, iv_level = 'fast response', num_measurements = 9, sample_size = 30)
errorbar_lengths_nm7_s30 <- compute_errorbar_lengths(exp_analytical_days = exp_3_analytical$days, iv_level = 'fast response', num_measurements = 7, sample_size = 30)


errorbar_lengths_fast <- c(paste(errorbar_lengths_nm5_s30$errorbar_length[1]), 
                      paste(errorbar_lengths_nm9_s30$errorbar_length[2]), 
                      paste(errorbar_lengths_nm7_s30$errorbar_length[3]), 
                      paste(errorbar_lengths_nm9_s30$errorbar_length[4]))
                    
summary_table <- data.frame('Parameter' = c('\\thead[lt]{$\\upbeta_{fixed}$ \\\\ (Figure \\ref{fig:exp3_plot_days_fast}A)}',
                                            '\\thead[lt]{$\\gamma_{fixed}$ \\\\  (Figure \\ref{fig:exp3_plot_days_fast}B)}', 
                                            '\\thead[lt]{$\\upbeta_{random}$ \\\\ (Figure \\ref{fig:exp3_plot_days_fast}C)}', 
                                            '\\thead[lt]{$\\upgamma_{random}$ \\\\ (Figure \\ref{fig:exp3_plot_days_fast}D)}'), 
                            
                            'Unbiased' = c('All cells', 
                                           'All cells', 
                                           'All cells', 
                                          '\\thead[lt]{
                                            \\textbf{NM $\\ge$ 7 with \\textit{N} = 1000} or \\\\
                                            \\textbf{NM $\\ge$ 9 with \\textit{N} $\\ge$ 200} or \\\\
                                            \\textbf{NM = 11 with \\textit{N} = 100}}'),

                            'Precise' = c('All cells', 
                                          'NM $\\ge$ 9 with \\textit{N} $\\ge$ 500',
                                          'No cells',
                                          'No cells'), 
                            
                            'Qualitative Description' = c('Unbiased and precise estimation in all cells', 

                                                      '\\thead[lt]{Largest improvements in precision \\\\ 
                                                      using \\textbf{NM = 7 with \\textit{N} $\\ge$ 200} or \\\\
                                                      \\textbf{NM = 9 with \\textit{N} $\\le$ 100}}', 
                                                     
                                                      'Largest improvements in precision with NM = 7',
                                                     
                                                      '\\thead[lt]{Largest improvements in precision \\\\ 
                                                      using \\textbf{NM = 7 with \\textit{N} $\\ge$ 200} or \\\\
                                                      \\textbf{NM = 9 with \\textit{N} $\\le$ 100}}'),
                            
                            'Error Bar Length' = errorbar_lengths_fast,
                            
                          
                            check.names = F)

kbl(x = summary_table, format = 'latex',
       longtable = T, booktabs = T, centering = T, escape = F,
       align = c('l', rep('l', times = ncol(summary_table) - 1)), 
    caption = 'Concise Summary of Results for Time-Unstructured Data (Fast Response Rate) in Experiment 3') %>%
 #header
     column_spec(column = 1, width = '3cm') %>%
  column_spec(column = 2, width = '5cm') %>%
  column_spec(column = 3, width = '5cm') %>%
  column_spec(column = 4, width = '6.5cm') %>%
  column_spec(column = 5, width = '3cm') %>%
  add_header_above(header = c(' ' = 3, 'Description' = 2)) %>%
  footnote(escape = F, threeparttable = T, general_title = '',
           general = "\\\\textit{Note. }Text in the `Unbiased' and `Precise' columns indicates the measurement number/sample size pairings that, respectively, resulted in unbiased and precise estimation. Emboldened text in the `Unbiased' and `Qualitative Description' columns indicates the number of measurements that, respectively, resulted in unbiased estimation and the greatest improvements in bias and precision across all day-unit parameters (acceptable precision was not obtained in the estimation of all day-unit parameters with time-unstructured data characterized by a fast response rate). `Error Bar Length' column indicates the maximum error bar length that resulted from using the measurement number/sample size recommendation listed in the `Qualitative Description' column. Parameter names and population values are as follows: $\\\\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter = 180; $\\\\upgamma_{fixed}$ = fixed-effect halfway-triquarter delta parameter = 20; $\\\\upbeta_{random}$ = random-effect days-to-halfway elevation parameter = 10; $\\\\upgamma_{random}$ = random-effect halfway-triquarter delta parameter = 4. NM = number of measurements.") %>% 
  kable_styling(position = 'left') %>%
  landscape(margin = '2.54cm')

```


* random-effect triquarter-halfway elevation parameter ($\upgamma_{random}$; Figure \ref{fig:exp3_plot_days_fast}D): five measurements across all sample sizes, seven measurements with $N \le 500$, nine measurements with $N \ge 100$, and 11 measurements with $N \le 50$.

\noindent Importantly, for the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$), although bias was still within the acceptable margin of error, bias appeared to be constant across all manipulated measurement number/sample size pairings. In comparing the bias/precision plots between time-unstructured data characterized by a fast response rate (Figure \ref{fig:exp3_plot_days_fast}A) and time-structured data (Figure \ref{fig:exp3_plot_days_time_struc}A), the systematic decline in bias observed for fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$) appeared to result from thedecrease in time structuredness. 

In summary, with time-unstructured data characterized by a fast response rate, estimation of all the day-unit parameters across all manipulated nature-of-change values was unbiased using at least seven measurements with $N = 1000$, nine measurements with $N \ge 200$, or 11 measurements with $N \ge 100$, which is indicated by the emboldened text in the 'Unbiased' column of Table \ref{tab:summary-table-fast-exp3}. 

#### Precision {#precision-fast-exp3}

With respect to precision for time-unstructured data characterized by a fast response rate, estimates were imprecise (i.e., error bar length with at least one whisker length exceeding 10% of a parameter's population value) in the following cells for each day-unit parameter: 

* fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$; Figure \ref{fig:exp3_plot_days_fast}A): no cells. 
* fixed-effect halfway-triquarter delta parameter ($\upgamma_{fixed}$; Figure \ref{fig:exp3_plot_days_fast}B): five and seven measurements across all sample sizes and nine and 11 measurements with $N \le 200$.

```{r plots-fast-response-exp3, include=F, eval=F}
generate_day_likert_facet_plot(analytical_data = exp_3_analytical, 
                               target_col = 'time_structuredness', target_value = 'Time unstructured (fast response)',
                              x_axis_name = expression("Sample Size ("*italic(N)*")"), 
                               x_axis_var = 'sample_size', exp_num = 'exp3_', beta_lower = 160, beta_upper = 210,
                                 beta_ticks = 5)
```

```{=tex}
\begin{apaFigure}
[portrait]
[samepage]
[-0.2cm]
{Bias/Precision Plots for Day-Unit Parameters With Time-Unstructured Data Characterized by a Fast Response Rate in Experiment 3}
{exp3_plot_days_fast}
{0.165}
{Figures/exp3_plot_days_time unstructured (fast response)}
{Panel A: Bias/precision plot for the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$). Panel B: Bias/precision plot for the fixed-effect triquarter-halfway elevation parameter ($\upgamma_{fixed}$). Panel C: Bias/precision plot for the random-effect days-to-halfway elevation parameter ($\upbeta_{random}$). Panel D: Bias/precision plot for the random-effect triquarter-halfway elevation parameter ($\upgamma_{random}$). Blue horizontal lines in each panel represent the population value for each parameter. Population values for each day-unit parameter are as follows: $\upbeta_{fixed}$ = 180.00, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, $\upgamma_{random}$ = 4.00. Gray bands indicate the $\pm 10\%$ margin of error for each parameter and unfilled dots indicate cells with average parameter estimates outside of the margin or biased estimates. Error bars represent the middle 95\% of estimated values, with light blue error bars indicating imprecise estimation. I considered dots that fell outside the gray bands as biased and error bar lengths with at least one whisker length exceeding the 10\% cutoff (i.e., or longer than the portion of the gray band underlying the whisker) as imprecise. Note that random-effect parameter units are in standard deviation units. See Table \ref{tab:param-exp-3} for specific values estimated for each parameter and Table \ref{tab:omega-exp3-fast} for $\upomega^2$ effect size values.}
\end{apaFigure}
```

```{r omega-exp3-fast, echo=F}
print_bias_var_omega_table(exp_data = exp_3_raw, target_col = 'time_structuredness', target_value = 'fast_response', 
ind_vars = c('number_measurements', 'sample_size'), 
ind_var_acronyms = c('NM', 'S', 'NM x S'), 
caption = 'Partial $\\upomega^2$ Values for Manipulated Variables With Time-Unstructured Data Characterized by a Fast Response Rate in Experiment 3',
footnote = '\\\\textit{Note. }NM = number of measurements $\\\\in$ \\\\{5, 7, 9, 11\\\\},  S = sample size $\\\\in$ \\\\{30, 50, 100, 200, 500, 1000\\\\}, NM x S = interaction between number of measurements and sample size.', 
parameter_labels = c('$\\upbeta_{fixed}$ (Figure \\ref{fig:exp3_plot_days_fast}A)',
                     '$\\upbeta_{random}$ (Figure \\ref{fig:exp3_plot_days_fast}B)',
                     '$\\upgamma_{fixed}$ (Figure \\ref{fig:exp3_plot_days_fast}C)',
                     '$\\upgamma_{random}$ (Figure \\ref{fig:exp3_plot_days_fast}D)'))

```


* random-effect days-to-halfway elevation parameter ($\upbeta_{random}$; Figure \ref{fig:exp3_plot_days_fast}C): all cells. 
* random-effect halfway-triquarter delta parameter [$\upgamma_{random}$] in Figure \ref{fig:exp3_plot_days_fast}D): all cells. 

In summary, with time-unstructured data characterized by a fast response rate, precise estimation for the fixed-effect day-unit parameters resulted from using at least nine measurements with $N \ge 500$, but no manipulated measurement number/sample size pairing resulted in precise estimation of the random-effect day-unit parameters (see the 'Precise' column of Table \ref{tab:summary-table-fast-exp3}). 
 

#### Qualitative Description {#qualitative-fast-exp3}

For time-unstructured data characterized by a fast response rate (see Figure \ref{fig:exp3_plot_days_fast}), although no manipulated measurement number resulted in precise estimation of all the day-unit parameters, the largest improvements in precision (and bias) resulted from using moderate measurement number/sample size pairings. With respect to bias under time-unstructured data characterized by a fast response rate, the largest improvements in bias resulted with the following measurement number/sample size pairing(s) for the random-effect triquarter-halfway delta parameter ($\upgamma_{fixed}$): 

* random-effect triquarter-halfway delta parameter ($\upgamma_{random}$): seven measurements with $N \ge 100$ or nine measurements with $N \le 50$. 

\noindent With respect to precision under time-unstructured data characterized by a fast response rate, the largest improvements in the estimation of all the day-unit parameters (except the fixed-effect days-to-halfway elevation parameter [$\upbeta_{fixed}$]) resulted from using the following measurement number/sample size pairings:

* fixed-effect triquarter-halfway delta parameter ($\upgamma_{fixed}$): seven measurements with $N \ge 200$ or nine measurements with $N \le 100$, which resulted in a maximum error bar length of `r errorbar_lengths_fast[2]` days. 
* random-effect days-to-halfway elevation parameter ($\upbeta_{random}$): seven measurements across all manipulated sample sizes, which resulted in a maximum error bar length of `r errorbar_lengths_fast[3]` days.
* random-effect triquarter-halfway delta parameter ($\upgamma_{random}$):  seven measurements with $N \ge 200$ or nine measurements with $N \le 100$, which resulted in a maximum error bar length of `r errorbar_lengths_fast[4]` days.

For an applied researcher, one plausible question might be what measurement number/sample size pairing(s) results in the greatest improvements in bias and precision in the estimation of all day-unit parameters with time-unstructured data characterized by a fast response rate. In looking across the measurement number/sample size pairings in the above lists, it becomes apparent that greatest improvements in bias and precision in the estimation of all day-unit parameters resulted from using seven measurements with $N \ge 200$ or nine measurements with $N \le 100$ (see the emboldened text in the 'Qualitative Description' column of Table \ref{tab:summary-table-fast-exp3}).

#### Summary of Results for Time-Unstructured Characterized by a Fast Response Rate

In summarizing the results for time-unstructured data characterized by a fast response rate, estimation of all the day-unit parameters was unbiased using least seven measurements with $N = 1000$, nine measurements with $N \ge 200$, or 11 measurements with $N \ge 100$ (see [bias](#bias-fast-exp3)). Importantly, bias for some day-unit parameters was constant across manipulated measurement number/sample size pairings. Precise estimation was never obtained in the estimation of all day-unit parameters with any manipulated measurement number/sample size pairing (see [precision](#precision-fast-exp3)). Although it may be discouraging that no manipulated measurement number/sample size pairing resulted in precise estimation of all the day-unit parameters with time-unstructured data characterized by a fast response rate, the largest improvements in precision (and bias) across all day-unit parameters resulted with moderate measurement number/sample size pairings. With time-unstructured data characterized by a fast response rate, the largest improvements in bias and precision in the estimation of all day-unit parameters resulted from using seven measurements with $N \ge 200$ or nine measurements with $N \le 100$ (see [qualitiative description](#qualitative-fast-exp3)). 


### Time-Unstructured Data Characterized by a Slow Response Rate

For time-unstructured data characterized by a slow response rate, Table \ref{tab:summary-table-slow-exp3} provides a concise summary of the results for the day-unit parameters (see Figure \ref{fig:exp3_plot_days_slow} for the corresponding bias/precision plots). The sections that follow will present the results for each column of Table \ref{tab:summary-table-slow-exp3} and provide elaboration when necessary (for a description of Table \ref{tab:summary-table-slow-exp3}, see [concise summary](#concise-example-exp3)). 

#### Bias {#bias-slow-exp3}

With respect to bias for time-unstructured data characterized by a slow response rate, estimates were biased (i.e., above the acceptable 10% cutoff) for each day-unit parameter in the following cells: 

* fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$; Figure \ref{fig:exp3_plot_days_slow}A): no cells. 
* fixed-effect halfway-triquarter delta parameter ($\upgamma_{fixed}$; Figure \ref{fig:exp3_plot_days_slow}B): no cells.
* random-effect days-to-halfway elevation parameter ($\upbeta_{random}$; Figure \ref{fig:exp3_plot_days_slow}C): no cells. 
* random-effect triquarter-halfway elevation parameter ($\upgamma_{random}$; Figure \ref{fig:exp3_plot_days_slow}D): five measurements across all sample sizes, seven measurements with $N \le 500$, nine measurements with $N \ge 100$, and 11 measurements with $N \le 50$.

\noindent Note that, for all parameters except the halfway-triquarter delta parameter ($\upgamma_{fixed}$), bias appeared to be constant across all manipulated measurement number/sample size pairings.

In summary, with time-unstructured data characterized by a slow response rate, estimation of all the day-unit parameters across all manipulated nature-of-change values was unbiased using at least seven measurements with $N = 1000$, nine measurements with $N \ge 200$, or 11 measurements with $N \ge 100$, which is indicated by the emboldened text 

```{r summary-table-slow-exp3, echo=F}
errorbar_lengths_nm5_s30 <- compute_errorbar_lengths(exp_analytical_days = exp_3_analytical$days, iv_level = 'slow response', num_measurements = 5, sample_size = 30)

errorbar_lengths_nm9_s30 <- compute_errorbar_lengths(exp_analytical_days = exp_3_analytical$days, iv_level = 'slow response', num_measurements = 9, sample_size = 30)
errorbar_lengths_nm7_s30 <- compute_errorbar_lengths(exp_analytical_days = exp_3_analytical$days, iv_level = 'slow response', num_measurements = 7, sample_size = 30)


errorbar_lengths_slow <- c(paste(errorbar_lengths_nm5_s30$errorbar_length[1]), 
                      paste(errorbar_lengths_nm9_s30$errorbar_length[2]), 
                      paste(errorbar_lengths_nm7_s30$errorbar_length[3]), 
                      paste(errorbar_lengths_nm9_s30$errorbar_length[4]))

summary_table <- data.frame('Parameter' = c('\\thead[lt]{$\\upbeta_{fixed}$ \\\\ (Figure \\ref{fig:exp3_plot_days_slow}A)}',
                                            '\\thead[lt]{$\\gamma_{fixed}$ \\\\ (Figure \\ref{fig:exp3_plot_days_slow}B)}', 
                                            '\\thead[lt]{$\\upbeta_{random}$ \\\\ (Figure \\ref{fig:exp3_plot_days_slow}C)}', 
                                            '\\thead[lt]{$\\upgamma_{random}$ \\\\ (Figure \\ref{fig:exp3_plot_days_slow}D)}'), 
                            
                            'Unbiased' = c('All cells', 
                                           'All cells except NM = 5 with \\textit{N} = 50', 
                                           'No cells except NM = 5 with \\textit{N} = 30 and NM = 11 with \\textit{N} $\\le$ 50', 
                                           'No cells'),
                            
                            'Precise' = c('All cells', 
                                            '\\thead[lt]{NM = 7 with \\textit{N} = 200 or \\\\ 
                                            NM = 9 with \\textit{N} $\\le$ 500}', 
                                            'No cells',
                                            'No cells'), 
                            
                            'Qualitative Summary' = c('Low bias and high precision in all cells', 

                                                      '\\thead[lt]{Largest improvements in precision \\\\ 
                                                      using \\textbf{NM = 7 with \\textit{N} $\\ge$ 200} or \\\\
                                                      \\textbf{NM = 9 with \\textit{N} $\\le$ 100}}', 
                                                     
                                                      'Largest improvements in precision with NM = 7',
                                                     
                                                      '\\thead[lt]{Largest improvements in bias and \\\\
                                                      precision using NM = 7 with \\textit{N} $\\boldsymbol{\\ge}$ 200 or \\\\
                                                      M = 9 with \\textit{N} $\\boldsymbol{\\le}$ 100}'),
                            
                            'Error Bar Length' = errorbar_lengths_slow,
                            
                            check.names = F)

kbl(x = summary_table, format = 'latex',
       longtable = T, booktabs = T, centering = T, escape = F,
       align = c('l', rep('l', times = ncol(summary_table) - 1)),
    caption = 'Concise Summary of Results for Time-Unstructured Data (Slow Response Rate) in Experiment 3') %>%
   #header
  column_spec(column = 1, width = '3cm') %>%
  column_spec(column = 2, width = '5cm') %>%
  column_spec(column = 3, width = '5cm') %>%
  column_spec(column = 4, width = '6.5cm') %>%
  column_spec(column = 5, width = '3cm') %>%
  add_header_above(header = c(' ' = 3, 'Description' = 2)) %>%
  
add_header_above(header = c(' ' = 3, 'Summary' = 2)) %>%
   footnote(escape = F, threeparttable = T, general_title = '',
           general = "\\\\textit{Note. }Text in the `Unbiased' and `Precise' columns indicates the measurement number/sample size pairings that, respectively, resulted in unbiased and precise estimation. Emboldened text in the `Unbiased' and `Qualitative Description' columns indicates the number of measurements that, respectively, resulted in unbiased estimation and the greatest improvements in bias and precision across all day-unit parameters (acceptable precision was not obtained in the estimation of all day-unit parameters with time-unstructured data characterized by a slow response rate). `Error Bar Length' column indicates the maximum error bar length that resulted from using the measurement number/sample size recommendation listed in the `Qualitative Description' column. Parameter names and population values are as follows: $\\\\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter = 180; $\\\\upgamma_{fixed}$ = fixed-effect halfway-triquarter delta parameter = 20; $\\\\upbeta_{random}$ = random-effect days-to-halfway elevation parameter = 10; $\\\\upgamma_{random}$ = random-effect halfway-triquarter delta parameter = 4. NM = number of measurements.") %>% 
  kable_styling(position = 'left') %>%
  kable_styling(position = 'left') %>%
  landscape(margin = '2.54cm')
```


```{r plots-slow-response-exp3, include=F, eval=F}
generate_day_likert_facet_plot(analytical_data = exp_3_analytical, 
                               target_col = 'time_structuredness', target_value = 'Time unstructured (slow response)',
                              x_axis_name = expression("Sample Size ("*italic(N)*")"), 
                               x_axis_var = 'sample_size', exp_num = 'exp3_', beta_lower = 160, beta_upper = 210,
                                 beta_ticks = 5)

generate_day_likert_facet_plot(analytical_data = exp_3_def_analytical, 
                               target_col = 'time_structuredness', target_value = 'Time unstructured (slow response)',
                              x_axis_name = expression("Sample Size ("*italic(N)*")"), 
                               x_axis_var = 'sample_size', exp_num = 'exp3_def', beta_lower = 160, beta_upper = 210,
                                 beta_ticks = 5)

```

```{=tex}
\begin{apaFigure}
[portrait]
[samepage]
[-0.2cm]
{Bias/Precision Plots for Day-Unit Parameters With Time-Unstructured Data Characterized by a Slow Response Rate in Experiment 3}
{exp3_plot_days_slow}
{0.165}
{Figures/exp3_plot_days_time unstructured (slow response)}
{Panel A: Bias/precision plot for the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$). Panel B: Bias/precision plot for the fixed-effect triquarter-halfway elevation parameter ($\upgamma_{fixed}$). Panel C: Bias/precision plot for the random-effect days-to-halfway elevation parameter ($\upbeta_{random}$). Panel D: Bias/precision plot for the random-effect triquarter-halfway elevation parameter ($\upgamma_{random}$). Blue horizontal lines in each panel represent the population value for each parameter. Population values for each day-unit parameter are as follows: $\upbeta_{fixed}$ = 180.00, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, $\upgamma_{random}$ = 4.00. Gray bands indicate the $\pm 10\%$ margin of error for each parameter and unfilled dots indicate cells with average parameter estimates outside of the margin or biased estimates. Error bars represent the middle 95\% of estimated values, with light blue error bars indicating imprecise estimation. I considered dots that fell outside the gray bands as biased and error bar lengths with at least one whisker length exceeding the 10\% cutoff (i.e., or longer than the portion of the gray band underlying the whisker) as imprecise. Note that random-effect parameter units are in standard deviation units. See Table \ref{tab:param-exp-3} for specific values estimated for each parameter and Table \ref{tab:omega-exp3-slow} for $\upomega^2$ effect size values.}
\end{apaFigure}
```

```{r omega-exp3-slow, echo=F}
print_bias_var_omega_table(exp_data = exp_3_raw, target_col = 'time_structuredness', target_value = 'fast_response', 
ind_vars = c('number_measurements', 'sample_size'), 
ind_var_acronyms = c('NM', 'S', 'NM x S'), 
caption = 'Partial $\\upomega^2$ Values for Manipulated Variables With Time-Unstructured Data Characterized by a Slow Response Rate in Experiment 3',
footnote = '\\\\textit{Note. }NM = number of measurements $\\\\in$ \\\\{5, 7, 9, 11\\\\},  S = sample size $\\\\in$ \\\\{30, 50, 100, 200, 500, 1000\\\\}, NM x S = interaction between number of measurements and sample size.', 
parameter_labels = c('$\\upbeta_{fixed}$ (Figure \\ref{fig:exp3_plot_days_slow}A)',
                     '$\\upbeta_{random}$ (Figure \\ref{fig:exp3_plot_days_slow}B)',
                     '$\\upgamma_{fixed}$ (Figure \\ref{fig:exp3_plot_days_slow}C)',
                     '$\\upgamma_{random}$ (Figure \\ref{fig:exp3_plot_days_slow}D)'))

```

in the 'Unbiased' column of Table \ref{tab:summary-table-slow-exp3}. 

#### Precision {#precision-slow-exp3}

With respect to precision for time-unstructured data characterized by a slow response rate, estimates were imprecise (i.e., error bar length with at least one whisker length exceeding 10% of a parameter's population value) in the following cells for each day-unit parameter: 

* fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$; Figure \ref{fig:exp3_plot_days_slow}A): no cells. 
* fixed-effect halfway-triquarter delta parameter ($\upgamma_{fixed}$; Figure \ref{fig:exp3_plot_days_slow}B): five and seven measurements across all sample sizes and nine and 11 measurements with $N \le 200$.
* random-effect days-to-halfway elevation parameter ($\upbeta_{random}$; Figure \ref{fig:exp3_plot_days_slow}C): all cells. 
* random-effect halfway-triquarter delta parameter [$\upgamma_{random}$] in Figure \ref{fig:exp3_plot_days_slow}D): all cells. 

In summary, with time-unstructured data characterized by a slow response rate, precise estimation for the fixed-effect day-unit parameters resulted from using at least nine measurements with $N \ge 500$, but no manipulated measurement number/sample size pairing resulted in precise estimation of the random-effect day-unit parameters (see the 'Precise' column of Table \ref{tab:summary-table-slow-exp3}). 


#### Qualitative Description {#qualitative-slow-exp3}

For time-unstructured data characterized by a slow response rate (see Figure \ref{fig:exp3_plot_days_slow}), although no manipulated measurement number resulted in precise estimation of all the day-unit parameters, the largest improvements in precision (and bias) resulted from using moderate measurement number/sample size pairings. With respect to bias under time-unstructured data characterized by a slow response rate, the largest improvements resulted with the following measurement number/sample size pairings for the random-effect triquarter-halfway delta parameter ($\upgamma_{fixed}$): 

* random-effect triquarter-halfway delta parameter ($\upgamma_{random}$): seven measurements with $N \ge 100$ or nine measurements with $N \le 50$. 

\noindent With respect to precision under time-unstructured data characterized by a slow response rate, the largest improvements in the estimation of all the day-unit parameters (except the fixed-effect days-to-halfway elevation parameter [$\upbeta_{fixed}$]) resulted from using the following measurement number/sample size pairings:

* fixed-effect triquarter-halfway delta parameter ($\upgamma_{fixed}$): seven measurements with $N \ge 200$ or nine measurements with $N \le 100$, which resulted in a maximum error bar length of `r errorbar_lengths_slow[2]` days. 
* random-effect days-to-halfway elevation parameter ($\upbeta_{random}$): seven measurements across all manipulated sample sizes, which resulted in a maximum error bar length of `r errorbar_lengths_slow[3]` days.
* random-effect triquarter-halfway delta parameter ($\upgamma_{random}$): seven measurements with $N \ge 200$ or nine measurements with $N \le 100$, which resulted in a maximum error bar length of `r errorbar_lengths_slow[4]` days.

For an applied researcher, one plausible question might be what measurement number/sample size pairing(s) results in the greatest improvements in bias and precision in the estimation of all day-unit parameters with time-unstructured data characterized by a fast response rate. In looking across the measurement number/sample size pairings in the above lists, it becomes apparent that the greatest improvements in bias and precision in the estimation of all day-unit parameters resulted from using seven measurements with $N \ge 200$ or nine measurements with $N \le 100$ (see the emboldened text in the 'Qualitative Description' column of Table \ref{tab:summary-table-slow-exp3}).

#### Summary of Results Time-Unstructured Characterized by a Slow Response Rate

In summarizing the results for time-unstructured data characterized by a slow response rate, estimation of all the day-unit parameters was unbiased using least seven measurements with $N = 1000$, nine measurements with $N \ge 200$, or 11 measurements with $N \ge 100$ (see [bias](#bias-slow-exp3)). Importantly, bias for most day-unit parameters was constant across manipulated measurement number/sample size pairings. Precise estimation was never obtained in the estimation of all day-unit parameters with any manipulated measurement number/sample size pairing (see [precision](#precision-slow-exp3)). Although it may be discouraging that no manipulated measurement number/sample size pairing resulted in precise estimation of all the day-unit parameters with time-unstructured data characterized by a slow response rate, the largest improvements in precision (and bias) across all day-unit parameters resulted with moderate measurement number/sample size pairings. With time-unstructured data characterized by a slow response rate, the largest improvements in bias and precision in the estimation of all day-unit parameters resulted from using seven measurements with $N \ge 200$ or nine measurements with $N \le 100$ (see [qualitiative description](#qualitative-slow-exp3)). 


### How Does Time Structuredness Affect Model Performance?

In Experiment 3, I was interested in how decreasing time structuredness affected model performance. Table \ref{tab:summary-table-exp3} summarizes the results for each spacing schedule in Experiment 3. Text within the 'Unbiased' and 'Precise' columns indicates the measurement number/sample size pairing needed to, respectively, obtain unbiased an precise estimation for all the day-unit parameters. The 'Error Bar Length' column indicates longest error bar lengths that result in the estimation of each day-unit parameter from using the measurement number/sample size pairings listed in the 'Qualitative Description' column. In looking at the 'Qualitative Description' column, the greatest improvements in bias and precision for all time structuredness levels result from using either seven measurements with $N \ge 200$ or nine measurements with $N \le 100$. 

Although the same measurement number/sample size pairing can be used to obtain the greatest improvements in model performance under any time structuredness level, two results suggest that model performance decreases as the time structuredness decreases. First, the error bar lengths in Table \ref{tab:summary-table-exp3} increase as time structuredness decreases. As an  

```{r summary-table-exp3, echo=F}
#combine vectors into a list 
errorbar_lengths_list <- list('ts' = errorbar_lengths_ts, 
                              'fast' = errorbar_lengths_fast, 
                              'slow' = errorbar_lengths_slow)

beta_fixed_errorbar_lengths <- as.numeric(unlist(lapply(X = errorbar_lengths_list, FUN = function(x){return(x[1])})))
gamma_fixed_errorbar_lengths <- as.numeric(unlist(lapply(X = errorbar_lengths_list, FUN = function(x){return(x[2])})))
beta_rand_errorbar_lengths <- as.numeric(unlist(lapply(X = errorbar_lengths_list, FUN = function(x){return(x[3])})))
gamma_rand_errorbar_lengths <- as.numeric(unlist(lapply(X = errorbar_lengths_list, FUN = function(x){return(x[4])})))


summary_table <- data.frame('Time Structuredness' = c('\\thead[lt]{Time structured \\\\ (see Figure \\ref{fig:exp3_plot_days_time_struc} and Table \\ref{tab:summary-table-time-struc-exp3})}', 
                                                   'Time unstructured (fast response rate; see Figure \\ref{fig:exp3_plot_days_fast} and Table \\ref{tab:summary-table-fast-exp3})', 
                                                   
                                                   'Time unstructured (slow response rate; see Figure \\ref{fig:exp3_plot_days_slow} and Table \\ref{tab:summary-table-slow-exp3})'), 
                                                   
                            'Unbiased' = c('\\thead[lt]{NM $\\ge$ 9 with \\textit{N} $\\ge$ 200}', 
                                           
                                           '\\thead[lt]{NM $\\ge$ 7 with \\textit{N} = 1000 or \\\\
                                            NM $\\ge$ 9 with \\textit{N} $\\ge$ 200 or \\\\
                                            NM = 11 with \\textit{N} = 100}', 
                                           
                                           'No cells'), 
                            
                            'Precise' = c('No cells', 
                                          'No cells',
                                          'No cells'),

                            'Qualitative Description' = c('\\thead[lt]{Largest improvements in precision \\\\
                                                          using \\textbf{NM = 7 with \\textit{N} $\\ge$ 200} or \\\\
                                                          \\textbf{NM = 9 with \\textit{N} $\\le$ 100}}', 
                                                      
                                                     '\\thead[lt]{Largest improvements in precision \\\\ 
                                                      using \\textbf{NM = 7 with \\textit{N} $\\ge$ 200} or \\\\
                                                      \\textbf{NM = 9 with \\textit{N} $\\le$ 100}}', 
                                                     
                                                      '\\thead[lt]{Largest improvements in precision \\\\ 
                                                      using \\textbf{NM = 7 with \\textit{N} $\\ge$ 200} or \\\\
                                                      \\textbf{NM = 9 with \\textit{N} $\\le$ 100}}'),
                                                     
                            
                            '$\\upbeta_{fixed}$' = beta_fixed_errorbar_lengths, 
                            '$\\upgamma_{fixed}$' = gamma_fixed_errorbar_lengths, 
                            '$\\upbeta_{random}$' = beta_rand_errorbar_lengths, 
                            '$\\upgamma_{random}$' = gamma_rand_errorbar_lengths, 
                            
                            
                            check.names = F)

kbl(x = summary_table, format = 'latex',
    linesep = c('\\cmidrule{1-8}', '\\cmidrule{1-8}'), #\\cmidrule(l{0.25cm}r{0.25cm}){1-8}
       longtable = T, booktabs = T, centering = T, escape = F,
    caption = 'Concise Summary of Results Across All Time Structuredness Levels in Experiment 3', 
   align = c('l', 'l', 'l', 'l', rep('c', times = 4))) %>%
     #header
  column_spec(column = 1, width = '5cm') %>%
  column_spec(column = 2, width = '4.5cm') %>%
  column_spec(column = 3, width = '2cm') %>%
  column_spec(column = 4, width = '5.5cm') %>%
  column_spec(column = 5:8, width = '1cm') %>%
  add_header_above(header = c(' ' = 4, 'Error Bar Summary' = 4)) %>%
  
   #footnotes
  footnote(escape = F, threeparttable = T, general_title = '',
           general = "\\\\textit{Note. }`Qualitative Description' column indicates the number of measurements that obtains the greatest improvements in bias and precision across all day-unit parameters. `Error Bar Summary' columns list the error bar lengths that result for each day-unit parameter using the measurement number listed in the `Qualitative Description' column. Parameter names and population values are as follows: $\\\\upbeta_{fixed}$ = fixed-effect days-to-halfway elevation parameter $\\\\in$ \\\\{80, 180, 280\\\\}; $\\\\upgamma_{fixed}$ = fixed-effect halfway-triquarter delta parameter = 20; $\\\\upbeta_{random}$ = random-effect days-to-halfway elevation parameter = 10; $\\\\upgamma_{random}$ = random-effect halfway-triquarter delta parameter = 4. NM = number of measurements.") %>%
  kable_styling(position = 'left') %>%
  landscape(margin = '2.54cm')
``` 

\noindent example, the error bar length of the fixed-effect days-to-halfway elevation parameter is `r errorbar_lengths_ts[1]` days with time-structured data and increases to `r errorbar_lengths_slow[1]` days with time-unstructured data characterized by a slow response rate. Second, and more alarming, the bias incurred as time structuredness decreases is constant across all measurement number/sample size pairings (see Figure \ref{fig:exp3_plot_days_slow}). That is, the increase in bias that results from time-unstructured data cannot be reduced by increasing the number of measurements or sample size. An an example, the fixed-effect days-to-halfway elevation parameter is underestimated by approximately 6 days across all measurement number/sample size pairings ($\upbeta_{fixed}$; see Figure \ref{fig:exp3_plot_days_slow}A).

To understand why bias is systematic as time structure decreases, it is important to first understand latent growth curve models more deeply. By default, latent growth curve models assume time-structured data. As a reminder, data are time structured when participants provide data at the exact same moment at each time point (e.g., if a study collects data on the first day of each month for a year, then time-structured data would only be obtained if participants all provide their data at the exact same moment each time data are collected). In other words, one response schedule characterized the response patterns of all participants. Consider a random-intercept-random-slope model shown in Figure \ref{fig:latent-growth} that is used to model stress ratings collected on the first day of each month over the course of five months from $j$ people. Stress ratings at each $i$ time point for each $j$ person are predicted by person-specific intercepts ($b_{0j}$) and slopes ($b_{1j}$; in addition to a residual term [$\upepsilon_{ij}$]) as shown below in Equation \ref{eq:stressLevel1} (which is often called a Level-1 equation):

\begin{align}
  Stress_{ij} = b_{0j} + b_{1j}(Stress_{ij}) + \upepsilon_{ij}.
  (\#eq:stressLevel1)
\end{align}


\noindent The person-specific intercepts and slopes are the sum of a fixed-effect parameter whose value is constant across all people ($\upgamma_{00}$ and $\upgamma_{10}$) and a random-effect parameter that represents the variance of the person-specific variables (i.e., $\upsigma_{00}$ and $\upsigma_{10}$). The fixed-effect intercept and slope, respectively, represent the mean starting stress value (i.e., average stress value at Time = 0) and the average slope value. Importantly, by estimating a random-effect parameter (in addition to the fixed-effect parameters), deviations from the mean intercept an slope values can be obtained for each $j$ person ($\upsigma_{0j}$ and $\upsigma_{1j}$) and these values can be used to compute person-specific intercepts and slopes as shown in Equations \ref{eq:intLevel2}--\ref{eq:slopeLevel2} (which are often called Level-2 equations):

\begin{align}
  b_{0j} = \hat{\upgamma_{00}} + \upsigma_{0j} \label{eq:intLevel2} \\
  b_{1j} = \hat{\upgamma_{10}} + \upsigma_{1j} \label{eq:slopeLevel2}
\end{align}


\noindent Note that the fixed- and random-effect parameters in Figure \ref{fig:latent-growth} are superscribed with a caret ($\hat{\phantom{\beta}}$) to indicate that the values of these parameters are estimated by the latent growth curve model. Also note that, in Figure \ref{fig:latent-growth}, circles indicate latent variables, triangles indicate constants, and squares indicate observed (or manifest variables). 

```{=tex}
\begin{apaFigure}
[portrait]
[samepage]
[-0.2cm]
{Path Diagram for a Random-Intercept-Random-Slope Latent Growth Curve Model}
{latent-growth}
{0.65}
{Figures/lgc_path_diagram}
{Stress at each $i$ time point for each $j$ person is predicted by a person-specific slope ($b_{0j}$), person-specific intercept ($b_{1j}$), and residual ($\upepsilon_{ij}$; see Equation \ref{eq:stressLevel1} [Level-1 equation]). The person-specific effects are also called \textit{random effects} and each is the sum of a fixed-effect parameter whose value is constant across all people ($\upgamma_{00}$ and $\upgamma_{10}$) and a random-effect parameter that represents the variance of the person-specific variables (i.e., $\upsigma_{00}$ and $\upsigma_{10}$; see Equations \ref{eq:intLevel2}--\ref{eq:slopeLevel2} [Level-2 equations]). Note that the fixed- and random-effect parameters are superscribed with a caret ($\hat{\phantom{\beta}}$) to indicate that the values of these parameters are estimated by the latent growth curve model. Also note that circles indicate latent variables, triangles indicate constants, and squares indicate observed (or manifest variables).}
\end{apaFigure}
```


To understand why bias in parameter estimation increases as time structuredness decreases, it is important to discuss one component of the latent growth curve model not yet discussed: loadings. In latent variable models, *loadings* comprise numbers that indicate how a latent variable should be modelled. The numbers in loadings satisfy two needs of latent variables. First, loadings  give latent variables a unit; latent variables are inherently unitless, and so require a unit so that they can be meaningfully interpreted. By fixing at least one pathway between a latent variable and observed variable with a loading, the latent variable takes on the units of the observed variable. In the current example, the intercept and slope latent variables take on the units of the stress ratings (e.g., Likert units). Second, in latent growth curve models, latent variables need their effect to be specified, and loadings satisfy this need. In the current example, the intercept has a constant effect at each time point, and this is represented by setting its loadings at each time point to 1. The slope represents linearly increasing change over time, and so its loadings are set to increase by an integer value of 1 after each time point. 

Although loadings allow latent variables to model change over time, their values are constant across participants and it is this characteristic that causes model performance to decrease as time structuredness decreases. In focusing on the slope variable in Figure \ref{fig:latent-growth}, the loadings of 0, 1, 2, 3, and 4 assume that only one response pattern describes how each participant provides their data over some period of time. If the period of time is assume to be five months, then the loadings assume that each participant provides data on the first day of each month, which is indicated by the gray rectangles (along with the loading number above each gray rectangle) in each panel of Figure \ref{fig:time-structure}. With time-structured data, constant loadings do not decrease model performance because each participant provides their data on the first day of each month. As examples of model performance with time-structured data, panels A and C of Figure \ref{fig:time-structure} show the predicted and actual patterns for individual participants with linear and logistic patterns of change, respectively. Because each individual participant displays a response pattern identical to the one specified by the loadings, the predicted and actual patterns of change are identical. With time-unstructured data however, the predicted and actual patterns of change no longer overlap because response patterns in participants differ from the one assumed by

```{r time-structured-plot, eval=F, include=F}
#Create  data set
##setup variables 
shift_factor <- 20
days <- 1:120
days_shift <- 1:(length(days) + shift_factor)
theta <- 3
alpha <- 3.32
beta <- 60
beta_shift <- beta - shift_factor
gamma <- 10

m <- (alpha - theta)/length(days)
num_measurements <- 5

measurement_days <- compute_measurement_schedule(time_period = length(days), 
                                                 num_measurements = num_measurements, 
                                                 smallest_int_length =  30, 
                                                 measurement_spacing = 'equal')$measurement_days

linear_scores <-  3 + m*days_shift
linear_point_scores <- linear_scores[c(1, measurement_days)]

shift_linear_scores <- linear_scores[shift_factor] + m*days_shift
shift_linear_point_scores <-  shift_linear_scores[c(1, measurement_days)]


logistic_scores <- theta + (alpha - theta)/(1 + exp((beta - days_shift)/gamma))
logistic_point_scores <- logistic_scores[c(1, measurement_days)]

shift_logistic_scores <- theta + (alpha - theta)/(1 + exp((beta_shift - days_shift)/gamma))
shift_logistic_point_scores <-  shift_logistic_scores[c(1, measurement_days)]

#panel titles
panel_A <- "atop(bold(A:~Predicted~Linear~Change~With), bold(`Time-Structured`~Data)~phantom(textf))"
panel_B <- "atop(bold(B:~Predicted~Linear~Change~With), bold(`Time-Unstructured`~Data)~phantom(ti))"
panel_C <- "atop(bold(C:~Predicted~Logistic~Change~With), bold(`Time-Structured`~Data)~phantom(textfsi))"
panel_D <- "atop(bold(D:~Predicted~Logistic~Change~With), bold(`Time-Unstructured`~Data)~phantom(tex))"

#observed data 
observed_line_data <- data.frame('days' = c(days_shift, days_shift, days_shift, days_shift), 
                            'scores' = c(linear_scores, shift_linear_scores,
                                         logistic_scores, shift_logistic_scores), 
                            'panel_title' =  c(rep(panel_A, 
                                                 times = length(linear_scores)),
                                               rep(panel_B, 
                                                 times = length(shift_linear_scores)), 
                                               rep(panel_C, 
                                                 times = length(logistic_scores)), 
                                                rep(panel_D, 
                                                 times = length(shift_logistic_scores))))

observed_point_data <- data.frame('days' = c(measurement_days, measurement_days+20, measurement_days, measurement_days+20), 
                                            
                                  'scores' = c(linear_point_scores, shift_linear_point_scores,
                                             logistic_point_scores, shift_logistic_point_scores),
                                  'panel_title' =  c(rep(panel_A, 
                                                 times = length(linear_point_scores)),
                                               rep(panel_B, 
                                                 times = length(linear_point_scores)), 
                                               rep(panel_C, 
                                                 times = length(logistic_point_scores)), 
                                                rep(panel_D, 
                                                 times = length(logistic_point_scores))))

#modelled data 
modelled_line_data <- data.frame('days' = c(days_shift, days_shift, days_shift, days_shift), 
                            'scores' = c(linear_scores, linear_scores, logistic_scores, logistic_scores),
                            'panel_title' =  c(rep(panel_A, 
                                                 times = length(days_shift)),
                                               rep(panel_B, 
                                                 times = length(days_shift)), 
                                               rep(panel_C, 
                                                 times = length(days_shift)), 
                                                rep(panel_D, 
                                                 times = length(days_shift))))

modelled_point_data <- data.frame('days' = rep(measurement_days, times = 4), 
                                  'scores' = c(linear_point_scores, shift_linear_point_scores, 
                                               logistic_point_scores, shift_logistic_point_scores), 
                                   'panel_title' =  c(rep(panel_A, 
                                                 times = length(linear_point_scores)),
                                               rep(panel_B, 
                                                 times = length(logistic_point_scores)), 
                                               rep(panel_C, 
                                                 times = length(shift_linear_point_scores)), 
                                                rep(panel_D, 
                                                 times = length(shift_logistic_point_scores))))

#combine observed & modelled data sets for modelled 
line_data <- rbind(observed_line_data, modelled_line_data)
line_data$line_type <- factor(x = c(rep(x = 'observed', times = nrow(observed_line_data)), 
                                    rep('model', times = nrow(modelled_line_data))))
point_data <- rbind(observed_point_data, modelled_point_data)
point_data$point_type <- factor(rep(x = c('observed', 'model'), each = nrow(observed_point_data)))

#rectangle data 
width <- 1.5
rectangle_data <- data.frame(
  'xmin' = measurement_days - width,
  'xmax' = measurement_days + width, 
  'ymin' = rep(3.00, times = length(measurement_days)), 
  'ymax' = rep(3.4,  length(measurement_days)), 
 ' panel_title' =  c(rep(panel_A, 
                         times = length(measurement_days))))
                     #rep('bold(B:~Predicted~Linear~Change~(`Time-Structured`~Data))', 
                     #  times = length(logistic_point_scores)), 
                     #rep('bold(C:~Predicted~Logistic~Change~(`Time-Structured`~Data))', 
                     #  times = length(shift_linear_point_scores)), 
                     # rep('bold(D:~Predicted~Logistic~Change~(`Time-Unstructured`~Data))', 
                     #  times = length(shift_logistic_point_scores))))

arrow_data <- data.frame(
  'panel_title' = c(rep(panel_B, times = length(shift_linear_point_scores)), 
                    rep(panel_D, times = length(shift_logistic_point_scores))),
               
  xmin = c(measurement_days + 19, measurement_days + 19), 
  xmax = c(measurement_days + 3, measurement_days + 3), 
  ymin = c(shift_linear_point_scores, shift_logistic_point_scores), 
  ymax = c(shift_linear_point_scores, shift_logistic_point_scores))

text_data <- data.frame('text' = c('0', '1', '2', '3', '4'), 
                        x = c( measurement_days), 
                        y = 3.41)


time_structure_plot <- ggplot(line_data, aes(x = days, y = scores, group = line_type)) + 
  geom_rect(inherit.aes = F, data = rectangle_data, mapping = aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax), 
            fill = 'grey50', color = NA, alpha = 0.2) + 
  geom_line(size = 1.5, mapping = aes(linetype = line_type)) + 
  geom_text(inherit.aes = F, data = text_data, mapping = aes(x = x, y = y, label = text, family = 'Helvetica', fontface = 'bold'), size = 17) + 
  scale_y_continuous(name = 'Stress Rating (Likert Units [1-5])', breaks = c(3.00, 3.16, 3.23, 3.32, 3.40), limits = c(3.00, 3.41)) +
  geom_point(data = point_data, inherit.aes = F, mapping = aes(x = days, y = scores, shape = point_type, fill = point_type), size = 15) + 
  theme_classic(base_family = 'Helvetica') + 

  #arrows
 geom_segment(data = arrow_data, inherit.aes = F, mapping = aes(x = xmin, xend = xmax, y = ymin, yend = ymax), 
              arrow = arrow(length = unit(1, 'cm')), size = 2.5)  + 

  nonlinSimsAnalysis:::facet_wrap_custom( ~ panel_title, scales = "free", ncol = 2, nrow = 2 , dir = 'h',
                     labeller = label_parsed,  

                            scale_overrides = list(
                            nonlinSimsAnalysis:::scale_override(1,
                              scale_x_continuous(
                                breaks = c(0, 30, 60, 90, 120, 150),
                                 labels = c('Feb', 'Mar', 'May', 'Apr', 'May', 'June'), 
                                limits = c(-2.5, 150))), 
                            
                             nonlinSimsAnalysis:::scale_override(which = 2,
                              scale_x_continuous(
                                breaks = c(0, 30, 60, 90, 120, 150),
                                 labels = c('Feb', 'Mar', 'May', 'Apr', 'May', 'June'), 
                                limits = c(-2.5, 150))),  
                            
                            nonlinSimsAnalysis:::scale_override(which = 3,
                               scale_x_continuous(
                                breaks = c(0, 30, 60, 90, 120, 150),
                                 labels = c('Feb', 'Mar', 'May', 'Apr', 'May', 'June'), 
                                limits = c(-2.5, 150))), 
                         
                            nonlinSimsAnalysis:::scale_override(4,
                              scale_x_continuous(
                                   breaks = c(0, 30, 60, 90, 120, 150),
                                   labels = c('Feb', 'Mar', 'May', 'Apr', 'May', 'June'), 
                                limits = c(-2.5, 150))))) + 
  
   scale_shape_manual(name = 'Pattern of Change', 
                      values=c(22,22),
                       labels = c('Predicted', 'Actual')) + 
                      
  scale_linetype_manual(name = 'Pattern of Change', values = c('solid', 'dashed'), 
                         labels = c('Predicted', 'Actual')) + 
  scale_fill_manual(name = 'Pattern of Change',
                    values = c('white', 'black'),
                    labels = c('Predicted', 'Actual')) +  #set drop =FALSE s that unused levels are included


  labs( x = 'Month') + 
  
  theme(
      #panel details
      strip.background = element_rect(fill = "white", color = "white"),
      strip.text.x = element_text(face = 'bold', hjust = 0, size = 60, margin = unit(c(t = 3, r = 0, b = 1, l = 0), "cm")),

      #axis details
      axis.text = element_text(size = 50, color = 'black'),
      axis.text.x = element_text(size = 55, vjust = 0.25, angle = 0), 
      axis.title = element_text(size = 60),
      axis.line = element_line(size = 2),
      axis.ticks.length.x = unit(x = 1, units = 'cm'),
      axis.title.x = element_text(margin = unit(c(t = 2, r = 0, 0, 0), "cm")),
      axis.title.y = element_text(margin = unit(c(t = 0, r = 2, b = 0, l = 0), units = 'cm')),
      axis.ticks = element_line(size = 2, colour = 'black'),
      axis.ticks.length.y =  unit(x = 1, units = 'cm'),

      #legend details
     
      legend.text = element_text(size = 45, margin = unit(c(t = 0, r = 3, b = 0, l = 0), "cm")),
      legend.margin = margin(unit(x = c(t = 0, r= 10, b = 10, l = 10), "cm")),
      legend.title = element_text(size = 50,  margin = unit(c(t = 0.5, r = 0, b = 0, l = 0), "cm")),
      legend.key.size = unit(3, 'cm'),
      legend.position = c(0.5, 0.51),
      legend.direction = 'vertical',
      legend.box.background = element_rect(colour = 'black', size = 3),

      #panel details
      panel.spacing.y = unit(x = 12, units = 'cm'),
      panel.spacing.x = unit(x = 2, units = 'cm'))


set_panel_size(p = time_structure_plot, height = unit(x = 32, units = 'cm'),
                 width = unit(x = 40, units = 'cm'),
                 file =  'Figures/time_structure_plots.pdf')



```


```{=tex}
\begin{apaFigure}
[portrait]
[samepage]
[-0.2cm]
{Model Performance Decreases as Time Structuredness Decreases}
{time-structure}
{0.165}
{Figures/time_structure_plots}
{Panel A: Predicted and actual linear patterns of change are identical because of time-structured data. Panel B: Predicted and actual linear patterns of change are different because of time-untructured data. Panel C: Predicted and actual logistic patterns of change are identical because of time-structured data. Panel D: Predicted and actual logistic patterns of change differ because model because of time-unstructured data. Predicted patterns of change are based on empty dots and actual patterns of change are based on filled dots. Shaded vertical rectangles indicate the response pattern expected across all participants by the loadings set in the latent growth curve model depicted in Figure \ref{fig:latent-growth}.}
\end{apaFigure}
```

\noindent the loadings. As examples of model performance with time-unstructured data, panels B and D of Figure \ref{fig:time-structure} show the predicted and actual patterns for individual participants with linear and logistic patterns of change, respectively. Although each participant provides data many days after the first day of each month, the constant loadings set in the model lead it to assume that data were collected on the first day of each month. Because the model misattributes the time at which data are recorded, the predicted patterns of change are shifted leftward, leading to a decrease in model performance. In Figure \ref{fig:time-structure}B, the intercept parameter value ($b_{0j}$) increases due to time-unstructured data. In Figure \ref{fig:time-structure}D, the value for the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$) decreases due to time-unstructured data. Therefore, the loading structured specified by default in latent growth curve model causes model performance to decrease when data are time unstructured.  



### Eliminating the Bias Caused by Time Unstructuredness: Using Definition Variables {#def-variables}

In examining the effects of time structuredness, the results show that model performance decreases as time structuredness decreases. Importantly, increasing the number of measurements and/or sample size has no effect on eliminating the decline in model performance.  Because data are likely to be time unstructured under realistic conditions, the resulting decline in model performance seems inevitable and this can be disconcerting. Fortunately, the error incurred when time unstructuredness is overlooked can be prevented by allowing loadings to vary across people by using *definition variables*: Observed variables are placed in parameter matrices so that values in the matrix (specifically, the loadings) are constrained to person-specific values [@mehta2000; @mehta2005; @blozis2008; @sterba2014]. In the current example, definition variables are used to set loadings to the specific time points at which each participant provides their data. Thus, the observed variable is the specific $i$ time point at which a $j$ person provides a datum and this value is inserted into the $\uplambda$ matrix (for details of this matrix, see Appendix \ref{structured-lgc}). Figure \ref{fig:latent-def} shows a path diagram for a random-intercept-random-slope latent variable model with definition variables. In comparing it to the latent growth curve model in Figure \ref{fig:latent-growth}, there is only one difference. Instead of setting the loadings to be constant across all participants, definition variables (indicated by diamonds) are used so that loadings for each $j$ person are set to the specific $i$ time point at which a datum was provided. 

```{=tex}
\begin{apaFigure}
[portrait]
[samepage]
[-0.2cm]
{Path Diagram for a Random-Intercept-Random-Slope Latent Growth Curve Model With Definition Variables}
{latent-def}
{0.65}
{Figures/def_model}
{Stress at each $i$ time point for each $j$ person is predicted by a person-specific slope ($b_{0j}$), person-specific intercept ($b_{1j}$), and residual ($\upepsilon_{ij}$; see Equation \ref{eq:stressLevel1} [Level-1 equation]). The person-specific effects are also called \textit{random effects} and each is the sum of a fixed-effect parameter whose value is constant across all people ($\upgamma_{00}$ and $\upgamma_{10}$) and a random-effect parameter that represents the variance of the person-specific variables (i.e., $\upsigma_{00}$ and $\upsigma_{10}$; see Equations \ref{eq:intLevel2}--\ref{eq:slopeLevel2} [Level-2 equations]). Note that the fixed- and random-effect parameters are superscribed with a caret ($\hat{\phantom{\beta}}$) to indicate that the values of these parameters are estimated by the latent growth curve model. To account for time-unstructured data, loadings are allowed to vary using definition variables (diamonds). Specifically, loadings for each $j$ person are set to the specific $i$ time point at which a datum was provided. Also note that circles indicate latent variables, triangles indicate constants, and squares indicate observed (or manifest variables).}
\end{apaFigure}
```

To show that definition variables can eliminate the error incurred by time-unstructured data, I ran an additional set of simulations. In these simulations, time-unstructured data characterized by a slow response rate were analyzed with a structured latent growth curve model equipped with definition variables (see Appendix \ref{def-model-code} for the corresponding code). Number of measurements and sample size were manipulated as in Experiment 3, thus yielding 24 cells (i.e., 4[number of measurements: 5, 7, 9, 11] x 6[sample size: 30, 50, 100, 200, 500, 1000]). As in all previous simulation experiments, I only present the results for the day-unit parameters because the results for the Likert-unit parameters were largely negligible (for Likert-unit bias/precision plots, see Appendix \ref{complete-versions}). Similar to the results for convergence success rates obtained in all other simulation experiments, convergence success rates across all cells were always above 90%, with the specific values presented in Table \ref{tab:conv-exp-3-def}.\footnote{It should be noted that convergence times increased by approximately eightfold when definition variables were used.}

Figure \ref{fig:exp3_plot_days_def} shows the bias/precision plots that result from using definition variables to model time-unstructured data characterized by a slow response rate. In comparing the bias/precision plot of Figure \ref{fig:exp3_plot_days_def} to that of Figure \ref{fig:exp3_plot_days_slow}, model performance improves in the following four ways: 

```{r plots-slow-response-def, include=F, eval=F}
generate_day_likert_facet_plot(analytical_data = exp_3_def_analytical, 
                               target_col = 'time_structuredness', target_value = 'Time unstructured (slow response)',
                              x_axis_name = expression("Sample Size ("*italic(N)*")"), 
                               x_axis_var = 'sample_size', exp_num = 'exp3_def', beta_lower = 160, beta_upper = 210,
                                 beta_ticks = 5)

```

```{=tex}
\begin{apaFigure}
[portrait]
[samepage]
[-0.2cm]
{Bias/Precision Plots for Day-Unit Parameters When Using Definition Variables To Model Time-Unstructured Data Characterized by a Slow Response Rate}
{exp3_plot_days_def}
{0.165}
{Figures/exp3_defplot_days_time unstructured (slow response)}
{Panel A: Bias/precision plot for the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$). Panel B: Bias/precision plot for the fixed-effect triquarter-halfway elevation parameter ($\upgamma_{fixed}$). Panel C: Bias/precision plot for the random-effect days-to-halfway elevation parameter ($\upbeta_{random}$). Panel D: Bias/precision plot for the random-effect triquarter-halfway elevation parameter ($\upgamma_{random}$). Blue horizontal lines in each panel represent the population value for each parameter. Population values for each day-unit parameter are as follows: $\upbeta_{fixed}$ = 180.00, $\upbeta_{random}$ = 10.00, $\upgamma_{fixed}$ = 20.00, $\upgamma_{random}$ = 4.00. Gray bands indicate the $\pm 10\%$ margin of error for each parameter and unfilled dots indicate cells with average parameter estimates outside of the margin or biased estimates. Error bars represent the middle 95\% of estimated values, with light blue error bars indicating imprecise estimation. I considered dots that fell outside the gray bands as biased and error bar lengths with at least one whisker length exceeding the 10\% cutoff (i.e., or longer than the portion of the gray band underlying the whisker) as imprecise. Note that random-effect parameter units are in standard deviation units. See Table \ref{tab:param-exp-3} for specific values estimated for each parameter and Table \ref{tab:omega-exp3-def} for $\upomega^2$ effect size values.}
\end{apaFigure}
```

```{r omega-exp3-def, echo=F}
print_bias_var_omega_table(exp_data = exp_3_raw, target_col = 'time_structuredness', target_value = 'time_structured', 
ind_vars = c('number_measurements', 'sample_size'), 
ind_var_acronyms = c('NM', 'S', 'NM x S'), 
caption = 'Partial $\\upomega^2$ Values for Manipulated Variables With Time-Unstructured Data Characterized by a Slow Response Rate With a Model Using Definition Variables in Experiment 3',
footnote = 'NM = number of measurements (5, 7, 9, 11), S = sample size (30, 50, 100, 200, 500, 100), NM x S = interaction between number of measurements and sample size.', 
parameter_labels = c('$\\upbeta_{fixed}$ (Figure \\ref{fig:exp3_plot_days_def}A)',
                     '$\\upbeta_{random}$ (Figure \\ref{fig:exp3_plot_days_def}B)',
                     '$\\upgamma_{fixed}$ (Figure \\ref{fig:exp3_plot_days_def}C)',
                     '$\\upgamma_{random}$ (Figure \\ref{fig:exp3_plot_days_def}D)'))

```


1) Bias in the estimation of the fixed-effect days-to-halfway elevation parameter ($\upbeta_{fixed}$; Figure \ref{fig:exp3_plot_days_slow}A) almost entirely disappears when using definition variables (Figure \ref{fig:exp3_plot_days_def}A). 
2) Bias in the estimation of the fixed-effect triquarter-halfway elevation parameter ($\upgamma_{fixed}$; Figure \ref{fig:exp3_plot_days_slow}B) almost entirely disappears when using definition variables (Figure \ref{fig:exp3_plot_days_def}B). 
3) Bias in the estimation of the random-effect days-to-halfway elevation parameter ($\upbeta_{random}$; Figure \ref{fig:exp3_plot_days_slow}C) almost entirely disappears when using definition variables (Figure \ref{fig:exp3_plot_days_def}C). 
4) Bias in the estimation of the random-effect triquarter-halfway elevation parameter ($\upgamma_{random}$; Figure \ref{fig:exp3_plot_days_slow}D) returns to levels observed with time-structured data (see Figure \ref{fig:exp3_plot_days_time_struc}A) with definition variables.  Precision also improves (especially with five measurements) when using definition variables (Figure \ref{fig:exp3_plot_days_def}C). 

\noindent Therefore, given the improvements in the estimation of each day-unit parameter that follow from using definition variables, latent variable models, by default, should use definition variables to improve model performance when data are time unstructured.



## Summary of Experiment 3

I designed Experiment 3 to investigate whether model performance decreased as time structuredness decreased. Across all manipulated levels of time structuredness, the greatest improvements in model performance result from using either seven measurements with $N \ge 200$ and nine measurements with $N \le 100$. Importantly, although the measurement number/sample size pairings that result in the greatest improvements in model performance do not change as time structuredness decreases, the absolute level of model performance itself decreases. In using the same measurement number/sample size pairing across all levels of time structuredness, precision slightly improves and, more importantly, bias decreases such that it is constant; that is, the decrease in bias cannot be avoided by using increasing measurement number and/or sample size. Given that data are unlikely to be time structured, then the decrease in model performance seems inevitable. Fortunately, the decrease in model performance that results from time-unstructured data can be avoided by using definition variables in latent growth curve models, which I show to be the case by in an additional set of simulations. Therefore, the greatest improvements in model performance result from using either seven measurements with $N \ge 200$ or nine measurements with $N \le 100$ and, definition variables should be used to prevent model performance from decreasing as time structuredness decreases.  




